Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: false
  get_crown_verified_acc: false
  csv_name: null
  onnx_path: null
  vnnlib_path: null
  results_file: null
  root_path: null
model:
  path: null
  name: mnist_9_200
data:
  start: 0
  end: 10000
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR
  data_filter_path: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.15
solver:
  alpha-crown:
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
  beta-crown:
    batch_size: 300
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 99999999
  timeout: 180
  get_upper_bound: false
  dfs_percent: 0.0
  branching:
    method: kfsb
    candidates: 3
    reduceop: max
attack:
  pgd_order: before
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
           Flatten-1                    [-1, 4]               0
            Linear-2                    [-1, 3]              15
              ReLU-3                    [-1, 3]               0
            Linear-4                    [-1, 5]              20
              ReLU-5                    [-1, 5]               0
            Linear-6                    [-1, 3]              18
================================================================
Total params: 53
Trainable params: 53
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.00
Params size (MB): 0.00
Estimated Total Size (MB): 0.00
----------------------------------------------------------------
X tensor([[ 0.3854,  0.2855,  0.4914, -0.0268]], device='cuda:0')
tensor([[-0.3828,  0.2229,  0.4259]], device='cuda:0', grad_fn=<AddmmBackward>)
Trying to verify that the network will never predict 0 upon seeing 2
C tensor([[[-1.,  0.,  1.]]], device='cuda:0')
domain torch.Size([1, 4, 2])
INIT_SLOPE X SHAPE 1 (1, 1, 4)
L tensor([[0.7708]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWNNNN bounds: tensor([[0.7708]], device='cuda:0') None
best_l after optimization: -0.7707942128181458 with beta sum per layer: []
alpha/beta optimization time: 3.4911398887634277
initial alpha-CROWN bounds: tensor([[0.7708]], device='cuda:0', grad_fn=<AsStridedBackward>) None
{0: '/8', 1: '/10'}
global_lb tensor([[0.7708]], device='cuda:0')
INIT domain SortedList([	
=======ReLUDomain========
	Priority:
	0
	Lower bound:
	0.7707942128181458
	History:
	[[[], []], [[], []]]
	Split History:
	None
])
layer 0 size torch.Size([3]) unstable 2
layer 1 size torch.Size([5]) unstable 1
-----------------
# of unstable neurons: 3
-----------------

visualizing internal state
BoundRelu()
BoundRelu()
In Pick_out_batch, dfs_percent:0
domains:SortedList([	
=======ReLUDomain========
	Priority:
	0
	Lower bound:
	0.7707942128181458
	History:
	[[[], []], [[], []]]
	Split History:
	None
])
Original mask [tensor([[1., 1., 0.]], device='cuda:0'), tensor([[0., 1., 0., 0., 0.]], device='cuda:0')]
branching decision [[0, 0]]
splitting decisions: [[0, 0]]
--------------------------
Computing lower bound for
Split:{'decision': [[[0, 0]]], 'coeffs': [[1.0]], 'diving': 0}
Using single node split
BoundRelu()
S matrix location
 tensor([[0],
        [0]], device='cuda:0') torch.Size([2, 1])
S matrix
 tensor([[ 1.],
        [-1.]]) torch.Size([2, 1])
BoundRelu()
S matrix location
 tensor([], device='cuda:0', size=(2, 0), dtype=torch.int64) torch.Size([2, 0])
S matrix
 tensor([], size=(2, 0)) torch.Size([2, 0])
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 2, 5])
sparse beta:
 tensor([], device='cuda:0', size=(2, 0), requires_grad=True)
sparse beta sign
 tensor([], device='cuda:0', size=(2, 0))
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 2, 3])
sparse beta:
 tensor([[0.],
        [0.]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[ 1.],
        [-1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 2, 5])
sparse beta:
 tensor([], device='cuda:0', size=(2, 0), requires_grad=True)
sparse beta sign
 tensor([], device='cuda:0', size=(2, 0))
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 2, 3])
sparse beta:
 tensor([[0.0500],
        [-0.0000]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[ 1.],
        [-1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 2, 5])
sparse beta:
 tensor([], device='cuda:0', size=(2, 0), requires_grad=True)
sparse beta sign
 tensor([], device='cuda:0', size=(2, 0))
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 2, 3])
sparse beta:
 tensor([[0.0990],
        [-0.0000]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[ 1.],
        [-1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 2, 5])
sparse beta:
 tensor([], device='cuda:0', size=(2, 0), requires_grad=True)
sparse beta sign
 tensor([], device='cuda:0', size=(2, 0))
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 2, 3])
sparse beta:
 tensor([[0.1425],
        [-0.0000]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[ 1.],
        [-1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 2, 5])
sparse beta:
 tensor([], device='cuda:0', size=(2, 0), requires_grad=True)
sparse beta sign
 tensor([], device='cuda:0', size=(2, 0))
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 2, 3])
sparse beta:
 tensor([[0.1829],
        [-0.0000]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[ 1.],
        [-1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 2, 5])
sparse beta:
 tensor([], device='cuda:0', size=(2, 0), requires_grad=True)
sparse beta sign
 tensor([], device='cuda:0', size=(2, 0))
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 2, 3])
sparse beta:
 tensor([[0.2148],
        [-0.0000]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[ 1.],
        [-1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 2, 5])
sparse beta:
 tensor([], device='cuda:0', size=(2, 0), requires_grad=True)
sparse beta sign
 tensor([], device='cuda:0', size=(2, 0))
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 2, 3])
sparse beta:
 tensor([[0.2402],
        [-0.0000]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[ 1.],
        [-1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 2, 5])
sparse beta:
 tensor([], device='cuda:0', size=(2, 0), requires_grad=True)
sparse beta sign
 tensor([], device='cuda:0', size=(2, 0))
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 2, 3])
sparse beta:
 tensor([[0.2606],
        [-0.0000]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[ 1.],
        [-1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 2, 5])
sparse beta:
 tensor([], device='cuda:0', size=(2, 0), requires_grad=True)
sparse beta sign
 tensor([], device='cuda:0', size=(2, 0))
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 2, 3])
sparse beta:
 tensor([[0.2768],
        [-0.0000]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[ 1.],
        [-1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 2, 5])
sparse beta:
 tensor([], device='cuda:0', size=(2, 0), requires_grad=True)
sparse beta sign
 tensor([], device='cuda:0', size=(2, 0))
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 2, 3])
sparse beta:
 tensor([[0.2896],
        [-0.0000]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[ 1.],
        [-1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 2, 5])
sparse beta:
 tensor([], device='cuda:0', size=(2, 0), requires_grad=True)
sparse beta sign
 tensor([], device='cuda:0', size=(2, 0))
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 2, 3])
sparse beta:
 tensor([[0.2996],
        [-0.0000]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[ 1.],
        [-1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 2, 5])
sparse beta:
 tensor([], device='cuda:0', size=(2, 0), requires_grad=True)
sparse beta sign
 tensor([], device='cuda:0', size=(2, 0))
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 2, 3])
sparse beta:
 tensor([[0.3071],
        [-0.0000]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[ 1.],
        [-1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 2, 5])
sparse beta:
 tensor([], device='cuda:0', size=(2, 0), requires_grad=True)
sparse beta sign
 tensor([], device='cuda:0', size=(2, 0))
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 2, 3])
sparse beta:
 tensor([[0.3126],
        [-0.0000]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[ 1.],
        [-1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 2, 5])
sparse beta:
 tensor([], device='cuda:0', size=(2, 0), requires_grad=True)
sparse beta sign
 tensor([], device='cuda:0', size=(2, 0))
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 2, 3])
sparse beta:
 tensor([[0.3162],
        [-0.0000]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[ 1.],
        [-1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 2, 5])
sparse beta:
 tensor([], device='cuda:0', size=(2, 0), requires_grad=True)
sparse beta sign
 tensor([], device='cuda:0', size=(2, 0))
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 2, 3])
sparse beta:
 tensor([[0.3183],
        [-0.0000]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[ 1.],
        [-1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 2, 5])
sparse beta:
 tensor([], device='cuda:0', size=(2, 0), requires_grad=True)
sparse beta sign
 tensor([], device='cuda:0', size=(2, 0))
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 2, 3])
sparse beta:
 tensor([[0.3191],
        [-0.0000]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[ 1.],
        [-1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 2, 5])
sparse beta:
 tensor([], device='cuda:0', size=(2, 0), requires_grad=True)
sparse beta sign
 tensor([], device='cuda:0', size=(2, 0))
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 2, 3])
sparse beta:
 tensor([[0.3187],
        [-0.0000]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[ 1.],
        [-1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 2, 5])
sparse beta:
 tensor([], device='cuda:0', size=(2, 0), requires_grad=True)
sparse beta sign
 tensor([], device='cuda:0', size=(2, 0))
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 2, 3])
sparse beta:
 tensor([[0.3172],
        [-0.0000]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[ 1.],
        [-1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 2, 5])
sparse beta:
 tensor([], device='cuda:0', size=(2, 0), requires_grad=True)
sparse beta sign
 tensor([], device='cuda:0', size=(2, 0))
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 2, 3])
sparse beta:
 tensor([[0.3148],
        [-0.0000]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[ 1.],
        [-1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 2, 5])
sparse beta:
 tensor([], device='cuda:0', size=(2, 0), requires_grad=True)
sparse beta sign
 tensor([], device='cuda:0', size=(2, 0))
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 2, 3])
sparse beta:
 tensor([[0.3117],
        [-0.0000]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[ 1.],
        [-1.]], device='cuda:0')
best_l after optimization: -1.577042579650879 with beta sum per layer: [0.18293826282024384, 0.0]
alpha/beta optimization time: 0.5668940544128418
In get_candidate_parallel
layer.inputs [<function LiRPAConvNet.transfer_to_cpu.<locals>.<lambda> at 0x7fa32fa67320>]
In get_candidate_parallel
layer.inputs [<function LiRPAConvNet.transfer_to_cpu.<locals>.<lambda> at 0x7fa32fa6e0e0>]
lower_bounds:
 [tensor([[ 0.0000, -0.0036,  0.5460],
        [-0.2831, -0.0036,  0.5460]]), tensor([[-0.8818, -0.2054, -0.8323,  0.4754, -0.5227],
        [-0.8818, -0.2054, -0.8323,  0.4754, -0.5227]]), tensor([[0.8057],
        [0.7714]])]
lower_bounds_new shape:
 [torch.Size([2, 3]), torch.Size([2, 5]), torch.Size([2, 1])]
This batch time : update_bounds func: 0.5727	 prepare: 0.0030	 bound: 0.5672	 transfer: 0.0006	 finalize: 0.0018
Accumulated time: update_bounds func: 0.5727	 prepare: 0.0030	 bound: 0.5672	 transfer: 0.0006	 finalize: 0.0018
batch bounding time:  0.5727636814117432
Lower bound of this batch:
[[tensor([[ 0.0000, -0.0036,  0.5460]]), tensor([[-0.8818, -0.2054, -0.8323,  0.4754, -0.5227]]), tensor([[0.8057]])], [tensor([[-0.2831, -0.0036,  0.5460]]), tensor([[-0.8818, -0.2054, -0.8323,  0.4754, -0.5227]]), tensor([[0.7714]])]]
In Add domain parallel
Before:
SortedList([])
After
SortedList([	
=======ReLUDomain========
	Priority:
	0
	Lower bound:
	0.7713782787322998
	History:
	[[[0], [-1.0]], [[], []]]
	Split History:
	{}
, 	
=======ReLUDomain========
	Priority:
	0
	Lower bound:
	0.8056643605232239
	History:
	[[[0], [1.0]], [[], []]]
	Split History:
	{}
])
Current worst splitting domains [lb, ub] (depth):
[0.77138, 99.770798] (1), [0.80566, 99.770798] (1), 
length of domains: 2
Total time: 0.5992	 pickout: 0.0010	 decision: 0.0210	 get_bound: 0.5751	 add_domain: 0.0003
Current lb:0.7713782787322998
2 neurons visited
Global ub: tensor([[99.7708]], device='cuda:0'), batch ub: inf
Cumulative time: 4.619273662567139

visualizing internal state
BoundRelu()
BoundRelu()
In Pick_out_batch, dfs_percent:0
domains:SortedList([	
=======ReLUDomain========
	Priority:
	0
	Lower bound:
	0.7713782787322998
	History:
	[[[0], [-1.0]], [[], []]]
	Split History:
	{}
, 	
=======ReLUDomain========
	Priority:
	0
	Lower bound:
	0.8056643605232239
	History:
	[[[0], [1.0]], [[], []]]
	Split History:
	{}
])
Original mask [tensor([[0., 1., 0.],
        [0., 1., 0.]], device='cuda:0'), tensor([[0., 1., 0., 0., 0.],
        [0., 1., 0., 0., 0.]], device='cuda:0')]
branching decision [[1, 1], [1, 1]]
splitting decisions: [[1, 1], [1, 1]]
--------------------------
Computing lower bound for
Split:{'decision': [[[1, 1]], [[1, 1]]], 'coeffs': [[1.0], [1.0]], 'diving': 0}
Using single node split
BoundRelu()
S matrix location
 tensor([[0],
        [0],
        [0],
        [0]], device='cuda:0') torch.Size([4, 1])
S matrix
 tensor([[-1.],
        [ 1.],
        [-1.],
        [ 1.]]) torch.Size([4, 1])
BoundRelu()
S matrix location
 tensor([[1],
        [1],
        [1],
        [1]], device='cuda:0') torch.Size([4, 1])
S matrix
 tensor([[ 1.],
        [ 1.],
        [-1.],
        [-1.]]) torch.Size([4, 1])
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 4, 5])
sparse beta:
 tensor([[0.],
        [0.],
        [0.],
        [0.]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[ 1.],
        [ 1.],
        [-1.],
        [-1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 4, 3])
sparse beta:
 tensor([[0.0000],
        [0.1829],
        [0.0000],
        [0.1829]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.],
        [ 1.],
        [-1.],
        [ 1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 4, 5])
sparse beta:
 tensor([[0.0500],
        [0.0500],
        [-0.0000],
        [-0.0000]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[ 1.],
        [ 1.],
        [-1.],
        [-1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 4, 3])
sparse beta:
 tensor([[-0.0000],
        [0.1329],
        [-0.0000],
        [0.1329]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.],
        [ 1.],
        [-1.],
        [ 1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 4, 5])
sparse beta:
 tensor([[0.0977],
        [0.0990],
        [-0.0000],
        [-0.0000]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[ 1.],
        [ 1.],
        [-1.],
        [-1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 4, 3])
sparse beta:
 tensor([[-0.0000],
        [0.0839],
        [-0.0000],
        [0.1600]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.],
        [ 1.],
        [-1.],
        [ 1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 4, 5])
sparse beta:
 tensor([[0.1442],
        [0.1468],
        [-0.0000],
        [-0.0000]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[ 1.],
        [ 1.],
        [-1.],
        [-1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 4, 3])
sparse beta:
 tensor([[-0.0000],
        [0.1000],
        [-0.0000],
        [0.1725]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.],
        [ 1.],
        [-1.],
        [ 1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 4, 5])
sparse beta:
 tensor([[0.1897],
        [0.1933],
        [-0.0000],
        [-0.0000]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[ 1.],
        [ 1.],
        [-1.],
        [-1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 4, 3])
sparse beta:
 tensor([[-0.0000],
        [0.1061],
        [-0.0000],
        [0.1757]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.],
        [ 1.],
        [-1.],
        [ 1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 4, 5])
sparse beta:
 tensor([[0.2344],
        [0.2387],
        [-0.0000],
        [-0.0000]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[ 1.],
        [ 1.],
        [-1.],
        [-1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 4, 3])
sparse beta:
 tensor([[-0.0000],
        [0.1052],
        [-0.0000],
        [0.1726]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.],
        [ 1.],
        [-1.],
        [ 1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 4, 5])
sparse beta:
 tensor([[0.2782],
        [0.2831],
        [-0.0000],
        [-0.0000]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[ 1.],
        [ 1.],
        [-1.],
        [-1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 4, 3])
sparse beta:
 tensor([[-0.0000],
        [0.0992],
        [-0.0000],
        [0.1647]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.],
        [ 1.],
        [-1.],
        [ 1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 4, 5])
sparse beta:
 tensor([[0.3212],
        [0.3265],
        [-0.0000],
        [-0.0000]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[ 1.],
        [ 1.],
        [-1.],
        [-1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 4, 3])
sparse beta:
 tensor([[-0.0000],
        [0.0893],
        [-0.0000],
        [0.1532]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.],
        [ 1.],
        [-1.],
        [ 1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 4, 5])
sparse beta:
 tensor([[0.3634],
        [0.3665],
        [-0.0000],
        [-0.0000]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[ 1.],
        [ 1.],
        [-1.],
        [-1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 4, 3])
sparse beta:
 tensor([[-0.0000],
        [0.0996],
        [-0.0000],
        [0.1595]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.],
        [ 1.],
        [-1.],
        [ 1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 4, 5])
sparse beta:
 tensor([[0.4034],
        [0.4038],
        [-0.0000],
        [-0.0000]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[ 1.],
        [ 1.],
        [-1.],
        [-1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 4, 3])
sparse beta:
 tensor([[-0.0000],
        [0.1193],
        [-0.0000],
        [0.1615]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.],
        [ 1.],
        [-1.],
        [ 1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 4, 5])
sparse beta:
 tensor([[0.4414],
        [0.4387],
        [-0.0000],
        [-0.0000]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[ 1.],
        [ 1.],
        [-1.],
        [-1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 4, 3])
sparse beta:
 tensor([[-0.0000],
        [0.1444],
        [-0.0000],
        [0.1600]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.],
        [ 1.],
        [-1.],
        [ 1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 4, 5])
sparse beta:
 tensor([[0.4779],
        [0.4716],
        [-0.0000],
        [-0.0000]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[ 1.],
        [ 1.],
        [-1.],
        [-1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 4, 3])
sparse beta:
 tensor([[-0.0000],
        [0.1730],
        [-0.0000],
        [0.1554]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.],
        [ 1.],
        [-1.],
        [ 1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 4, 5])
sparse beta:
 tensor([[0.5130],
        [0.5029],
        [-0.0000],
        [-0.0000]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[ 1.],
        [ 1.],
        [-1.],
        [-1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 4, 3])
sparse beta:
 tensor([[-0.0000],
        [0.2040],
        [-0.0000],
        [0.1623]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.],
        [ 1.],
        [-1.],
        [ 1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 4, 5])
sparse beta:
 tensor([[0.5469],
        [0.5327],
        [-0.0000],
        [-0.0000]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[ 1.],
        [ 1.],
        [-1.],
        [-1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 4, 3])
sparse beta:
 tensor([[-0.0000],
        [0.2365],
        [-0.0000],
        [0.1656]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.],
        [ 1.],
        [-1.],
        [ 1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 4, 5])
sparse beta:
 tensor([[0.5796],
        [0.5611],
        [-0.0000],
        [-0.0000]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[ 1.],
        [ 1.],
        [-1.],
        [-1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 4, 3])
sparse beta:
 tensor([[-0.0000],
        [0.2701],
        [-0.0000],
        [0.1661]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.],
        [ 1.],
        [-1.],
        [ 1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 4, 5])
sparse beta:
 tensor([[0.6104],
        [0.5885],
        [-0.0000],
        [-0.0000]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[ 1.],
        [ 1.],
        [-1.],
        [-1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 4, 3])
sparse beta:
 tensor([[-0.0000],
        [0.3042],
        [-0.0000],
        [0.1641]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.],
        [ 1.],
        [-1.],
        [ 1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 4, 5])
sparse beta:
 tensor([[0.6394],
        [0.6148],
        [-0.0000],
        [-0.0000]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[ 1.],
        [ 1.],
        [-1.],
        [-1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 4, 3])
sparse beta:
 tensor([[-0.0000],
        [0.3388],
        [-0.0000],
        [0.1600]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.],
        [ 1.],
        [-1.],
        [ 1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 4, 5])
sparse beta:
 tensor([[0.6669],
        [0.6427],
        [-0.0000],
        [-0.0000]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[ 1.],
        [ 1.],
        [-1.],
        [-1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 4, 3])
sparse beta:
 tensor([[-0.0000],
        [0.3683],
        [-0.0000],
        [0.1540]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.],
        [ 1.],
        [-1.],
        [ 1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 4, 5])
sparse beta:
 tensor([[0.6912],
        [0.6715],
        [-0.0000],
        [-0.0000]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[ 1.],
        [ 1.],
        [-1.],
        [-1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 4, 3])
sparse beta:
 tensor([[-0.0000],
        [0.3935],
        [-0.0000],
        [0.1572]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.],
        [ 1.],
        [-1.],
        [ 1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 4, 5])
sparse beta:
 tensor([[0.7127],
        [0.7011],
        [-0.0000],
        [-0.0000]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[ 1.],
        [ 1.],
        [-1.],
        [-1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 4, 3])
sparse beta:
 tensor([[-0.0000],
        [0.4147],
        [-0.0000],
        [0.1669]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.],
        [ 1.],
        [-1.],
        [ 1.]], device='cuda:0')
best_l after optimization: -3.30329966545105 with beta sum per layer: [0.5719042420387268, 1.3679876327514648]
alpha/beta optimization time: 0.41858482360839844
In get_candidate_parallel
layer.inputs [<function LiRPAConvNet.transfer_to_cpu.<locals>.<lambda> at 0x7fa3266dde60>]
In get_candidate_parallel
layer.inputs [<function LiRPAConvNet.transfer_to_cpu.<locals>.<lambda> at 0x7fa3266e1440>]
lower_bounds:
 [tensor([[-0.2831, -0.0036,  0.5460],
        [ 0.0000, -0.0036,  0.5460],
        [-0.2831, -0.0036,  0.5460],
        [ 0.0000, -0.0036,  0.5460]]), tensor([[-0.8818,  0.0000, -0.8323,  0.4754, -0.5227],
        [-0.8818,  0.0000, -0.8323,  0.4754, -0.5227],
        [-0.8818, -0.2054, -0.8323,  0.4754, -0.5227],
        [-0.8818, -0.2054, -0.8323,  0.4754, -0.5227]]), tensor([[0.8439],
        [0.8819],
        [0.7714],
        [0.8061]])]
lower_bounds_new shape:
 [torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 1])]
This batch time : update_bounds func: 0.4282	 prepare: 0.0046	 bound: 0.4190	 transfer: 0.0012	 finalize: 0.0034
Accumulated time: update_bounds func: 1.0009	 prepare: 0.0076	 bound: 0.9861	 transfer: 0.0012	 finalize: 0.0052
batch bounding time:  0.4283711910247803
Lower bound of this batch:
[[tensor([[-0.2831, -0.0036,  0.5460]]), tensor([[-0.8818,  0.0000, -0.8323,  0.4754, -0.5227]]), tensor([[0.8439]])], [tensor([[ 0.0000, -0.0036,  0.5460]]), tensor([[-0.8818,  0.0000, -0.8323,  0.4754, -0.5227]]), tensor([[0.8819]])], [tensor([[-0.2831, -0.0036,  0.5460]]), tensor([[-0.8818, -0.2054, -0.8323,  0.4754, -0.5227]]), tensor([[0.7714]])], [tensor([[ 0.0000, -0.0036,  0.5460]]), tensor([[-0.8818, -0.2054, -0.8323,  0.4754, -0.5227]]), tensor([[0.8061]])]]
In Add domain parallel
Before:
SortedList([])
After
SortedList([	
=======ReLUDomain========
	Priority:
	0
	Lower bound:
	0.7713782787322998
	History:
	[[[0], [-1.0]], [[1], [-1.0]]]
	Split History:
	{}
, 	
=======ReLUDomain========
	Priority:
	0
	Lower bound:
	0.8060606122016907
	History:
	[[[0], [1.0]], [[1], [-1.0]]]
	Split History:
	{}
, 	
=======ReLUDomain========
	Priority:
	0
	Lower bound:
	0.8439362049102783
	History:
	[[[0], [-1.0]], [[1], [1.0]]]
	Split History:
	{}
, 	
=======ReLUDomain========
	Priority:
	0
	Lower bound:
	0.8819246292114258
	History:
	[[[0], [1.0]], [[1], [1.0]]]
	Split History:
	{}
])
Current worst splitting domains [lb, ub] (depth):
[0.77138, 99.770798] (2), [0.80606, 99.770798] (2), [0.84394, 99.770798] (2), [0.88192, 99.770798] (2), 
length of domains: 4
Total time: 0.4601	 pickout: 0.0013	 decision: 0.0219	 get_bound: 0.4344	 add_domain: 0.0005
Current lb:0.7713782787322998
6 neurons visited
Global ub: 99.77079772949219, batch ub: inf
Cumulative time: 5.079586029052734

visualizing internal state
BoundRelu()
BoundRelu()
In Pick_out_batch, dfs_percent:0
domains:SortedList([	
=======ReLUDomain========
	Priority:
	0
	Lower bound:
	0.7713782787322998
	History:
	[[[0], [-1.0]], [[1], [-1.0]]]
	Split History:
	{}
, 	
=======ReLUDomain========
	Priority:
	0
	Lower bound:
	0.8060606122016907
	History:
	[[[0], [1.0]], [[1], [-1.0]]]
	Split History:
	{}
, 	
=======ReLUDomain========
	Priority:
	0
	Lower bound:
	0.8439362049102783
	History:
	[[[0], [-1.0]], [[1], [1.0]]]
	Split History:
	{}
, 	
=======ReLUDomain========
	Priority:
	0
	Lower bound:
	0.8819246292114258
	History:
	[[[0], [1.0]], [[1], [1.0]]]
	Split History:
	{}
])
Original mask [tensor([[0., 1., 0.],
        [0., 1., 0.],
        [0., 1., 0.],
        [0., 1., 0.]], device='cuda:0'), tensor([[0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.]], device='cuda:0')]
branching decision [[0, 1], [0, 1], [0, 1], [0, 1]]
splitting decisions: [[0, 1], [0, 1], [0, 1], [0, 1]]
--------------------------
Computing lower bound for
Split:{'decision': [[[0, 1]], [[0, 1]], [[0, 1]], [[0, 1]]], 'coeffs': [[1.0], [1.0], [1.0], [1.0]], 'diving': 0}
Using single node split
BoundRelu()
S matrix location
 tensor([[0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1]], device='cuda:0') torch.Size([8, 2])
S matrix
 tensor([[-1.,  1.],
        [ 1.,  1.],
        [-1.,  1.],
        [ 1.,  1.],
        [-1., -1.],
        [ 1., -1.],
        [-1., -1.],
        [ 1., -1.]]) torch.Size([8, 2])
BoundRelu()
S matrix location
 tensor([[1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0') torch.Size([8, 1])
S matrix
 tensor([[-1.],
        [-1.],
        [ 1.],
        [ 1.],
        [-1.],
        [-1.],
        [ 1.],
        [ 1.]]) torch.Size([8, 1])
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 8, 5])
sparse beta:
 tensor([[0.0000],
        [-0.0000],
        [0.6669],
        [0.7011],
        [0.0000],
        [-0.0000],
        [0.6669],
        [0.7011]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.],
        [-1.],
        [ 1.],
        [ 1.],
        [-1.],
        [-1.],
        [ 1.],
        [ 1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 8, 3])
sparse beta:
 tensor([[0.0000, 0.0000],
        [0.1572, 0.0000],
        [-0.0000, 0.0000],
        [0.4147, 0.0000],
        [0.0000, 0.0000],
        [0.1572, 0.0000],
        [-0.0000, 0.0000],
        [0.4147, 0.0000]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.,  1.],
        [ 1.,  1.],
        [-1.,  1.],
        [ 1.,  1.],
        [-1., -1.],
        [ 1., -1.],
        [-1., -1.],
        [ 1., -1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 8, 5])
sparse beta:
 tensor([[-0.0000],
        [-0.0000],
        [0.6169],
        [0.7511],
        [-0.0000],
        [-0.0000],
        [0.6169],
        [0.7511]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.],
        [-1.],
        [ 1.],
        [ 1.],
        [-1.],
        [-1.],
        [ 1.],
        [ 1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 8, 3])
sparse beta:
 tensor([[-0.0000, -0.0000],
        [0.2072, -0.0000],
        [-0.0000, -0.0000],
        [0.3647, -0.0000],
        [-0.0000, 0.0500],
        [0.2072, 0.0500],
        [-0.0000, 0.0500],
        [0.3647, 0.0500]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.,  1.],
        [ 1.,  1.],
        [-1.,  1.],
        [ 1.,  1.],
        [-1., -1.],
        [ 1., -1.],
        [-1., -1.],
        [ 1., -1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 8, 5])
sparse beta:
 tensor([[-0.0000],
        [-0.0000],
        [0.6511],
        [0.7948],
        [-0.0000],
        [-0.0000],
        [0.6520],
        [0.7948]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.],
        [-1.],
        [ 1.],
        [ 1.],
        [-1.],
        [-1.],
        [ 1.],
        [ 1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 8, 3])
sparse beta:
 tensor([[-0.0000, -0.0000],
        [0.2298, -0.0000],
        [-0.0000, -0.0000],
        [0.3942, -0.0000],
        [-0.0000, 0.0831],
        [0.2298, 0.0990],
        [-0.0000, 0.0819],
        [0.3942, 0.0909]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.,  1.],
        [ 1.,  1.],
        [-1.,  1.],
        [ 1.,  1.],
        [-1., -1.],
        [ 1., -1.],
        [-1., -1.],
        [ 1., -1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 8, 5])
sparse beta:
 tensor([[-0.0000],
        [-0.0000],
        [0.6911],
        [0.8362],
        [-0.0000],
        [-0.0000],
        [0.6925],
        [0.8362]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.],
        [-1.],
        [ 1.],
        [ 1.],
        [-1.],
        [-1.],
        [ 1.],
        [ 1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 8, 3])
sparse beta:
 tensor([[-0.0000, -0.0000],
        [0.2390, -0.0000],
        [-0.0000, -0.0000],
        [0.4317, -0.0000],
        [-0.0000, 0.1083],
        [0.2390, 0.1469],
        [-0.0000, 0.1054],
        [0.4317, 0.1283]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.,  1.],
        [ 1.,  1.],
        [-1.,  1.],
        [ 1.,  1.],
        [-1., -1.],
        [ 1., -1.],
        [-1., -1.],
        [ 1., -1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 8, 5])
sparse beta:
 tensor([[-0.0000],
        [-0.0000],
        [0.7219],
        [0.8676],
        [-0.0000],
        [-0.0000],
        [0.7349],
        [0.8764]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.],
        [-1.],
        [ 1.],
        [ 1.],
        [-1.],
        [-1.],
        [ 1.],
        [ 1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 8, 3])
sparse beta:
 tensor([[-0.0000, -0.0000],
        [0.2397, -0.0000],
        [-0.0000, -0.0000],
        [0.4723, -0.0000],
        [-0.0000, 0.1287],
        [0.2397, 0.1940],
        [-0.0000, 0.1235],
        [0.4720, 0.1640]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.,  1.],
        [ 1.,  1.],
        [-1.,  1.],
        [ 1.,  1.],
        [-1., -1.],
        [ 1., -1.],
        [-1., -1.],
        [ 1., -1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 8, 5])
sparse beta:
 tensor([[-0.0000],
        [-0.0000],
        [0.7462],
        [0.8919],
        [-0.0000],
        [-0.0000],
        [0.7778],
        [0.9157]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.],
        [-1.],
        [ 1.],
        [ 1.],
        [-1.],
        [-1.],
        [ 1.],
        [ 1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 8, 3])
sparse beta:
 tensor([[-0.0000, -0.0000],
        [0.2345, -0.0000],
        [-0.0000, -0.0000],
        [0.5142, -0.0000],
        [-0.0000, 0.1458],
        [0.2345, 0.2400],
        [-0.0000, 0.1379],
        [0.5135, 0.1985]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.,  1.],
        [ 1.,  1.],
        [-1.,  1.],
        [ 1.,  1.],
        [-1., -1.],
        [ 1., -1.],
        [-1., -1.],
        [ 1., -1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 8, 5])
sparse beta:
 tensor([[-0.0000],
        [-0.0000],
        [0.7655],
        [0.9108],
        [-0.0000],
        [-0.0000],
        [0.8193],
        [0.9544]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.],
        [-1.],
        [ 1.],
        [ 1.],
        [-1.],
        [-1.],
        [ 1.],
        [ 1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 8, 3])
sparse beta:
 tensor([[-0.0000, -0.0000],
        [0.2249, -0.0000],
        [-0.0000, -0.0000],
        [0.5566, -0.0000],
        [-0.0000, 0.1604],
        [0.2249, 0.2852],
        [-0.0000, 0.1564],
        [0.5554, 0.2322]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.,  1.],
        [ 1.,  1.],
        [-1.,  1.],
        [ 1.,  1.],
        [-1., -1.],
        [ 1., -1.],
        [-1., -1.],
        [ 1., -1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 8, 5])
sparse beta:
 tensor([[-0.0000],
        [-0.0000],
        [0.7811],
        [0.9352],
        [-0.0000],
        [-0.0000],
        [0.8596],
        [0.9924]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.],
        [-1.],
        [ 1.],
        [ 1.],
        [-1.],
        [-1.],
        [ 1.],
        [ 1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 8, 3])
sparse beta:
 tensor([[-0.0000, -0.0000],
        [0.2120, -0.0000],
        [-0.0000, -0.0000],
        [0.5930, -0.0000],
        [-0.0000, 0.1730],
        [0.2365, 0.3259],
        [-0.0000, 0.1779],
        [0.5972, 0.2652]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.,  1.],
        [ 1.,  1.],
        [-1.,  1.],
        [ 1.,  1.],
        [-1., -1.],
        [ 1., -1.],
        [-1., -1.],
        [ 1., -1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 8, 5])
sparse beta:
 tensor([[-0.0000],
        [-0.0000],
        [0.7934],
        [0.9630],
        [-0.0000],
        [-0.0000],
        [0.8987],
        [1.0298]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.],
        [-1.],
        [ 1.],
        [ 1.],
        [-1.],
        [-1.],
        [ 1.],
        [ 1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 8, 3])
sparse beta:
 tensor([[-0.0000, -0.0000],
        [0.1965, -0.0000],
        [-0.0000, -0.0000],
        [0.6246, -0.0000],
        [-0.0000, 0.1841],
        [0.2574, 0.3632],
        [-0.0000, 0.2015],
        [0.6388, 0.2976]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.,  1.],
        [ 1.,  1.],
        [-1.,  1.],
        [ 1.,  1.],
        [-1., -1.],
        [ 1., -1.],
        [-1., -1.],
        [ 1., -1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 8, 5])
sparse beta:
 tensor([[-0.0000],
        [-0.0000],
        [0.8032],
        [0.9932],
        [-0.0000],
        [-0.0000],
        [0.9370],
        [1.0666]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.],
        [-1.],
        [ 1.],
        [ 1.],
        [-1.],
        [-1.],
        [ 1.],
        [ 1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 8, 3])
sparse beta:
 tensor([[-0.0000, -0.0000],
        [0.1790, -0.0000],
        [-0.0000, -0.0000],
        [0.6522, -0.0000],
        [-0.0000, 0.1938],
        [0.2837, 0.3976],
        [-0.0000, 0.2268],
        [0.6801, 0.3296]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.,  1.],
        [ 1.,  1.],
        [-1.,  1.],
        [ 1.,  1.],
        [-1., -1.],
        [ 1., -1.],
        [-1., -1.],
        [ 1., -1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 8, 5])
sparse beta:
 tensor([[-0.0000],
        [-0.0000],
        [0.8108],
        [1.0250],
        [-0.0000],
        [-0.0000],
        [0.9744],
        [1.1028]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.],
        [-1.],
        [ 1.],
        [ 1.],
        [-1.],
        [-1.],
        [ 1.],
        [ 1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 8, 3])
sparse beta:
 tensor([[-0.0000, -0.0000],
        [0.1598, -0.0000],
        [-0.0000, -0.0000],
        [0.6765, -0.0000],
        [-0.0000, 0.2025],
        [0.3134, 0.4295],
        [-0.0000, 0.2533],
        [0.7208, 0.3610]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.,  1.],
        [ 1.,  1.],
        [-1.,  1.],
        [ 1.,  1.],
        [-1., -1.],
        [ 1., -1.],
        [-1., -1.],
        [ 1., -1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 8, 5])
sparse beta:
 tensor([[-0.0000],
        [-0.0000],
        [0.8166],
        [1.0579],
        [-0.0000],
        [-0.0000],
        [1.0110],
        [1.1385]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.],
        [-1.],
        [ 1.],
        [ 1.],
        [-1.],
        [-1.],
        [ 1.],
        [ 1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 8, 3])
sparse beta:
 tensor([[-0.0000, -0.0000],
        [0.1394, -0.0000],
        [-0.0000, -0.0000],
        [0.6979, -0.0000],
        [-0.0000, 0.2102],
        [0.3454, 0.4595],
        [-0.0000, 0.2806],
        [0.7609, 0.3921]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.,  1.],
        [ 1.,  1.],
        [-1.,  1.],
        [ 1.,  1.],
        [-1., -1.],
        [ 1., -1.],
        [-1., -1.],
        [ 1., -1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 8, 5])
sparse beta:
 tensor([[-0.0000],
        [-0.0000],
        [0.8207],
        [1.0913],
        [-0.0000],
        [-0.0000],
        [1.0469],
        [1.1736]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.],
        [-1.],
        [ 1.],
        [ 1.],
        [-1.],
        [-1.],
        [ 1.],
        [ 1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 8, 3])
sparse beta:
 tensor([[-0.0000, -0.0000],
        [0.1370, -0.0000],
        [-0.0000, -0.0000],
        [0.7169, -0.0000],
        [-0.0000, 0.2171],
        [0.3788, 0.4877],
        [-0.0000, 0.3086],
        [0.8005, 0.4227]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.,  1.],
        [ 1.,  1.],
        [-1.,  1.],
        [ 1.,  1.],
        [-1., -1.],
        [ 1., -1.],
        [-1., -1.],
        [ 1., -1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 8, 5])
sparse beta:
 tensor([[-0.0000],
        [-0.0000],
        [0.8235],
        [1.1252],
        [-0.0000],
        [-0.0000],
        [1.0820],
        [1.2082]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.],
        [-1.],
        [ 1.],
        [ 1.],
        [-1.],
        [-1.],
        [ 1.],
        [ 1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 8, 3])
sparse beta:
 tensor([[-0.0000, -0.0000],
        [0.1451, -0.0000],
        [-0.0000, -0.0000],
        [0.7339, -0.0000],
        [-0.0000, 0.2234],
        [0.4131, 0.5144],
        [-0.0000, 0.3371],
        [0.8394, 0.4528]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.,  1.],
        [ 1.,  1.],
        [-1.,  1.],
        [ 1.,  1.],
        [-1., -1.],
        [ 1., -1.],
        [-1., -1.],
        [ 1., -1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 8, 5])
sparse beta:
 tensor([[-0.0000],
        [-0.0000],
        [0.8251],
        [1.1593],
        [-0.0000],
        [-0.0000],
        [1.1164],
        [1.2421]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.],
        [-1.],
        [ 1.],
        [ 1.],
        [-1.],
        [-1.],
        [ 1.],
        [ 1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 8, 3])
sparse beta:
 tensor([[-0.0000, -0.0000],
        [0.1601, -0.0000],
        [-0.0000, -0.0000],
        [0.7490, -0.0000],
        [-0.0000, 0.2290],
        [0.4480, 0.5398],
        [-0.0000, 0.3658],
        [0.8777, 0.4826]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.,  1.],
        [ 1.,  1.],
        [-1.,  1.],
        [ 1.,  1.],
        [-1., -1.],
        [ 1., -1.],
        [-1., -1.],
        [ 1., -1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 8, 5])
sparse beta:
 tensor([[-0.0000],
        [-0.0000],
        [0.8256],
        [1.1933],
        [-0.0000],
        [-0.0000],
        [1.1502],
        [1.2756]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.],
        [-1.],
        [ 1.],
        [ 1.],
        [-1.],
        [-1.],
        [ 1.],
        [ 1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 8, 3])
sparse beta:
 tensor([[-0.0000, -0.0000],
        [0.1711, -0.0000],
        [-0.0000, -0.0000],
        [0.7625, -0.0000],
        [-0.0000, 0.2341],
        [0.4832, 0.5641],
        [-0.0000, 0.3946],
        [0.9153, 0.5119]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.,  1.],
        [ 1.,  1.],
        [-1.,  1.],
        [ 1.,  1.],
        [-1., -1.],
        [ 1., -1.],
        [-1., -1.],
        [ 1., -1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 8, 5])
sparse beta:
 tensor([[-0.0000],
        [-0.0000],
        [0.8253],
        [1.2273],
        [-0.0000],
        [-0.0000],
        [1.1834],
        [1.3084]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.],
        [-1.],
        [ 1.],
        [ 1.],
        [-1.],
        [-1.],
        [ 1.],
        [ 1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 8, 3])
sparse beta:
 tensor([[-0.0000, -0.0000],
        [0.1787, -0.0000],
        [-0.0000, -0.0000],
        [0.7746, -0.0000],
        [-0.0000, 0.2388],
        [0.5185, 0.5873],
        [-0.0000, 0.4236],
        [0.9522, 0.5408]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.,  1.],
        [ 1.,  1.],
        [-1.,  1.],
        [ 1.,  1.],
        [-1., -1.],
        [ 1., -1.],
        [-1., -1.],
        [ 1., -1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 8, 5])
sparse beta:
 tensor([[-0.0000],
        [-0.0000],
        [0.8241],
        [1.2569],
        [-0.0000],
        [-0.0000],
        [1.2159],
        [1.3407]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.],
        [-1.],
        [ 1.],
        [ 1.],
        [-1.],
        [-1.],
        [ 1.],
        [ 1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 8, 3])
sparse beta:
 tensor([[-0.0000, -0.0000],
        [0.1832, -0.0000],
        [-0.0000, -0.0000],
        [0.7921, -0.0000],
        [-0.0000, 0.2430],
        [0.5537, 0.6096],
        [-0.0000, 0.4524],
        [0.9885, 0.5693]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.,  1.],
        [ 1.,  1.],
        [-1.,  1.],
        [ 1.,  1.],
        [-1., -1.],
        [ 1., -1.],
        [-1., -1.],
        [ 1., -1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 8, 5])
sparse beta:
 tensor([[-0.0000],
        [-0.0000],
        [0.8223],
        [1.2825],
        [-0.0000],
        [-0.0000],
        [1.2490],
        [1.3725]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.],
        [-1.],
        [ 1.],
        [ 1.],
        [-1.],
        [-1.],
        [ 1.],
        [ 1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 8, 3])
sparse beta:
 tensor([[-0.0000, -0.0000],
        [0.1852, -0.0000],
        [-0.0000, -0.0000],
        [0.8133, -0.0000],
        [-0.0000, 0.2469],
        [0.5887, 0.6311],
        [-0.0000, 0.4778],
        [1.0241, 0.5974]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.,  1.],
        [ 1.,  1.],
        [-1.,  1.],
        [ 1.,  1.],
        [-1., -1.],
        [ 1., -1.],
        [-1., -1.],
        [ 1., -1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 8, 5])
sparse beta:
 tensor([[-0.0000],
        [-0.0000],
        [0.8198],
        [1.3047],
        [-0.0000],
        [-0.0000],
        [1.2826],
        [1.4037]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.],
        [-1.],
        [ 1.],
        [ 1.],
        [-1.],
        [-1.],
        [ 1.],
        [ 1.]], device='cuda:0')
Somewhere deep inside bound_backward...
A.shape torch.Size([1, 8, 3])
sparse beta:
 tensor([[-0.0000, -0.0000],
        [0.1850, -0.0000],
        [-0.0000, -0.0000],
        [0.8374, -0.0000],
        [-0.0000, 0.2505],
        [0.6234, 0.6519],
        [-0.0000, 0.5002],
        [1.0590, 0.6251]], device='cuda:0', requires_grad=True)
sparse beta sign
 tensor([[-1.,  1.],
        [ 1.,  1.],
        [-1.,  1.],
        [ 1.,  1.],
        [-1., -1.],
        [ 1., -1.],
        [-1., -1.],
        [ 1., -1.]], device='cuda:0')
best_l after optimization: -6.909817218780518 with beta sum per layer: [4.704623699188232, 4.6578474044799805]
alpha/beta optimization time: 0.4642140865325928
In get_candidate_parallel
layer.inputs [<function LiRPAConvNet.transfer_to_cpu.<locals>.<lambda> at 0x7fa3266dd9e0>]
In get_candidate_parallel
layer.inputs [<function LiRPAConvNet.transfer_to_cpu.<locals>.<lambda> at 0x7fa3266dd7a0>]
lower_bounds:
 [tensor([[-0.2831,  0.0000,  0.5460],
        [ 0.0000,  0.0000,  0.5460],
        [-0.2831,  0.0000,  0.5460],
        [ 0.0000,  0.0000,  0.5460],
        [-0.2831, -0.0036,  0.5460],
        [ 0.0000, -0.0036,  0.5460],
        [-0.2831, -0.0036,  0.5460],
        [ 0.0000, -0.0036,  0.5460]]), tensor([[-0.8818, -0.2054, -0.8323,  0.4754, -0.5227],
        [-0.8818, -0.2054, -0.8323,  0.4754, -0.5227],
        [-0.8818,  0.0000, -0.8323,  0.4754, -0.5227],
        [-0.8818,  0.0000, -0.8323,  0.4754, -0.5227],
        [-0.8818, -0.2054, -0.8323,  0.4754, -0.5227],
        [-0.8818, -0.2054, -0.8323,  0.4754, -0.5227],
        [-0.8818,  0.0000, -0.8323,  0.4754, -0.5227],
        [-0.8818,  0.0000, -0.8323,  0.4754, -0.5227]]), tensor([[0.7714],
        [0.8061],
        [0.8439],
        [0.9263],
        [0.7738],
        [0.8993],
        [0.8952],
        [0.9938]])]
lower_bounds_new shape:
 [torch.Size([8, 3]), torch.Size([8, 5]), torch.Size([8, 1])]
This batch time : update_bounds func: 0.4740	 prepare: 0.0062	 bound: 0.4645	 transfer: 0.0005	 finalize: 0.0027
Accumulated time: update_bounds func: 1.4749	 prepare: 0.0138	 bound: 1.4507	 transfer: 0.0005	 finalize: 0.0079
batch bounding time:  0.47414708137512207
Lower bound of this batch:
[[tensor([[-0.2831,  0.0000,  0.5460]]), tensor([[-0.8818, -0.2054, -0.8323,  0.4754, -0.5227]]), tensor([[0.7714]])], [tensor([[0.0000, 0.0000, 0.5460]]), tensor([[-0.8818, -0.2054, -0.8323,  0.4754, -0.5227]]), tensor([[0.8061]])], [tensor([[-0.2831,  0.0000,  0.5460]]), tensor([[-0.8818,  0.0000, -0.8323,  0.4754, -0.5227]]), tensor([[0.8439]])], [tensor([[0.0000, 0.0000, 0.5460]]), tensor([[-0.8818,  0.0000, -0.8323,  0.4754, -0.5227]]), tensor([[0.9263]])], [tensor([[-0.2831, -0.0036,  0.5460]]), tensor([[-0.8818, -0.2054, -0.8323,  0.4754, -0.5227]]), tensor([[0.7738]])], [tensor([[ 0.0000, -0.0036,  0.5460]]), tensor([[-0.8818, -0.2054, -0.8323,  0.4754, -0.5227]]), tensor([[0.8993]])], [tensor([[-0.2831, -0.0036,  0.5460]]), tensor([[-0.8818,  0.0000, -0.8323,  0.4754, -0.5227]]), tensor([[0.8952]])], [tensor([[ 0.0000, -0.0036,  0.5460]]), tensor([[-0.8818,  0.0000, -0.8323,  0.4754, -0.5227]]), tensor([[0.9938]])]]
In Add domain parallel
Before:
SortedList([])
After
SortedList([	
=======ReLUDomain========
	Priority:
	0
	Lower bound:
	0.7713782787322998
	History:
	[[[0, 1], [-1.0, 1.0]], [[1], [-1.0]]]
	Split History:
	{}
, 	
=======ReLUDomain========
	Priority:
	0
	Lower bound:
	0.7738372683525085
	History:
	[[[0, 1], [-1.0, -1.0]], [[1], [-1.0]]]
	Split History:
	{}
, 	
=======ReLUDomain========
	Priority:
	0
	Lower bound:
	0.8060606122016907
	History:
	[[[0, 1], [1.0, 1.0]], [[1], [-1.0]]]
	Split History:
	{}
, 	
=======ReLUDomain========
	Priority:
	0
	Lower bound:
	0.8439362049102783
	History:
	[[[0, 1], [-1.0, 1.0]], [[1], [1.0]]]
	Split History:
	{}
, 	
=======ReLUDomain========
	Priority:
	0
	Lower bound:
	0.8951930999755859
	History:
	[[[0, 1], [-1.0, -1.0]], [[1], [1.0]]]
	Split History:
	{}
, 	
=======ReLUDomain========
	Priority:
	0
	Lower bound:
	0.8993397951126099
	History:
	[[[0, 1], [1.0, -1.0]], [[1], [-1.0]]]
	Split History:
	{}
, 	
=======ReLUDomain========
	Priority:
	0
	Lower bound:
	0.9262502193450928
	History:
	[[[0, 1], [1.0, 1.0]], [[1], [1.0]]]
	Split History:
	{}
, 	
=======ReLUDomain========
	Priority:
	0
	Lower bound:
	0.9938217401504517
	History:
	[[[0, 1], [1.0, -1.0]], [[1], [1.0]]]
	Split History:
	{}
])
Current worst splitting domains [lb, ub] (depth):
[0.77138, 99.770798] (3), [0.77384, 99.770798] (3), [0.80606, 99.770798] (3), [0.84394, 99.770798] (3), [0.89519, 99.770798] (3), [0.89934, 99.770798] (3), [0.92625, 99.770798] (3), [0.99382, 99.770798] (3), 
length of domains: 8
Total time: 0.5114	 pickout: 0.0020	 decision: 0.0240	 get_bound: 0.4822	 add_domain: 0.0005
Current lb:0.7713782787322998
14 neurons visited
Global ub: 99.77079772949219, batch ub: inf
Cumulative time: 5.591143369674683

visualizing internal state
BoundRelu()
BoundRelu()
In Pick_out_batch, dfs_percent:0
domains:SortedList([	
=======ReLUDomain========
	Priority:
	0
	Lower bound:
	0.7713782787322998
	History:
	[[[0, 1], [-1.0, 1.0]], [[1], [-1.0]]]
	Split History:
	{}
, 	
=======ReLUDomain========
	Priority:
	0
	Lower bound:
	0.7738372683525085
	History:
	[[[0, 1], [-1.0, -1.0]], [[1], [-1.0]]]
	Split History:
	{}
, 	
=======ReLUDomain========
	Priority:
	0
	Lower bound:
	0.8060606122016907
	History:
	[[[0, 1], [1.0, 1.0]], [[1], [-1.0]]]
	Split History:
	{}
, 	
=======ReLUDomain========
	Priority:
	0
	Lower bound:
	0.8439362049102783
	History:
	[[[0, 1], [-1.0, 1.0]], [[1], [1.0]]]
	Split History:
	{}
, 	
=======ReLUDomain========
	Priority:
	0
	Lower bound:
	0.8951930999755859
	History:
	[[[0, 1], [-1.0, -1.0]], [[1], [1.0]]]
	Split History:
	{}
, 	
=======ReLUDomain========
	Priority:
	0
	Lower bound:
	0.8993397951126099
	History:
	[[[0, 1], [1.0, -1.0]], [[1], [-1.0]]]
	Split History:
	{}
, 	
=======ReLUDomain========
	Priority:
	0
	Lower bound:
	0.9262502193450928
	History:
	[[[0, 1], [1.0, 1.0]], [[1], [1.0]]]
	Split History:
	{}
, 	
=======ReLUDomain========
	Priority:
	0
	Lower bound:
	0.9938217401504517
	History:
	[[[0, 1], [1.0, -1.0]], [[1], [1.0]]]
	Split History:
	{}
])
Original mask [tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0'), tensor([[0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.]], device='cuda:0')]
Random branching decision used for example [0, 1, 2, 3, 4, 5, 6, 7]
branching decision []
all nodes are split!!
Global ub: 99.77079772949219, batch ub: inf
(0.7713782787322998, 99.77079772949219, [[4.018354177474976, 0.7707942128181458]], 14)
