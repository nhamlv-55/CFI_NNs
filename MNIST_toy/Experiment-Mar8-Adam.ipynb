{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import FeedforwardNeuralNetModel, TinyCNN, PatternClassifier\n",
    "import regularizer_losts as rl\n",
    "from torchvision import datasets, transforms\n",
    "from torch import optim\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import utils as CFI_utils\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "#from frozendict import frozendict\n",
    "from datetime import datetime\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "colors = sns.color_palette(\"tab10\")\n",
    "\n",
    "#Logging stuffs\n",
    "import logging\n",
    "import sys\n",
    "# Create logger\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Create STDERR handler\n",
    "handler = logging.StreamHandler(sys.stderr)\n",
    "# ch.setLevel(logging.DEBUG)\n",
    "\n",
    "# Create formatter and add it to the handler\n",
    "formatter = logging.Formatter('%(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "\n",
    "# Set STDERR handler as the only handler \n",
    "logger.handlers = [handler]\n",
    "\n",
    "\n",
    "#configs\n",
    "epochs = 10\n",
    "batch_size = 1000\n",
    "test_batch_size = 10000\n",
    "stable_batch_size = 60000\n",
    "use_cuda = True\n",
    "lr = 0.01\n",
    "log_interval = 100\n",
    "\n",
    "\n",
    "#torch specific configs\n",
    "torch.manual_seed(1)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "train_kwargs = {'batch_size': batch_size}\n",
    "\n",
    "test_kwargs = {'batch_size': test_batch_size}\n",
    "stable_kwargs = {'batch_size': stable_batch_size}\n",
    "\n",
    "if use_cuda:\n",
    "    cuda_kwargs = {'num_workers': 1,\n",
    "                   'pin_memory': True,\n",
    "                   'shuffle': True}\n",
    "    train_kwargs.update(cuda_kwargs)\n",
    "    test_kwargs.update(cuda_kwargs)\n",
    "    stable_kwargs.update(cuda_kwargs)\n",
    "class Shift:\n",
    "    def __init__(self, shift = 0):\n",
    "        print(\"alive\")\n",
    "        self.shift = shift\n",
    "\n",
    "    def __call__(self, arr):\n",
    "        print(\"running\")\n",
    "        #print(arr)\n",
    "        return arr\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}()\"\n",
    "\n",
    "class Rescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks = sample['image'], sample['landmarks']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "\n",
    "        img = transform.resize(image, (new_h, new_w))\n",
    "\n",
    "        # h and w are swapped for landmarks because for images,\n",
    "        # x and y axes are axis 1 and 0 respectively\n",
    "        landmarks = landmarks * [new_w / w, new_h / h]\n",
    "\n",
    "        return {'image': img, 'landmarks': landmarks}\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "   \n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "   \n",
    "  \n",
    "])\n",
    "\n",
    "def shift_and_roll(arr : torch.Tensor, x : int , y : int) -> torch.Tensor:\n",
    "    return torch.roll(arr, shifts = (x,y), dims = (0,1)) #indexing\n",
    "def shift(arr : torch.Tensor, x : int , y : int) -> torch.Tensor:\n",
    "\n",
    "    pad = [0,0,0,0]\n",
    "    x_start = 0\n",
    "    x_end = 0\n",
    "    y_start = 0\n",
    "    y_end = 0\n",
    "    if x >= 0:\n",
    "        pad[0] = x\n",
    "        x_start = 0\n",
    "        x_end = 28\n",
    "    else:\n",
    "         pad[1] = abs(x)\n",
    "         x_start = -28\n",
    "         \n",
    "         \n",
    "        \n",
    "         \n",
    "    \n",
    "    if y >= 0:\n",
    "        pad[2] = y\n",
    "        y_start = 0\n",
    "        y_end = 28\n",
    "    else:\n",
    "        pad[3] = abs(y)\n",
    "        y_start= -28\n",
    "        print(\"ys is {}\".format(y_start))\n",
    "    \n",
    "\n",
    "    padder = torch.nn.ZeroPad2d(tuple(pad))\n",
    "  \n",
    "    result = padder(arr)\n",
    "\n",
    "    if y < 0:\n",
    "        y_end = result.shape[0]\n",
    "    if x < 0:\n",
    "        x_end = result.shape[1]\n",
    "    \n",
    "    return result[y_start:y_end, x_start:x_end]\n",
    "\n",
    "def noisify(arr : torch.Tensor , distribution : torch.distributions.Distribution) -> torch.Tensor: #randomly add noise\n",
    "   \n",
    "    #print(distribution.sample(arr.size()).shape\\\\)\n",
    "    #print(torch.reshape(distribution.sample(arr.size()), (28,28)).shape)\n",
    "   \n",
    "    noise = torch.reshape(distribution.sample(arr.size()), (arr.shape))\n",
    "    return arr + noise\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "   \n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dataset(dataset):\n",
    "    '''\n",
    "    DO A STATE CHANGE\n",
    "    '''\n",
    "    shift_x = 1\n",
    "    shift_y = 0\n",
    "    mu = 1\n",
    "    sigma = 1\n",
    "    do_shift = False\n",
    "    do_noisfy = True\n",
    "    modification_string = \"base\"\n",
    "    if do_shift:\n",
    "        modification_string += \" -shift {} {} - \".format(shift_x, shift_y)\n",
    "    if do_noisfy:\n",
    "        modification_string += \" -noise added using gaussian using mean {} and stddev {}- \".format(mu, sigma)\n",
    "    for i in range(dataset.data.shape[0]):\n",
    "        if do_shift:\n",
    "            dataset.data[i,:,:] = shift(dataset.data[i,:,:],shift_x, shift_y)\n",
    "        \n",
    "        if do_noisfy:\n",
    "            gaussian = torch.distributions.Normal(loc = mu, scale = sigma)# loc = mu, scale = stddev\n",
    "\n",
    "            dataset.data[i,:,:] = noisify(dataset.data[i,:,:], gaussian)\n",
    "    return modification_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "### Big question: CFI for NN\n",
    "\n",
    "\n",
    "Are we doing complete verification or fuzzing/testing?\n",
    "\n",
    "What is a `CFI`?\n",
    "\n",
    "# What is a good abstraction for a NN's structure? Can it be enforced through regularization?\n",
    "- Distillation? (https://arxiv.org/pdf/1503.02531.pdf)\n",
    "- Decision Tree? (https://arxiv.org/pdf/1711.09784.pdf)\n",
    "- Model Extraction? (https://arxiv.org/pdf/2003.04884.pdf)\n",
    "\n",
    "\n",
    "### Where are we?\n",
    "We want to do CFI for NN\n",
    "\n",
    "## Question: Do we want to verify each AP separately? Or we want to tell the difference between activation patterns of real images from fake one using a method M and verify M?\n",
    "\n",
    "\n",
    "\n",
    "## Option 1: We want to verify each AP separately (we are here)\n",
    "To be able to do so, we need\n",
    "\n",
    "### Condition 1: The number of activation patterns for a neural networks has to be way smaller than the size of the training/test set.\n",
    "#### Why: \n",
    "\n",
    "  If every input results in a different AP, given an AP, very likely during infer time every input will have its own AP, so we have to reject it\n",
    "\n",
    "  We want to verify each AP separately, so smaller the number the better\n",
    "\n",
    "#### Progress: \n",
    "\n",
    "  with the current regularization effort, we have been able to reduce the number of AP to about 20k for 60k input.\n",
    "\n",
    "#### Aim: \n",
    "\n",
    "Reduce to about few hundreds\n",
    "\n",
    "#### Tricky part: \n",
    "\n",
    "Given a network of N layers, we can limit the number of activation patterns by only looking at k < N layers. Question: which k? \n",
    "\n",
    "### Condition 2: All, or most, of the activation patterns of the test set has to be covered by the AP of the training set\n",
    "#### Why: \n",
    "If the activation patterns in the test set are completely different from the training set, there would be too many false negative at the inferencing time\n",
    "#### Progress: \n",
    "Possible, but with a big caveat: the fake AP is now also included in the set\n",
    "\n",
    "### Condition 3: Given an adv exp, its AP cannot be in the training AP set.\n",
    "#### Progress:\n",
    "Currently, if Cond.2 is satisfied, then 3 is not.\n",
    "\n",
    "\n",
    "## Option 2: Train the network s.t the fake AP and real AP can be separated by some methods (linear classifier or a small neural net)\n",
    "\n",
    "## What are the state-of-the-art attacks and defences?\n",
    "\n",
    "\n",
    "## Backlog RQs: \n",
    "- BRQ1: Can we look at a random k entries in the weight instead of the first k?\n",
    "- BRQ2: What if we set all the small abs weight in the Pattern classifer to 0? what is the accuracy in that case?\n",
    "- BRQ4: Given a simple attacking method (e.g, Fast gradient sign), build a dataset of activation maps of true and fake digits. Try to train a pattern classifier using that dataset.\n",
    "- __BRQ5: Given a target and its corresponding adv. exp, can we gradually move in the in-between space to see at which point the label is changed?__\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -accuracy 0.9042-\n"
     ]
    }
   ],
   "source": [
    "def check_gradient(grad, label, last_sorted_grads, plot = False):\n",
    "    logging.info(\"CHECKING GRADIENT FOR LABEL {}\".format(label))\n",
    "    sum_abs_grad = np.sum(abs(grad[label]), axis = 0)\n",
    "    \n",
    "    current_sorted_grad = (-sum_abs_grad).argsort()\n",
    "    \n",
    "#     if len(last_sorted_grads[label]) > 0:\n",
    "#         for k in [100, 200, 300, 400]:\n",
    "#             prev_top_k = set(last_sorted_grads[label][-1][:k])\n",
    "#             current_top_k = set(current_sorted_grad[:k])\n",
    "#             intersect = prev_top_k.intersection(current_top_k)\n",
    "#             logging.info('k = {}. How many top Gradients are stable since last epoch?: {}'.format(k, len(intersect)))\n",
    "        \n",
    "    for k in [0, 9, 99, 199]:    \n",
    "        logging.debug('{}th biggest gradient = {}'.format(k, np.sort(-sum_abs_grad)[k]))\n",
    "    if plot:\n",
    "        fig = plt.figure(figsize=(30, 1))\n",
    "        plt.bar(range(sum_abs_grad.shape[0]), sum_abs_grad)\n",
    "        plt.show()\n",
    "        print(sum_abs_grad.max(), sum_abs_grad.argmax(), sum_abs_grad.min())\n",
    "\n",
    "    return current_sorted_grad\n",
    "\n",
    "\n",
    "\n",
    "#init stuffs\n",
    "LOAD = True\n",
    "# LOADPATH = 'TinyCNNreg.conv1.conv2.fc1.fc2.17:09:00'\n",
    "# LOADPATH = 'FFN18:28:21'\n",
    "LOADPATH = 'FFN18_28_21'\n",
    "# LOADPATH = 'TinyCNNreg.fc1.fc2.16:06:26'\n",
    "LAST_N_EPOCHS = 10\n",
    "\n",
    "dataset1 = datasets.MNIST('../data', train=True, download=True,\n",
    "                          transform=transform)\n",
    "dataset2 = datasets.MNIST('../data', train=False,\n",
    "                          transform=transform)\n",
    "\n",
    "\n",
    "#transform_dataset(dataset1)\n",
    "#modification_string = transform_dataset(dataset2)\n",
    "modification_string = \"\"\n",
    "train_loader = torch.utils.data.DataLoader(dataset1, **train_kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
    "\n",
    "model = FeedforwardNeuralNetModel(28*28, 128, 10).to(device)\n",
    "# model = TinyCNN().to(device)\n",
    "if LOAD:\n",
    "    model.load_state_dict(torch.load(LOADPATH))\n",
    "else:\n",
    "\n",
    "    epochs = 10\n",
    "    optimizer = optim.Adadelta(model.parameters(), lr=lr)\n",
    "\n",
    "    scheduler = StepLR(optimizer, step_size=1, gamma = 0.7)\n",
    "    last_sorted_grads = defaultdict(list)\n",
    "    \n",
    "    all_rows = []\n",
    "    \n",
    "    for epoch in tqdm(range(1, epochs + 1)):\n",
    "        model.register_gradient()\n",
    "        model.train()\n",
    "        target_log  = None # need to record the label to match with the gradient later\n",
    "        for data, target in train_loader:\n",
    "            target_log = np.concatenate((target_log, target), axis = 0) if target_log is not None else target\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data.float())\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        CFI_utils.test(model, device, test_loader)\n",
    "#         scheduler.step()\n",
    "        grad = CFI_utils.get_grad_each_label(model.gradient_log, \n",
    "                                      target_log = target_log, \n",
    "                                      layers = ['fc1', 'fc2', 'fc3', 'fc4'], \n",
    "                                      labels = range(10))\n",
    "        torch.save(model.state_dict(), model.model_savename())\n",
    "        \n",
    "        row_data = []\n",
    "        for label in range(10):\n",
    "            r = []\n",
    "            logging.info(\"After {} epoch:\".format(epoch))\n",
    "            last_sorted_grads[label].append(check_gradient(grad, label, last_sorted_grads))\n",
    "            \n",
    "            \n",
    "            if epoch >= LAST_N_EPOCHS:\n",
    "                for k in [100, 200, 300, 400]:\n",
    "                    all_top_k = [set(sorted_grad[:k]) for sorted_grad in last_sorted_grads[label][-LAST_N_EPOCHS:]]\n",
    "                    intersect = set.intersection(*all_top_k)\n",
    "                    logging.info('k = {}. How many top Gradients are stable among all last {} epochs?: {}'.format(k, LAST_N_EPOCHS, len(intersect)))\n",
    "with torch.no_grad():\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for data, target in dataset2:\n",
    "        if int(torch.argmax(model.cuda()(data.cuda()), dim = 1)) == target:\n",
    "            correct += 1\n",
    "        total+=1\n",
    "    \"accuracy {}\".format( correct/total)\n",
    "    modification_string += \" -accuracy {}-\".format( correct/total)\n",
    "    print(modification_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study stable gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute all patterns in the training set, and put them into corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "root - INFO - (5923, 458)\n",
      "root - INFO - (6742, 458)\n",
      "root - INFO - (5958, 458)\n",
      "root - INFO - (6131, 458)\n",
      "root - INFO - (5842, 458)\n",
      "root - INFO - (5421, 458)\n",
      "root - INFO - (5918, 458)\n",
      "root - INFO - (6265, 458)\n",
      "root - INFO - (5851, 458)\n",
      "root - INFO - (5949, 458)\n",
      "root - INFO - (980, 458)\n",
      "root - INFO - (1135, 458)\n",
      "root - INFO - (1032, 458)\n",
      "root - INFO - (1010, 458)\n",
      "root - INFO - (982, 458)\n",
      "root - INFO - (892, 458)\n",
      "root - INFO - (958, 458)\n",
      "root - INFO - (1028, 458)\n",
      "root - INFO - (974, 458)\n",
      "root - INFO - (1009, 458)\n"
     ]
    }
   ],
   "source": [
    "class Patterns:\n",
    "    def __init__(self, model: torch.nn.Module, dataloader: torch.utils.data.DataLoader, labels, layers):\n",
    "        self._model = model\n",
    "        self.label2patterns = {}\n",
    "        self.label2idx = {}\n",
    "        self._labels = labels\n",
    "        self._layers = layers\n",
    "        self._dataloader = dataloader\n",
    "        self._populate()\n",
    "        \n",
    "    def _populate(self):\n",
    "        \n",
    "        label2patterns = {}\n",
    "        label2idx = {}\n",
    "        for label in self._labels:\n",
    "            patterns = []\n",
    "            filter_ids = []\n",
    "            \n",
    "            for data, target in self._dataloader:\n",
    "                \n",
    "                flter = np.where(target == label)\n",
    "                filter_ids.append(flter)\n",
    "                data = data[flter]\n",
    "                logging.debug(data.shape[0])\n",
    "                pattern = self._model.get_pattern(data, layers, device, flatten = True)\n",
    "                logging.debug(pattern.shape)\n",
    "                patterns.append(pattern)\n",
    "\n",
    "            patterns = np.squeeze(np.concatenate(patterns, axis = 0))\n",
    "            filter_ids = np.squeeze(np.concatenate(filter_ids, axis = 0))\n",
    "            label2patterns[label] = patterns\n",
    "            label2idx[label] = filter_ids\n",
    "            \n",
    "            logging.info(patterns.shape)\n",
    "        \n",
    "        #freeze\n",
    "        self.label2patterns = dict(label2patterns)\n",
    "        self.label2idx = dict(label2idx)\n",
    "        \n",
    "    def apply_filter(self, f):\n",
    "        pass\n",
    "    \n",
    "    def unique():\n",
    "        pass\n",
    "    \n",
    "    def query_pattern():\n",
    "        pass\n",
    "\n",
    "\n",
    "layers = ['fc1', 'fc2', 'fc3', 'fc4']\n",
    "labels = range(10)\n",
    "K = 25\n",
    "stable_loader = torch.utils.data.DataLoader(dataset1, **stable_kwargs)\n",
    "\n",
    "all_patterns = Patterns(model = model,\n",
    "                        dataloader = stable_loader,\n",
    "                        labels = labels,\n",
    "                        layers = layers)\n",
    "all_test_patterns = Patterns(model = model,\n",
    "                        dataloader = test_loader,\n",
    "                        labels = labels,\n",
    "                        layers = layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5923,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_patterns.label2idx[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can only study gradient if the model is trained\n",
    "# FIXME: should save gradient into a pickle as well\n",
    "if not LOAD:\n",
    "    for K in [25, 50, 100]:\n",
    "        print(\"K=\", K)\n",
    "        row = []\n",
    "        row.append(str(K))\n",
    "        for label in labels:\n",
    "            #construct the stable gradients \n",
    "            all_top_k = [set(sorted_grad[:K]) for sorted_grad in last_sorted_grads[label][-LAST_N_EPOCHS:]]\n",
    "            intersect = set.intersection(*all_top_k)\n",
    "            stable_grad = np.array(sorted(list(intersect)))\n",
    "            print(\"There are {} stable grad in top K\".format(len(stable_grad)))\n",
    "            print(stable_grad)\n",
    "\n",
    "            logging.info(all_patterns[label].shape)\n",
    "            print(\"LABEL:\", label)\n",
    "            print(\"how many unique paths in the full pattern?\", np.unique(all_patterns[label], axis = 0).shape)\n",
    "            print(\"how many unique paths in the filtered pattern?\", np.unique(all_patterns[label][:, stable_grad ], axis = 0).shape)\n",
    "            print(\"how many unique paths in the randomly filtered pattern?\", \n",
    "                  np.unique(patterns[:, \n",
    "                                     np.random.choice(458, len(stable_grad), replace = False) ], axis = 0).shape)\n",
    "            row.append(\"|\".join([str(len(stable_grad)),\n",
    "                                 str(np.unique(all_patterns[label], axis = 0).shape[0]),\n",
    "                                 str(np.unique(all_patterns[label][:, stable_grad ], axis = 0).shape[0]),\n",
    "                                 str(np.unique(all_patterns[label][:, np.random.choice(458, len(stable_grad), replace = False) ], axis = 0).shape[0])\n",
    "                                ]))\n",
    "        all_rows.append(\",\".join(row)+\"\\n\")\n",
    "\n",
    "    with open(\"gradient_exp_log_2.csv\", \"w\") as f:\n",
    "        f.write(\"K,\"+\",\".join([str(l) for l in labels]) + \"\\n\")\n",
    "        f.writelines(all_rows)\n",
    "\n",
    "                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study stable ReLUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5923, 458)\n",
      "threshold:  0.5923 5922.4077\n",
      "relu_sum, prediction [5685    0   29   15   11   77   48   11   43    4]\n",
      "non active neurons:  (array([257, 267, 288, 338, 343, 374, 375, 392, 401, 403, 414, 418, 449],\n",
      "      dtype=int64),)\n",
      "active neurons:  (array([ 19,  70, 142, 238, 258, 259, 260, 265, 275, 285, 287, 295, 302,\n",
      "       307, 323, 329, 339, 340, 346, 347, 349, 352, 360, 365, 369, 380,\n",
      "       396, 406, 417, 420, 423, 424, 426, 429, 434], dtype=int64),)\n",
      "WARN: neuro_idx = 448 for label 0 is not stable, let's include it anyway\n",
      "\n",
      "Label is  0\n",
      "Stable ReLUs [19, 70, 142, 238, 257, 258, 259, 260, 265, 267, 275, 285, 287, 288, 295, 302, 307, 323, 329, 338, 339, 340, 343, 346, 347, 349, 352, 360, 365, 369, 374, 375, 380, 392, 396, 401, 403, 406, 414, 417, 418, 420, 423, 424, 426, 429, 434, 448, 449]\n",
      "how many unique paths in the filtered pattern? (2, 49)\n",
      "their freq\n",
      " [ 238 5685] (2,)\n",
      "primary pattern coverage:  0.95981765996961\n",
      "(6742, 458)\n",
      "threshold:  0.6742 6741.3258000000005\n",
      "relu_sum, prediction [   1 6519   35   27   10   28    8   22   88    4]\n",
      "non active neurons:  (array([257, 267, 325, 326, 338, 343, 345, 374, 375, 386, 392, 401, 403,\n",
      "       411, 414, 444], dtype=int64),)\n",
      "active neurons:  (array([ 17,  31,  33,  39,  49,  66,  75,  96,  98,  99, 145, 157, 158,\n",
      "       167, 176, 180, 194, 196, 220, 249, 256, 258, 259, 260, 270, 272,\n",
      "       273, 275, 277, 290, 297, 310, 314, 318, 321, 323, 329, 339, 346,\n",
      "       356, 357, 363, 364, 366, 368, 369, 371, 378, 379, 380, 387, 389,\n",
      "       399, 400, 404, 408, 416, 419, 431, 433, 441, 443], dtype=int64),)\n",
      "WARN: neuro_idx = 449 for label 1 is not stable, let's include it anyway\n",
      "\n",
      "Label is  1\n",
      "Stable ReLUs [17, 31, 33, 39, 49, 66, 75, 96, 98, 99, 145, 157, 158, 167, 176, 180, 194, 196, 220, 249, 256, 257, 258, 259, 260, 267, 270, 272, 273, 275, 277, 290, 297, 310, 314, 318, 321, 323, 325, 326, 329, 338, 339, 343, 345, 346, 356, 357, 363, 364, 366, 368, 369, 371, 374, 375, 378, 379, 380, 386, 387, 389, 392, 399, 400, 401, 403, 404, 408, 411, 414, 416, 419, 431, 433, 441, 443, 444, 449]\n",
      "how many unique paths in the filtered pattern? (2, 79)\n",
      "their freq\n",
      " [ 223 6519] (2,)\n",
      "primary pattern coverage:  0.9669237614951053\n",
      "(5958, 458)\n",
      "threshold:  0.5958 5957.4042\n",
      "relu_sum, prediction [  72  103 5157  106  116   22  126   98  127   31]\n",
      "non active neurons:  (array([257, 267, 288, 343, 345, 374, 375, 392, 401, 403, 411, 414, 444],\n",
      "      dtype=int64),)\n",
      "active neurons:  (array([196, 258, 275, 310, 321, 323, 329, 333, 339, 346, 357, 360, 366,\n",
      "       368, 371, 380, 394, 404, 410, 431], dtype=int64),)\n",
      "WARN: neuro_idx = 450 for label 2 is not stable, let's include it anyway\n",
      "\n",
      "Label is  2\n",
      "Stable ReLUs [196, 257, 258, 267, 275, 288, 310, 321, 323, 329, 333, 339, 343, 345, 346, 357, 360, 366, 368, 371, 374, 375, 380, 392, 394, 401, 403, 404, 410, 411, 414, 431, 444, 450]\n",
      "how many unique paths in the filtered pattern? (2, 34)\n",
      "their freq\n",
      " [ 801 5157] (2,)\n",
      "primary pattern coverage:  0.8655589123867069\n",
      "(6131, 458)\n",
      "threshold:  0.6131 6130.3869\n",
      "relu_sum, prediction [  22   42  156 5277    2  323   25   85  144   55]\n",
      "non active neurons:  (array([257, 267, 325, 338, 343, 345, 374, 375, 392, 401, 403, 411, 414],\n",
      "      dtype=int64),)\n",
      "active neurons:  (array([ 17,  58,  66, 112, 145, 194, 196, 220, 258, 259, 270, 275, 277,\n",
      "       321, 323, 329, 339, 346, 360, 365, 369, 371, 380, 400, 404, 431,\n",
      "       434], dtype=int64),)\n",
      "WARN: neuro_idx = 451 for label 3 is not stable, let's include it anyway\n",
      "\n",
      "Label is  3\n",
      "Stable ReLUs [17, 58, 66, 112, 145, 194, 196, 220, 257, 258, 259, 267, 270, 275, 277, 321, 323, 325, 329, 338, 339, 343, 345, 346, 360, 365, 369, 371, 374, 375, 380, 392, 400, 401, 403, 404, 411, 414, 431, 434, 451]\n",
      "how many unique paths in the filtered pattern? (2, 41)\n",
      "their freq\n",
      " [ 854 5277] (2,)\n",
      "primary pattern coverage:  0.860707877997064\n",
      "(5842, 458)\n",
      "threshold:  0.5842 5841.4158\n",
      "relu_sum, prediction [  14   22   33    0 5380   12   86    9   42  244]\n",
      "non active neurons:  (array([257, 267, 343, 345, 374, 375, 386, 392, 401, 403, 411, 414, 418,\n",
      "       451], dtype=int64),)\n",
      "active neurons:  (array([ 58, 115, 129, 145, 155, 196, 223, 258, 273, 275, 285, 295, 298,\n",
      "       299, 307, 310, 314, 316, 321, 323, 333, 336, 339, 346, 349, 357,\n",
      "       358, 360, 379, 394, 395, 404, 407, 422, 423, 426, 431, 441],\n",
      "      dtype=int64),)\n",
      "WARN: neuro_idx = 452 for label 4 is not stable, let's include it anyway\n",
      "\n",
      "Label is  4\n",
      "Stable ReLUs [58, 115, 129, 145, 155, 196, 223, 257, 258, 267, 273, 275, 285, 295, 298, 299, 307, 310, 314, 316, 321, 323, 333, 336, 339, 343, 345, 346, 349, 357, 358, 360, 374, 375, 379, 386, 392, 394, 395, 401, 403, 404, 407, 411, 414, 418, 422, 423, 426, 431, 441, 451, 452]\n",
      "how many unique paths in the filtered pattern? (2, 53)\n",
      "their freq\n",
      " [ 462 5380] (2,)\n",
      "primary pattern coverage:  0.9209174940089011\n",
      "(5421, 458)\n",
      "threshold:  0.5421 5420.4579\n",
      "relu_sum, prediction [  93   59   37  228   96 4560  113   34  128   73]\n",
      "non active neurons:  (array([257, 267, 374, 375, 392, 401, 403, 411, 414, 418], dtype=int64),)\n",
      "active neurons:  (array([196, 220, 258, 259, 260, 275, 277, 287, 295, 302, 323, 329, 339,\n",
      "       346, 358, 369, 380, 399, 404, 420, 423], dtype=int64),)\n",
      "WARN: neuro_idx = 453 for label 5 is not stable, let's include it anyway\n",
      "\n",
      "Label is  5\n",
      "Stable ReLUs [196, 220, 257, 258, 259, 260, 267, 275, 277, 287, 295, 302, 323, 329, 339, 346, 358, 369, 374, 375, 380, 392, 399, 401, 403, 404, 411, 414, 418, 420, 423, 453]\n",
      "how many unique paths in the filtered pattern? (2, 32)\n",
      "their freq\n",
      " [ 861 4560] (2,)\n",
      "primary pattern coverage:  0.8411732152739347\n",
      "(5918, 458)\n",
      "threshold:  0.5918 5917.4082\n",
      "relu_sum, prediction [  57   31   44    1   68   85 5606    1   25    0]\n",
      "non active neurons:  (array([257, 267, 288, 325, 338, 343, 345, 374, 375, 392, 401, 403, 411,\n",
      "       414, 418, 444, 457], dtype=int64),)\n",
      "active neurons:  (array([ 39,  58, 142, 145, 179, 196, 207, 210, 220, 238, 253, 258, 259,\n",
      "       273, 275, 285, 295, 297, 299, 302, 307, 310, 314, 315, 316, 321,\n",
      "       323, 329, 333, 336, 339, 340, 346, 347, 349, 356, 357, 358, 360,\n",
      "       365, 366, 369, 371, 378, 379, 380, 394, 395, 404, 405, 406, 409,\n",
      "       410, 420, 423, 431, 434, 441], dtype=int64),)\n",
      "WARN: neuro_idx = 454 for label 6 is not stable, let's include it anyway\n",
      "\n",
      "Label is  6\n",
      "Stable ReLUs [39, 58, 142, 145, 179, 196, 207, 210, 220, 238, 253, 257, 258, 259, 267, 273, 275, 285, 288, 295, 297, 299, 302, 307, 310, 314, 315, 316, 321, 323, 325, 329, 333, 336, 338, 339, 340, 343, 345, 346, 347, 349, 356, 357, 358, 360, 365, 366, 369, 371, 374, 375, 378, 379, 380, 392, 394, 395, 401, 403, 404, 405, 406, 409, 410, 411, 414, 418, 420, 423, 431, 434, 441, 444, 454, 457]\n",
      "how many unique paths in the filtered pattern? (2, 76)\n",
      "their freq\n",
      " [ 312 5606] (2,)\n",
      "primary pattern coverage:  0.9472794863129436\n",
      "(6265, 458)\n",
      "threshold:  0.6265000000000001 6264.3735\n",
      "relu_sum, prediction [  31   47   93   28   83   15    1 5789   20  158]\n",
      "non active neurons:  (array([257, 267, 338, 343, 374, 375, 401, 403, 414, 418], dtype=int64),)\n",
      "active neurons:  (array([ 26,  66, 138, 143, 145, 196, 220, 229, 258, 272, 275, 277, 285,\n",
      "       295, 308, 312, 314, 320, 323, 329, 339, 341, 346, 360, 369, 377,\n",
      "       389, 404, 407, 433, 434, 436, 439], dtype=int64),)\n",
      "WARN: neuro_idx = 455 for label 7 is not stable, let's include it anyway\n",
      "\n",
      "Label is  7\n",
      "Stable ReLUs [26, 66, 138, 143, 145, 196, 220, 229, 257, 258, 267, 272, 275, 277, 285, 295, 308, 312, 314, 320, 323, 329, 338, 339, 341, 343, 346, 360, 369, 374, 375, 377, 389, 401, 403, 404, 407, 414, 418, 433, 434, 436, 439, 455]\n",
      "how many unique paths in the filtered pattern? (2, 44)\n",
      "their freq\n",
      " [ 476 5789] (2,)\n",
      "primary pattern coverage:  0.924022346368715\n",
      "(5851, 458)\n",
      "threshold:  0.5851000000000001 5850.4149\n",
      "relu_sum, prediction [  26  144   81  185   47  206   52   13 4966  131]\n",
      "non active neurons:  (array([257, 267, 288, 325, 326, 338, 343, 345, 372, 374, 375, 392, 401,\n",
      "       403, 411, 414, 418], dtype=int64),)\n",
      "active neurons:  (array([ 17,  65,  66,  97, 196, 220, 249, 258, 259, 260, 270, 272, 275,\n",
      "       277, 283, 286, 295, 306, 307, 310, 317, 318, 321, 323, 329, 336,\n",
      "       339, 346, 347, 349, 357, 358, 360, 364, 365, 366, 369, 371, 394,\n",
      "       400, 404, 422, 426, 431, 434, 438], dtype=int64),)\n",
      "WARN: neuro_idx = 456 for label 8 is not stable, let's include it anyway\n",
      "\n",
      "Label is  8\n",
      "Stable ReLUs [17, 65, 66, 97, 196, 220, 249, 257, 258, 259, 260, 267, 270, 272, 275, 277, 283, 286, 288, 295, 306, 307, 310, 317, 318, 321, 323, 325, 326, 329, 336, 338, 339, 343, 345, 346, 347, 349, 357, 358, 360, 364, 365, 366, 369, 371, 372, 374, 375, 392, 394, 400, 401, 403, 404, 411, 414, 418, 422, 426, 431, 434, 438, 456]\n",
      "how many unique paths in the filtered pattern? (2, 64)\n",
      "their freq\n",
      " [ 885 4966] (2,)\n",
      "primary pattern coverage:  0.848743804477867\n",
      "(5949, 458)\n",
      "threshold:  0.5949 5948.4051\n",
      "relu_sum, prediction [  43   21   22   76  249   43   10  247   72 5166]\n",
      "non active neurons:  (array([257, 267, 343, 345, 374, 375, 401, 403, 411, 414, 418], dtype=int64),)\n",
      "active neurons:  (array([ 58, 115, 143, 196, 220, 258, 259, 273, 275, 277, 295, 306, 307,\n",
      "       321, 323, 329, 333, 336, 339, 341, 346, 351, 360, 367, 369, 404,\n",
      "       405, 417, 422, 426, 436], dtype=int64),)\n",
      "WARN: neuro_idx = 457 for label 9 is not stable, let's include it anyway\n",
      "\n",
      "Label is  9\n",
      "Stable ReLUs [58, 115, 143, 196, 220, 257, 258, 259, 267, 273, 275, 277, 295, 306, 307, 321, 323, 329, 333, 336, 339, 341, 343, 345, 346, 351, 360, 367, 369, 374, 375, 401, 403, 404, 405, 411, 414, 417, 418, 422, 426, 436, 457]\n",
      "how many unique paths in the filtered pattern? (2, 43)\n",
      "their freq\n",
      " [ 783 5166] (2,)\n",
      "primary pattern coverage:  0.8683812405446294\n",
      "(5923, 458)\n",
      "threshold:  2.9615 5920.038500000001\n",
      "relu_sum, prediction [5685    0   29   15   11   77   48   11   43    4]\n",
      "non active neurons:  (array([257, 267, 288, 338, 343, 345, 374, 375, 392, 401, 403, 411, 414,\n",
      "       418, 449], dtype=int64),)\n",
      "active neurons:  (array([ 19,  56,  70,  82, 127, 138, 141, 142, 145, 159, 172, 179, 194,\n",
      "       196, 238, 258, 259, 260, 265, 275, 285, 287, 295, 298, 302, 307,\n",
      "       316, 321, 323, 329, 339, 340, 346, 347, 349, 352, 357, 358, 360,\n",
      "       362, 365, 369, 371, 380, 388, 393, 395, 396, 398, 406, 408, 409,\n",
      "       410, 417, 420, 423, 424, 426, 429, 434], dtype=int64),)\n",
      "WARN: neuro_idx = 448 for label 0 is not stable, let's include it anyway\n",
      "\n",
      "Label is  0\n",
      "Stable ReLUs [19, 56, 70, 82, 127, 138, 141, 142, 145, 159, 172, 179, 194, 196, 238, 257, 258, 259, 260, 265, 267, 275, 285, 287, 288, 295, 298, 302, 307, 316, 321, 323, 329, 338, 339, 340, 343, 345, 346, 347, 349, 352, 357, 358, 360, 362, 365, 369, 371, 374, 375, 380, 388, 392, 393, 395, 396, 398, 401, 403, 406, 408, 409, 410, 411, 414, 417, 418, 420, 423, 424, 426, 429, 434, 448, 449]\n",
      "how many unique paths in the filtered pattern? (28, 76)\n",
      "their freq\n",
      " [   1    1    1    1    1    1    1    1    1    1    1    2    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1  223 5671    2    2] (28,)\n",
      "primary pattern coverage:  0.9574539929089988\n",
      "(6742, 458)\n",
      "threshold:  3.371 6738.629000000001\n",
      "relu_sum, prediction [   1 6519   35   27   10   28    8   22   88    4]\n",
      "non active neurons:  (array([257, 267, 319, 325, 326, 338, 343, 345, 374, 375, 386, 392, 401,\n",
      "       403, 411, 414, 418, 444, 448], dtype=int64),)\n",
      "active neurons:  (array([  1,   6,  12,  13,  17,  26,  31,  33,  39,  49,  58,  65,  66,\n",
      "        75,  87,  91,  96,  97,  98,  99, 112, 145, 157, 158, 162, 167,\n",
      "       176, 180, 189, 194, 196, 207, 220, 239, 249, 256, 258, 259, 260,\n",
      "       268, 270, 271, 272, 273, 275, 277, 284, 290, 295, 297, 310, 312,\n",
      "       314, 315, 317, 318, 321, 323, 328, 329, 333, 336, 339, 341, 346,\n",
      "       356, 357, 358, 363, 364, 366, 368, 369, 371, 377, 378, 379, 380,\n",
      "       387, 389, 390, 394, 399, 400, 404, 408, 409, 416, 419, 420, 424,\n",
      "       428, 431, 433, 435, 438, 441, 443], dtype=int64),)\n",
      "WARN: neuro_idx = 449 for label 1 is not stable, let's include it anyway\n",
      "\n",
      "Label is  1\n",
      "Stable ReLUs [1, 6, 12, 13, 17, 26, 31, 33, 39, 49, 58, 65, 66, 75, 87, 91, 96, 97, 98, 99, 112, 145, 157, 158, 162, 167, 176, 180, 189, 194, 196, 207, 220, 239, 249, 256, 257, 258, 259, 260, 267, 268, 270, 271, 272, 273, 275, 277, 284, 290, 295, 297, 310, 312, 314, 315, 317, 318, 319, 321, 323, 325, 326, 328, 329, 333, 336, 338, 339, 341, 343, 345, 346, 356, 357, 358, 363, 364, 366, 368, 369, 371, 374, 375, 377, 378, 379, 380, 386, 387, 389, 390, 392, 394, 399, 400, 401, 403, 404, 408, 409, 411, 414, 416, 418, 419, 420, 424, 428, 431, 433, 435, 438, 441, 443, 444, 448, 449]\n",
      "how many unique paths in the filtered pattern? (36, 118)\n",
      "their freq\n",
      " [   1    2    1    1    3    1    1    3    1    1    1    1    2    1\n",
      "    1    1    1    2    1    2    1    1    1    1    1    2    1    1\n",
      "    1    1    1    1  194 6505    1    1] (36,)\n",
      "primary pattern coverage:  0.9648472263423317\n",
      "(5958, 458)\n",
      "threshold:  2.979 5955.021000000001\n",
      "relu_sum, prediction [  72  103 5157  106  116   22  126   98  127   31]\n",
      "non active neurons:  (array([257, 267, 288, 325, 343, 345, 374, 375, 392, 401, 403, 411, 414,\n",
      "       418, 444], dtype=int64),)\n",
      "active neurons:  (array([ 58, 196, 220, 258, 259, 273, 275, 277, 297, 310, 321, 323, 329,\n",
      "       333, 339, 346, 347, 357, 360, 364, 366, 368, 371, 380, 394, 404,\n",
      "       406, 410, 422, 431, 434], dtype=int64),)\n",
      "WARN: neuro_idx = 450 for label 2 is not stable, let's include it anyway\n",
      "\n",
      "Label is  2\n",
      "Stable ReLUs [58, 196, 220, 257, 258, 259, 267, 273, 275, 277, 288, 297, 310, 321, 323, 325, 329, 333, 339, 343, 345, 346, 347, 357, 360, 364, 366, 368, 371, 374, 375, 380, 392, 394, 401, 403, 404, 406, 410, 411, 414, 418, 422, 431, 434, 444, 450]\n",
      "how many unique paths in the filtered pattern? (17, 47)\n",
      "their freq\n",
      " [   1    2    1    1    1    1    1    1    2    1    1    1  787 5154\n",
      "    1    1    1] (17,)\n",
      "primary pattern coverage:  0.865055387713998\n",
      "(6131, 458)\n",
      "threshold:  3.0655 6127.9345\n",
      "relu_sum, prediction [  22   42  156 5277    2  323   25   85  144   55]\n",
      "non active neurons:  (array([257, 267, 288, 305, 319, 325, 338, 343, 345, 374, 375, 392, 401,\n",
      "       403, 411, 414, 444, 452], dtype=int64),)\n",
      "active neurons:  (array([ 17,  31,  58,  66,  87, 112, 143, 145, 157, 189, 194, 196, 220,\n",
      "       258, 259, 260, 270, 272, 275, 277, 283, 286, 318, 321, 323, 329,\n",
      "       333, 334, 339, 346, 347, 357, 358, 359, 360, 363, 364, 365, 366,\n",
      "       369, 371, 380, 390, 394, 396, 400, 404, 408, 415, 416, 422, 427,\n",
      "       428, 431, 433, 434, 438, 440, 447], dtype=int64),)\n",
      "WARN: neuro_idx = 451 for label 3 is not stable, let's include it anyway\n",
      "\n",
      "Label is  3\n",
      "Stable ReLUs [17, 31, 58, 66, 87, 112, 143, 145, 157, 189, 194, 196, 220, 257, 258, 259, 260, 267, 270, 272, 275, 277, 283, 286, 288, 305, 318, 319, 321, 323, 325, 329, 333, 334, 338, 339, 343, 345, 346, 347, 357, 358, 359, 360, 363, 364, 365, 366, 369, 371, 374, 375, 380, 390, 392, 394, 396, 400, 401, 403, 404, 408, 411, 414, 415, 416, 422, 427, 428, 431, 433, 434, 438, 440, 444, 447, 451, 452]\n",
      "how many unique paths in the filtered pattern? (32, 78)\n",
      "their freq\n",
      " [   1    2    1    1    1    1    2    1    2    1    1    2    3    1\n",
      "    1    1    3    1    1    1    3    1    2    1    1    1  815    1\n",
      " 5274    1    2    1] (32,)\n",
      "primary pattern coverage:  0.8602185614092318\n",
      "(5842, 458)\n",
      "threshold:  2.9210000000000003 5839.079000000001\n",
      "relu_sum, prediction [  14   22   33    0 5380   12   86    9   42  244]\n",
      "non active neurons:  (array([257, 267, 288, 319, 325, 343, 345, 372, 374, 375, 386, 392, 401,\n",
      "       403, 411, 414, 418, 444, 451], dtype=int64),)\n",
      "active neurons:  (array([ 54,  55,  58,  66,  84, 115, 129, 143, 145, 155, 196, 220, 223,\n",
      "       228, 256, 258, 261, 273, 275, 285, 286, 295, 296, 298, 299, 302,\n",
      "       306, 307, 310, 314, 316, 321, 323, 333, 336, 339, 341, 346, 349,\n",
      "       351, 356, 357, 358, 360, 377, 378, 379, 394, 395, 404, 405, 407,\n",
      "       409, 417, 420, 422, 423, 425, 426, 431, 436, 441], dtype=int64),)\n",
      "WARN: neuro_idx = 452 for label 4 is not stable, let's include it anyway\n",
      "\n",
      "Label is  4\n",
      "Stable ReLUs [54, 55, 58, 66, 84, 115, 129, 143, 145, 155, 196, 220, 223, 228, 256, 257, 258, 261, 267, 273, 275, 285, 286, 288, 295, 296, 298, 299, 302, 306, 307, 310, 314, 316, 319, 321, 323, 325, 333, 336, 339, 341, 343, 345, 346, 349, 351, 356, 357, 358, 360, 372, 374, 375, 377, 378, 379, 386, 392, 394, 395, 401, 403, 404, 405, 407, 409, 411, 414, 417, 418, 420, 422, 423, 425, 426, 431, 436, 441, 444, 451, 452]\n",
      "how many unique paths in the filtered pattern? (25, 82)\n",
      "their freq\n",
      " [   1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1  443 5374    2    1    2    1    1] (25,)\n",
      "primary pattern coverage:  0.9198904484765491\n",
      "(5421, 458)\n",
      "threshold:  2.7105 5418.2895\n",
      "relu_sum, prediction [  93   59   37  228   96 4560  113   34  128   73]\n",
      "non active neurons:  (array([257, 267, 338, 343, 374, 375, 392, 401, 403, 411, 414, 418, 444],\n",
      "      dtype=int64),)\n",
      "active neurons:  (array([ 58,  66, 196, 220, 258, 259, 260, 261, 270, 275, 277, 283, 285,\n",
      "       286, 287, 295, 302, 321, 323, 329, 336, 339, 340, 346, 347, 357,\n",
      "       358, 365, 369, 380, 395, 399, 400, 404, 408, 419, 420, 422, 423,\n",
      "       424, 426], dtype=int64),)\n",
      "WARN: neuro_idx = 453 for label 5 is not stable, let's include it anyway\n",
      "\n",
      "Label is  5\n",
      "Stable ReLUs [58, 66, 196, 220, 257, 258, 259, 260, 261, 267, 270, 275, 277, 283, 285, 286, 287, 295, 302, 321, 323, 329, 336, 338, 339, 340, 343, 346, 347, 357, 358, 365, 369, 374, 375, 380, 392, 395, 399, 400, 401, 403, 404, 408, 411, 414, 418, 419, 420, 422, 423, 424, 426, 444, 453]\n",
      "how many unique paths in the filtered pattern? (27, 55)\n",
      "their freq\n",
      " [   1    1    1    1    1    1    1    1    1    1    1    2    1    1\n",
      "    2    1    1    1    1    1    1  838 4555    1    1    1    2] (27,)\n",
      "primary pattern coverage:  0.8402508762220993\n",
      "(5918, 458)\n",
      "threshold:  2.959 5915.041\n",
      "relu_sum, prediction [  57   31   44    1   68   85 5606    1   25    0]\n",
      "non active neurons:  (array([257, 267, 288, 325, 338, 343, 345, 372, 374, 375, 385, 392, 401,\n",
      "       403, 411, 414, 418, 444, 451, 455, 457], dtype=int64),)\n",
      "active neurons:  (array([ 13,  39,  55,  58,  76,  84, 129, 142, 143, 145, 167, 179, 196,\n",
      "       207, 210, 220, 238, 253, 256, 258, 259, 261, 265, 273, 275, 285,\n",
      "       287, 295, 297, 299, 302, 307, 310, 314, 315, 316, 321, 323, 329,\n",
      "       333, 336, 339, 340, 346, 347, 349, 352, 356, 357, 358, 360, 364,\n",
      "       365, 366, 368, 369, 371, 378, 379, 380, 382, 394, 395, 396, 404,\n",
      "       405, 406, 409, 410, 417, 419, 420, 422, 423, 431, 434, 441],\n",
      "      dtype=int64),)\n",
      "WARN: neuro_idx = 454 for label 6 is not stable, let's include it anyway\n",
      "\n",
      "Label is  6\n",
      "Stable ReLUs [13, 39, 55, 58, 76, 84, 129, 142, 143, 145, 167, 179, 196, 207, 210, 220, 238, 253, 256, 257, 258, 259, 261, 265, 267, 273, 275, 285, 287, 288, 295, 297, 299, 302, 307, 310, 314, 315, 316, 321, 323, 325, 329, 333, 336, 338, 339, 340, 343, 345, 346, 347, 349, 352, 356, 357, 358, 360, 364, 365, 366, 368, 369, 371, 372, 374, 375, 378, 379, 380, 382, 385, 392, 394, 395, 396, 401, 403, 404, 405, 406, 409, 410, 411, 414, 417, 418, 419, 420, 422, 423, 431, 434, 441, 444, 451, 454, 455, 457]\n",
      "how many unique paths in the filtered pattern? (25, 99)\n",
      "their freq\n",
      " [   2    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    2  291 5601    1    2    1] (25,)\n",
      "primary pattern coverage:  0.9464346062859074\n",
      "(6265, 458)\n",
      "threshold:  3.1325000000000003 6261.8675\n",
      "relu_sum, prediction [  31   47   93   28   83   15    1 5789   20  158]\n",
      "non active neurons:  (array([257, 267, 338, 343, 374, 375, 401, 403, 414, 418, 454], dtype=int64),)\n",
      "active neurons:  (array([ 26,  49,  58,  66,  87,  98, 138, 143, 145, 155, 196, 220, 228,\n",
      "       229, 239, 258, 259, 265, 272, 273, 275, 277, 282, 284, 285, 295,\n",
      "       298, 299, 306, 307, 308, 312, 314, 317, 320, 323, 329, 333, 334,\n",
      "       336, 339, 341, 344, 346, 350, 360, 369, 377, 389, 391, 402, 404,\n",
      "       405, 407, 426, 433, 434, 436, 439, 442], dtype=int64),)\n",
      "WARN: neuro_idx = 455 for label 7 is not stable, let's include it anyway\n",
      "\n",
      "Label is  7\n",
      "Stable ReLUs [26, 49, 58, 66, 87, 98, 138, 143, 145, 155, 196, 220, 228, 229, 239, 257, 258, 259, 265, 267, 272, 273, 275, 277, 282, 284, 285, 295, 298, 299, 306, 307, 308, 312, 314, 317, 320, 323, 329, 333, 334, 336, 338, 339, 341, 343, 344, 346, 350, 360, 369, 374, 375, 377, 389, 391, 401, 402, 403, 404, 405, 407, 414, 418, 426, 433, 434, 436, 439, 442, 454, 455]\n",
      "how many unique paths in the filtered pattern? (29, 72)\n",
      "their freq\n",
      " [   1    1    1    1    1    1    1    1    1    2    1    1    2    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1  450 5786\n",
      "    1] (29,)\n",
      "primary pattern coverage:  0.9235434956105347\n",
      "(5851, 458)\n",
      "threshold:  2.9255 5848.074500000001\n",
      "relu_sum, prediction [  26  144   81  185   47  206   52   13 4966  131]\n",
      "non active neurons:  (array([257, 267, 288, 325, 326, 338, 343, 345, 372, 374, 375, 386, 392,\n",
      "       401, 403, 411, 414, 418], dtype=int64),)\n",
      "active neurons:  (array([ 12,  17,  55,  56,  58,  65,  66,  75,  87,  97,  98, 112, 143,\n",
      "       145, 191, 194, 196, 220, 249, 256, 258, 259, 260, 270, 271, 272,\n",
      "       275, 277, 283, 285, 286, 290, 295, 298, 306, 307, 310, 317, 318,\n",
      "       321, 323, 329, 333, 336, 339, 340, 341, 346, 347, 349, 357, 358,\n",
      "       360, 364, 365, 366, 369, 371, 377, 380, 390, 394, 395, 400, 404,\n",
      "       406, 408, 410, 419, 420, 422, 423, 426, 431, 434, 438], dtype=int64),)\n",
      "WARN: neuro_idx = 456 for label 8 is not stable, let's include it anyway\n",
      "\n",
      "Label is  8\n",
      "Stable ReLUs [12, 17, 55, 56, 58, 65, 66, 75, 87, 97, 98, 112, 143, 145, 191, 194, 196, 220, 249, 256, 257, 258, 259, 260, 267, 270, 271, 272, 275, 277, 283, 285, 286, 288, 290, 295, 298, 306, 307, 310, 317, 318, 321, 323, 325, 326, 329, 333, 336, 338, 339, 340, 341, 343, 345, 346, 347, 349, 357, 358, 360, 364, 365, 366, 369, 371, 372, 374, 375, 377, 380, 386, 390, 392, 394, 395, 400, 401, 403, 404, 406, 408, 410, 411, 414, 418, 419, 420, 422, 423, 426, 431, 434, 438, 456]\n",
      "how many unique paths in the filtered pattern? (25, 95)\n",
      "their freq\n",
      " [   1    1    1    1    1    2    1    1    1    1    1    2    1    1\n",
      "    2    1    1    1    1    1    1    1    1  864 4961] (25,)\n",
      "primary pattern coverage:  0.8478892497009058\n",
      "(5949, 458)\n",
      "threshold:  2.9745 5946.025500000001\n",
      "relu_sum, prediction [  43   21   22   76  249   43   10  247   72 5166]\n",
      "non active neurons:  (array([257, 267, 343, 345, 372, 374, 375, 392, 401, 403, 411, 414, 418],\n",
      "      dtype=int64),)\n",
      "active neurons:  (array([ 12,  54,  58,  65,  66,  87,  98, 112, 115, 138, 143, 155, 189,\n",
      "       196, 220, 223, 258, 259, 273, 275, 277, 282, 283, 285, 286, 295,\n",
      "       298, 299, 306, 307, 308, 314, 321, 323, 329, 333, 334, 336, 339,\n",
      "       341, 346, 349, 351, 359, 360, 367, 369, 377, 380, 389, 404, 405,\n",
      "       407, 417, 422, 426, 436], dtype=int64),)\n",
      "WARN: neuro_idx = 457 for label 9 is not stable, let's include it anyway\n",
      "\n",
      "Label is  9\n",
      "Stable ReLUs [12, 54, 58, 65, 66, 87, 98, 112, 115, 138, 143, 155, 189, 196, 220, 223, 257, 258, 259, 267, 273, 275, 277, 282, 283, 285, 286, 295, 298, 299, 306, 307, 308, 314, 321, 323, 329, 333, 334, 336, 339, 341, 343, 345, 346, 349, 351, 359, 360, 367, 369, 372, 374, 375, 377, 380, 389, 392, 401, 403, 404, 405, 407, 411, 414, 417, 418, 422, 426, 436, 457]\n",
      "how many unique paths in the filtered pattern? (20, 71)\n",
      "their freq\n",
      " [   1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1  766 5165    1] (20,)\n",
      "primary pattern coverage:  0.8682131450663977\n",
      "(5923, 458)\n",
      "threshold:  5.923 5917.077\n",
      "relu_sum, prediction [5685    0   29   15   11   77   48   11   43    4]\n",
      "non active neurons:  (array([257, 267, 288, 305, 325, 338, 343, 345, 372, 374, 375, 386, 392,\n",
      "       401, 403, 411, 414, 418, 449, 457], dtype=int64),)\n",
      "active neurons:  (array([ 19,  56,  63,  70,  75,  82,  83, 127, 138, 141, 142, 145, 159,\n",
      "       172, 173, 179, 194, 196, 209, 217, 235, 238, 258, 259, 260, 265,\n",
      "       275, 277, 285, 287, 290, 295, 298, 302, 307, 309, 316, 321, 323,\n",
      "       329, 339, 340, 346, 347, 349, 351, 352, 357, 358, 360, 362, 365,\n",
      "       369, 371, 380, 388, 393, 395, 396, 398, 406, 408, 409, 410, 417,\n",
      "       420, 423, 424, 426, 429, 434], dtype=int64),)\n",
      "WARN: neuro_idx = 448 for label 0 is not stable, let's include it anyway\n",
      "\n",
      "Label is  0\n",
      "Stable ReLUs [19, 56, 63, 70, 75, 82, 83, 127, 138, 141, 142, 145, 159, 172, 173, 179, 194, 196, 209, 217, 235, 238, 257, 258, 259, 260, 265, 267, 275, 277, 285, 287, 288, 290, 295, 298, 302, 305, 307, 309, 316, 321, 323, 325, 329, 338, 339, 340, 343, 345, 346, 347, 349, 351, 352, 357, 358, 360, 362, 365, 369, 371, 372, 374, 375, 380, 386, 388, 392, 393, 395, 396, 398, 401, 403, 406, 408, 409, 410, 411, 414, 417, 418, 420, 423, 424, 426, 429, 434, 448, 449, 457]\n",
      "how many unique paths in the filtered pattern? (51, 92)\n",
      "their freq\n",
      " [   1    2    3    1    1    1    1    3    1    1    1    1    1    1\n",
      "    1    1    1    2    1    2    1    3    1    1    2    1    1    3\n",
      "    1    1    3    1    1    2    1    1    1    1    1  207    4 5644\n",
      "    1    3    3    1    1    1    1    1    2] (51,)\n",
      "primary pattern coverage:  0.9528954921492487\n",
      "(6742, 458)\n",
      "threshold:  6.742 6735.258\n",
      "relu_sum, prediction [   1 6519   35   27   10   28    8   22   88    4]\n",
      "non active neurons:  (array([257, 267, 319, 325, 326, 338, 343, 345, 374, 375, 386, 392, 401,\n",
      "       403, 411, 414, 418, 444, 448, 457], dtype=int64),)\n",
      "active neurons:  (array([  1,   6,  12,  13,  17,  26,  31,  33,  39,  49,  58,  65,  66,\n",
      "        75,  76,  81,  84,  87,  91,  96,  97,  98,  99, 105, 112, 113,\n",
      "       143, 145, 157, 158, 162, 166, 167, 170, 176, 180, 189, 194, 196,\n",
      "       207, 212, 220, 230, 237, 239, 249, 256, 258, 259, 260, 268, 270,\n",
      "       271, 272, 273, 275, 277, 284, 286, 290, 295, 297, 310, 312, 314,\n",
      "       315, 317, 318, 320, 321, 323, 328, 329, 331, 333, 336, 337, 339,\n",
      "       341, 346, 356, 357, 358, 363, 364, 366, 368, 369, 371, 377, 378,\n",
      "       379, 380, 382, 384, 387, 389, 390, 394, 395, 399, 400, 404, 408,\n",
      "       409, 416, 419, 420, 424, 428, 431, 433, 435, 438, 439, 440, 441,\n",
      "       443], dtype=int64),)\n",
      "WARN: neuro_idx = 449 for label 1 is not stable, let's include it anyway\n",
      "\n",
      "Label is  1\n",
      "Stable ReLUs [1, 6, 12, 13, 17, 26, 31, 33, 39, 49, 58, 65, 66, 75, 76, 81, 84, 87, 91, 96, 97, 98, 99, 105, 112, 113, 143, 145, 157, 158, 162, 166, 167, 170, 176, 180, 189, 194, 196, 207, 212, 220, 230, 237, 239, 249, 256, 257, 258, 259, 260, 267, 268, 270, 271, 272, 273, 275, 277, 284, 286, 290, 295, 297, 310, 312, 314, 315, 317, 318, 319, 320, 321, 323, 325, 326, 328, 329, 331, 333, 336, 337, 338, 339, 341, 343, 345, 346, 356, 357, 358, 363, 364, 366, 368, 369, 371, 374, 375, 377, 378, 379, 380, 382, 384, 386, 387, 389, 390, 392, 394, 395, 399, 400, 401, 403, 404, 408, 409, 411, 414, 416, 418, 419, 420, 424, 428, 431, 433, 435, 438, 439, 440, 441, 443, 444, 448, 449, 457]\n",
      "how many unique paths in the filtered pattern? (68, 139)\n",
      "their freq\n",
      " [   1    1    1    1    1    1    1    1    1    1    1    5    1    1\n",
      "    1    1    1    1    3    1    1    1    1    2    1    1    1    1\n",
      "    1    1    1    3    1    1    1    1    1    1    3    1    5    1\n",
      "    1    2    1    1    1    1    4    2    1    1    1    1    1    1\n",
      "    1    2    1    1    2    1    1    1  174    2 6479    1] (68,)\n",
      "primary pattern coverage:  0.960990803915752\n",
      "(5958, 458)\n",
      "threshold:  5.958 5952.042\n",
      "relu_sum, prediction [  72  103 5157  106  116   22  126   98  127   31]\n",
      "non active neurons:  (array([257, 267, 288, 325, 326, 343, 345, 374, 375, 385, 386, 392, 401,\n",
      "       403, 411, 414, 418, 444], dtype=int64),)\n",
      "active neurons:  (array([ 17,  39,  58, 145, 194, 196, 220, 258, 259, 260, 273, 275, 277,\n",
      "       290, 297, 302, 310, 321, 323, 329, 333, 339, 346, 347, 357, 360,\n",
      "       364, 365, 366, 368, 369, 371, 380, 394, 404, 406, 410, 422, 431,\n",
      "       434], dtype=int64),)\n",
      "WARN: neuro_idx = 450 for label 2 is not stable, let's include it anyway\n",
      "\n",
      "Label is  2\n",
      "Stable ReLUs [17, 39, 58, 145, 194, 196, 220, 257, 258, 259, 260, 267, 273, 275, 277, 288, 290, 297, 302, 310, 321, 323, 325, 326, 329, 333, 339, 343, 345, 346, 347, 357, 360, 364, 365, 366, 368, 369, 371, 374, 375, 380, 385, 386, 392, 394, 401, 403, 404, 406, 410, 411, 414, 418, 422, 431, 434, 444, 450]\n",
      "how many unique paths in the filtered pattern? (37, 59)\n",
      "their freq\n",
      " [   1    1    2    1    2    1    1    4    2    1    2    1    1    4\n",
      "    1    1    1    1    1    1    3    1    1    3    3    1    1    1\n",
      "  756 5146    1    1    2    4    2    1    1] (37,)\n",
      "primary pattern coverage:  0.8637126552534408\n",
      "(6131, 458)\n",
      "threshold:  6.131 6124.869\n",
      "relu_sum, prediction [  22   42  156 5277    2  323   25   85  144   55]\n",
      "non active neurons:  (array([257, 267, 279, 288, 305, 319, 325, 338, 343, 345, 372, 374, 375,\n",
      "       385, 392, 401, 403, 411, 414, 444, 452], dtype=int64),)\n",
      "active neurons:  (array([ 12,  17,  31,  58,  66,  87, 112, 138, 143, 145, 157, 166, 170,\n",
      "       180, 189, 194, 196, 220, 258, 259, 260, 270, 272, 275, 277, 283,\n",
      "       286, 312, 318, 321, 323, 329, 333, 334, 339, 346, 347, 357, 358,\n",
      "       359, 360, 363, 364, 365, 366, 369, 371, 380, 389, 390, 394, 396,\n",
      "       400, 404, 408, 415, 416, 422, 427, 428, 431, 433, 434, 438, 440,\n",
      "       447], dtype=int64),)\n",
      "WARN: neuro_idx = 451 for label 3 is not stable, let's include it anyway\n",
      "\n",
      "Label is  3\n",
      "Stable ReLUs [12, 17, 31, 58, 66, 87, 112, 138, 143, 145, 157, 166, 170, 180, 189, 194, 196, 220, 257, 258, 259, 260, 267, 270, 272, 275, 277, 279, 283, 286, 288, 305, 312, 318, 319, 321, 323, 325, 329, 333, 334, 338, 339, 343, 345, 346, 347, 357, 358, 359, 360, 363, 364, 365, 366, 369, 371, 372, 374, 375, 380, 385, 389, 390, 392, 394, 396, 400, 401, 403, 404, 408, 411, 414, 415, 416, 422, 427, 428, 431, 433, 434, 438, 440, 444, 447, 451, 452]\n",
      "how many unique paths in the filtered pattern? (48, 88)\n",
      "their freq\n",
      " [   1    3    2    1    1    1    1    5    1    1    1    3    1    1\n",
      "    2    2    1    1    1    1    1    1    2    1    2    3    1    1\n",
      "    1    3    1    1    4    1    3    1    2    1    1  789    1 5264\n",
      "    4    5    1    2    1    2] (48,)\n",
      "primary pattern coverage:  0.8585875061164574\n",
      "(5842, 458)\n",
      "threshold:  5.8420000000000005 5836.158\n",
      "relu_sum, prediction [  14   22   33    0 5380   12   86    9   42  244]\n",
      "non active neurons:  (array([257, 267, 288, 319, 325, 326, 343, 345, 372, 374, 375, 386, 392,\n",
      "       401, 403, 411, 414, 418, 444, 451], dtype=int64),)\n",
      "active neurons:  (array([ 13,  51,  54,  55,  58,  65,  66,  84,  98, 107, 115, 129, 143,\n",
      "       145, 155, 179, 196, 198, 200, 219, 220, 223, 228, 248, 256, 258,\n",
      "       261, 273, 275, 277, 285, 286, 295, 296, 298, 299, 302, 306, 307,\n",
      "       308, 310, 314, 316, 321, 323, 329, 333, 334, 336, 339, 340, 341,\n",
      "       346, 347, 349, 351, 353, 356, 357, 358, 360, 361, 369, 377, 378,\n",
      "       379, 394, 395, 397, 404, 405, 407, 409, 417, 419, 420, 422, 423,\n",
      "       425, 426, 431, 436, 441], dtype=int64),)\n",
      "WARN: neuro_idx = 452 for label 4 is not stable, let's include it anyway\n",
      "\n",
      "Label is  4\n",
      "Stable ReLUs [13, 51, 54, 55, 58, 65, 66, 84, 98, 107, 115, 129, 143, 145, 155, 179, 196, 198, 200, 219, 220, 223, 228, 248, 256, 257, 258, 261, 267, 273, 275, 277, 285, 286, 288, 295, 296, 298, 299, 302, 306, 307, 308, 310, 314, 316, 319, 321, 323, 325, 326, 329, 333, 334, 336, 339, 340, 341, 343, 345, 346, 347, 349, 351, 353, 356, 357, 358, 360, 361, 369, 372, 374, 375, 377, 378, 379, 386, 392, 394, 395, 397, 401, 403, 404, 405, 407, 409, 411, 414, 417, 418, 419, 420, 422, 423, 425, 426, 431, 436, 441, 444, 451, 452]\n",
      "how many unique paths in the filtered pattern? (58, 104)\n",
      "their freq\n",
      " [   1    2    1    1    1    1    1    1    1    2    1    1    1    1\n",
      "    1    1    1    1    1    3    1    2    1    1    1    1    1    1\n",
      "    1    1    2    1    1    1    1    1    1    3    2    1    1    2\n",
      "    3    3    5    1    1    2    1    1    2  418 5345    1    1    3\n",
      "    2    1] (58,)\n",
      "primary pattern coverage:  0.9149263950701815\n",
      "(5421, 458)\n",
      "threshold:  5.421 5415.579\n",
      "relu_sum, prediction [  93   59   37  228   96 4560  113   34  128   73]\n",
      "non active neurons:  (array([257, 267, 338, 343, 374, 375, 392, 401, 403, 411, 414, 418, 444],\n",
      "      dtype=int64),)\n",
      "active neurons:  (array([ 58,  66, 112, 191, 196, 220, 258, 259, 260, 261, 270, 275, 277,\n",
      "       283, 285, 286, 287, 295, 298, 302, 307, 318, 321, 323, 329, 336,\n",
      "       339, 340, 346, 347, 349, 357, 358, 365, 369, 371, 380, 382, 390,\n",
      "       395, 397, 399, 400, 404, 406, 408, 419, 420, 422, 423, 424, 426],\n",
      "      dtype=int64),)\n",
      "WARN: neuro_idx = 453 for label 5 is not stable, let's include it anyway\n",
      "\n",
      "Label is  5\n",
      "Stable ReLUs [58, 66, 112, 191, 196, 220, 257, 258, 259, 260, 261, 267, 270, 275, 277, 283, 285, 286, 287, 295, 298, 302, 307, 318, 321, 323, 329, 336, 338, 339, 340, 343, 346, 347, 349, 357, 358, 365, 369, 371, 374, 375, 380, 382, 390, 392, 395, 397, 399, 400, 401, 403, 404, 406, 408, 411, 414, 418, 419, 420, 422, 423, 424, 426, 444, 453]\n",
      "how many unique paths in the filtered pattern? (42, 66)\n",
      "their freq\n",
      " [   1    1    1    1    3    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    3    1    2    1    1    2    1    1    2\n",
      "    1    3    2    1    3    1    3    1  814 4552    1    1    1    2] (42,)\n",
      "primary pattern coverage:  0.8396974727909979\n",
      "(5918, 458)\n",
      "threshold:  5.918 5912.082\n",
      "relu_sum, prediction [  57   31   44    1   68   85 5606    1   25    0]\n",
      "non active neurons:  (array([257, 267, 288, 325, 338, 343, 345, 372, 374, 375, 385, 386, 392,\n",
      "       401, 403, 411, 414, 418, 444, 451, 455, 457], dtype=int64),)\n",
      "active neurons:  (array([ 13,  39,  55,  58,  76,  84, 129, 130, 142, 143, 145, 167, 179,\n",
      "       194, 196, 202, 207, 210, 219, 220, 238, 242, 249, 253, 256, 258,\n",
      "       259, 261, 265, 269, 273, 275, 283, 284, 285, 287, 295, 297, 299,\n",
      "       302, 306, 307, 310, 314, 315, 316, 321, 323, 329, 333, 336, 339,\n",
      "       340, 346, 347, 349, 352, 356, 357, 358, 360, 364, 365, 366, 368,\n",
      "       369, 371, 378, 379, 380, 382, 387, 394, 395, 396, 404, 405, 406,\n",
      "       409, 410, 417, 419, 420, 422, 423, 431, 434, 441], dtype=int64),)\n",
      "WARN: neuro_idx = 454 for label 6 is not stable, let's include it anyway\n",
      "\n",
      "Label is  6\n",
      "Stable ReLUs [13, 39, 55, 58, 76, 84, 129, 130, 142, 143, 145, 167, 179, 194, 196, 202, 207, 210, 219, 220, 238, 242, 249, 253, 256, 257, 258, 259, 261, 265, 267, 269, 273, 275, 283, 284, 285, 287, 288, 295, 297, 299, 302, 306, 307, 310, 314, 315, 316, 321, 323, 325, 329, 333, 336, 338, 339, 340, 343, 345, 346, 347, 349, 352, 356, 357, 358, 360, 364, 365, 366, 368, 369, 371, 372, 374, 375, 378, 379, 380, 382, 385, 386, 387, 392, 394, 395, 396, 401, 403, 404, 405, 406, 409, 410, 411, 414, 417, 418, 419, 420, 422, 423, 431, 434, 441, 444, 451, 454, 455, 457]\n",
      "how many unique paths in the filtered pattern? (43, 111)\n",
      "their freq\n",
      " [   2    1    1    1    1    1    1    3    1    1    1    2    1    1\n",
      "    1    3    1    1    1    1    1    1    1    1    2    2    2    2\n",
      "    1    1    1    3    1    1    3    1    2  270 5587    1    5    2\n",
      "    1] (43,)\n",
      "primary pattern coverage:  0.9440689422102061\n",
      "(6265, 458)\n",
      "threshold:  6.265000000000001 6258.735\n",
      "relu_sum, prediction [  31   47   93   28   83   15    1 5789   20  158]\n",
      "non active neurons:  (array([257, 267, 338, 343, 345, 372, 374, 375, 401, 403, 414, 418, 454],\n",
      "      dtype=int64),)\n",
      "active neurons:  (array([ 26,  49,  58,  66,  87,  98, 107, 115, 138, 143, 145, 155, 196,\n",
      "       220, 228, 229, 239, 258, 259, 265, 272, 273, 275, 277, 282, 284,\n",
      "       285, 286, 295, 298, 299, 306, 307, 308, 312, 314, 317, 320, 323,\n",
      "       329, 333, 334, 336, 339, 341, 344, 346, 350, 360, 367, 369, 377,\n",
      "       380, 389, 391, 402, 404, 405, 406, 407, 426, 433, 434, 436, 439,\n",
      "       442], dtype=int64),)\n",
      "WARN: neuro_idx = 455 for label 7 is not stable, let's include it anyway\n",
      "\n",
      "Label is  7\n",
      "Stable ReLUs [26, 49, 58, 66, 87, 98, 107, 115, 138, 143, 145, 155, 196, 220, 228, 229, 239, 257, 258, 259, 265, 267, 272, 273, 275, 277, 282, 284, 285, 286, 295, 298, 299, 306, 307, 308, 312, 314, 317, 320, 323, 329, 333, 334, 336, 338, 339, 341, 343, 344, 345, 346, 350, 360, 367, 369, 372, 374, 375, 377, 380, 389, 391, 401, 402, 403, 404, 405, 406, 407, 414, 418, 426, 433, 434, 436, 439, 442, 454, 455]\n",
      "how many unique paths in the filtered pattern? (40, 80)\n",
      "their freq\n",
      " [   1    1    1    1    1    4    1    1    2    1    1    1    1    2\n",
      "    1    1    2    1    1    1    2    3    1    1    1    1    1    1\n",
      "    1    2    5    1    1    3    1  436 5772    1    4    1] (40,)\n",
      "primary pattern coverage:  0.9213088587390263\n",
      "(5851, 458)\n",
      "threshold:  5.851 5845.149\n",
      "relu_sum, prediction [  26  144   81  185   47  206   52   13 4966  131]\n",
      "non active neurons:  (array([257, 267, 288, 305, 325, 326, 338, 343, 345, 372, 374, 375, 386,\n",
      "       392, 401, 403, 411, 414, 418], dtype=int64),)\n",
      "active neurons:  (array([  6,  12,  17,  30,  51,  55,  56,  58,  65,  66,  75,  87,  97,\n",
      "        98, 110, 112, 119, 138, 143, 145, 157, 167, 173, 179, 188, 191,\n",
      "       194, 196, 207, 220, 223, 249, 256, 258, 259, 260, 261, 270, 271,\n",
      "       272, 273, 275, 277, 283, 285, 286, 290, 295, 298, 302, 306, 307,\n",
      "       310, 317, 318, 321, 323, 329, 333, 336, 339, 340, 341, 346, 347,\n",
      "       349, 352, 357, 358, 360, 364, 365, 366, 369, 371, 377, 380, 390,\n",
      "       394, 395, 400, 404, 405, 406, 408, 410, 419, 420, 421, 422, 423,\n",
      "       424, 426, 431, 433, 434, 438, 440, 441], dtype=int64),)\n",
      "WARN: neuro_idx = 456 for label 8 is not stable, let's include it anyway\n",
      "\n",
      "Label is  8\n",
      "Stable ReLUs [6, 12, 17, 30, 51, 55, 56, 58, 65, 66, 75, 87, 97, 98, 110, 112, 119, 138, 143, 145, 157, 167, 173, 179, 188, 191, 194, 196, 207, 220, 223, 249, 256, 257, 258, 259, 260, 261, 267, 270, 271, 272, 273, 275, 277, 283, 285, 286, 288, 290, 295, 298, 302, 305, 306, 307, 310, 317, 318, 321, 323, 325, 326, 329, 333, 336, 338, 339, 340, 341, 343, 345, 346, 347, 349, 352, 357, 358, 360, 364, 365, 366, 369, 371, 372, 374, 375, 377, 380, 386, 390, 392, 394, 395, 400, 401, 403, 404, 405, 406, 408, 410, 411, 414, 418, 419, 420, 421, 422, 423, 424, 426, 431, 433, 434, 438, 440, 441, 456]\n",
      "how many unique paths in the filtered pattern? (59, 119)\n",
      "their freq\n",
      " [   1    3    1    1    1    1    1    1    1    2    1    1    2    1\n",
      "    1    1    1    3    5    1    1    1    1    1    1    1    2    2\n",
      "    1    1    3    1    1    1    1    2    1    1    2    2    2    1\n",
      "    1    1    1    1    1    1    2    1    4    4    1    4    2  812\n",
      " 4952    1    2] (59,)\n",
      "primary pattern coverage:  0.8463510511023756\n",
      "(5949, 458)\n",
      "threshold:  5.949 5943.051\n",
      "relu_sum, prediction [  43   21   22   76  249   43   10  247   72 5166]\n",
      "non active neurons:  (array([257, 267, 288, 343, 345, 372, 374, 375, 386, 392, 401, 403, 411,\n",
      "       414, 418], dtype=int64),)\n",
      "active neurons:  (array([  8,  12,  54,  55,  58,  65,  66,  87,  96,  98, 107, 112, 115,\n",
      "       129, 138, 143, 155, 170, 189, 196, 201, 220, 223, 229, 258, 259,\n",
      "       264, 273, 275, 277, 282, 283, 285, 286, 295, 298, 299, 306, 307,\n",
      "       308, 312, 314, 321, 323, 329, 330, 332, 333, 334, 336, 339, 341,\n",
      "       344, 346, 349, 351, 357, 358, 359, 360, 365, 367, 369, 377, 380,\n",
      "       389, 391, 395, 404, 405, 407, 417, 422, 426, 431, 434, 436, 439,\n",
      "       442], dtype=int64),)\n",
      "WARN: neuro_idx = 457 for label 9 is not stable, let's include it anyway\n",
      "\n",
      "Label is  9\n",
      "Stable ReLUs [8, 12, 54, 55, 58, 65, 66, 87, 96, 98, 107, 112, 115, 129, 138, 143, 155, 170, 189, 196, 201, 220, 223, 229, 257, 258, 259, 264, 267, 273, 275, 277, 282, 283, 285, 286, 288, 295, 298, 299, 306, 307, 308, 312, 314, 321, 323, 329, 330, 332, 333, 334, 336, 339, 341, 343, 344, 345, 346, 349, 351, 357, 358, 359, 360, 365, 367, 369, 372, 374, 375, 377, 380, 386, 389, 391, 392, 395, 401, 403, 404, 405, 407, 411, 414, 417, 418, 422, 426, 431, 434, 436, 439, 442, 457]\n",
      "how many unique paths in the filtered pattern? (54, 95)\n",
      "their freq\n",
      " [   2    1    1    1    1    3    1    1    1    1    1    1    1    1\n",
      "    1    3    1    1    1    1    1    2    1    1    2    2    1    1\n",
      "    1    1    1    1    1    2    1    1    1    1    2    3    3    1\n",
      "    1    2    4    4    2    1  714 5158    1    1    3    2] (54,)\n",
      "primary pattern coverage:  0.8670364767187763\n",
      "(5923, 458)\n",
      "threshold:  29.615000000000002 5893.385\n",
      "relu_sum, prediction [5685    0   29   15   11   77   48   11   43    4]\n",
      "non active neurons:  (array([257, 267, 279, 288, 305, 325, 326, 338, 343, 345, 372, 373, 374,\n",
      "       375, 376, 381, 385, 386, 392, 401, 403, 411, 414, 418, 444, 449,\n",
      "       450, 451, 452, 455, 457], dtype=int64),)\n",
      "active neurons:  (array([ 19,  26,  27,  30,  31,  55,  56,  63,  70,  72,  75,  82,  83,\n",
      "        85,  88,  97, 112, 116, 127, 138, 141, 142, 143, 144, 145, 147,\n",
      "       148, 159, 170, 171, 172, 173, 179, 192, 193, 194, 196, 209, 213,\n",
      "       217, 222, 234, 235, 238, 258, 259, 260, 264, 265, 269, 272, 275,\n",
      "       276, 277, 283, 284, 285, 287, 289, 290, 295, 298, 302, 303, 306,\n",
      "       307, 309, 316, 318, 321, 323, 329, 339, 340, 342, 344, 346, 347,\n",
      "       348, 349, 351, 352, 357, 358, 360, 362, 365, 366, 367, 369, 371,\n",
      "       380, 388, 390, 391, 393, 394, 395, 396, 398, 404, 405, 406, 408,\n",
      "       409, 410, 415, 417, 419, 420, 423, 424, 426, 427, 429, 434, 437,\n",
      "       447], dtype=int64),)\n",
      "WARN: neuro_idx = 448 for label 0 is not stable, let's include it anyway\n",
      "\n",
      "Label is  0\n",
      "Stable ReLUs [19, 26, 27, 30, 31, 55, 56, 63, 70, 72, 75, 82, 83, 85, 88, 97, 112, 116, 127, 138, 141, 142, 143, 144, 145, 147, 148, 159, 170, 171, 172, 173, 179, 192, 193, 194, 196, 209, 213, 217, 222, 234, 235, 238, 257, 258, 259, 260, 264, 265, 267, 269, 272, 275, 276, 277, 279, 283, 284, 285, 287, 288, 289, 290, 295, 298, 302, 303, 305, 306, 307, 309, 316, 318, 321, 323, 325, 326, 329, 338, 339, 340, 342, 343, 344, 345, 346, 347, 348, 349, 351, 352, 357, 358, 360, 362, 365, 366, 367, 369, 371, 372, 373, 374, 375, 376, 380, 381, 385, 386, 388, 390, 391, 392, 393, 394, 395, 396, 398, 401, 403, 404, 405, 406, 408, 409, 410, 411, 414, 415, 417, 418, 419, 420, 423, 424, 426, 427, 429, 434, 437, 444, 447, 448, 449, 450, 451, 452, 455, 457]\n",
      "how many unique paths in the filtered pattern? (225, 150)\n",
      "their freq\n",
      " [   1    1    1    2    1    1   11    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    3    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    7    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    2    1    1    1    2    4    1    1    1    1    1    1    1    1\n",
      "    1    2    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    3    2    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    2    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    7    1    1    2    1    1    1    1    1    2    1\n",
      "    1    1    2    1    1    1    1    1    1    1    1    1    1    1\n",
      "    3    1    2    1    1    1    1    1    1    2    1    1    1    1\n",
      "    1    1    1   12    1    1    1    1    2    1    1    4    1    1\n",
      "    5    1   10    1    1    1    3    1    1    1    2    3    1    1\n",
      "    1    1    2    1    1    7    6    3    1    1    1    4    1    1\n",
      "   12    1    1    8    4    8    1  106    2    2   11   13 5423    5\n",
      "    1    3    3    2    1    4    1    2    1    2   11    1    1    1\n",
      "    4] (225,)\n",
      "primary pattern coverage:  0.9155833192638866\n",
      "(6742, 458)\n",
      "threshold:  33.71 6708.29\n",
      "relu_sum, prediction [   1 6519   35   27   10   28    8   22   88    4]\n",
      "non active neurons:  (array([ 68, 161, 257, 266, 267, 279, 288, 292, 319, 325, 326, 338, 343,\n",
      "       345, 374, 375, 385, 386, 392, 401, 403, 411, 414, 418, 444, 448,\n",
      "       451, 452, 453, 454, 455, 457], dtype=int64),)\n",
      "active neurons:  (array([  1,   5,   6,  12,  13,  17,  24,  26,  31,  33,  38,  39,  49,\n",
      "        58,  61,  63,  65,  66,  67,  74,  75,  76,  79,  81,  84,  87,\n",
      "        91,  96,  97,  98,  99, 103, 105, 112, 113, 138, 143, 145, 151,\n",
      "       157, 158, 160, 162, 166, 167, 170, 176, 180, 188, 189, 191, 194,\n",
      "       196, 201, 202, 207, 212, 217, 220, 229, 230, 233, 237, 239, 240,\n",
      "       249, 256, 258, 259, 260, 261, 268, 270, 271, 272, 273, 275, 277,\n",
      "       282, 284, 286, 290, 295, 297, 298, 308, 310, 312, 314, 315, 317,\n",
      "       318, 320, 321, 323, 324, 328, 329, 331, 333, 334, 336, 337, 339,\n",
      "       341, 346, 356, 357, 358, 359, 363, 364, 366, 368, 369, 371, 377,\n",
      "       378, 379, 380, 382, 384, 387, 389, 390, 394, 395, 396, 399, 400,\n",
      "       404, 408, 409, 410, 412, 415, 416, 419, 420, 424, 428, 431, 432,\n",
      "       433, 435, 436, 438, 439, 440, 441, 443], dtype=int64),)\n",
      "WARN: neuro_idx = 449 for label 1 is not stable, let's include it anyway\n",
      "\n",
      "Label is  1\n",
      "Stable ReLUs [1, 5, 6, 12, 13, 17, 24, 26, 31, 33, 38, 39, 49, 58, 61, 63, 65, 66, 67, 68, 74, 75, 76, 79, 81, 84, 87, 91, 96, 97, 98, 99, 103, 105, 112, 113, 138, 143, 145, 151, 157, 158, 160, 161, 162, 166, 167, 170, 176, 180, 188, 189, 191, 194, 196, 201, 202, 207, 212, 217, 220, 229, 230, 233, 237, 239, 240, 249, 256, 257, 258, 259, 260, 261, 266, 267, 268, 270, 271, 272, 273, 275, 277, 279, 282, 284, 286, 288, 290, 292, 295, 297, 298, 308, 310, 312, 314, 315, 317, 318, 319, 320, 321, 323, 324, 325, 326, 328, 329, 331, 333, 334, 336, 337, 338, 339, 341, 343, 345, 346, 356, 357, 358, 359, 363, 364, 366, 368, 369, 371, 374, 375, 377, 378, 379, 380, 382, 384, 385, 386, 387, 389, 390, 392, 394, 395, 396, 399, 400, 401, 403, 404, 408, 409, 410, 411, 412, 414, 415, 416, 418, 419, 420, 424, 428, 431, 432, 433, 435, 436, 438, 439, 440, 441, 443, 444, 448, 449, 451, 452, 453, 454, 455, 457]\n",
      "how many unique paths in the filtered pattern? (200, 184)\n",
      "their freq\n",
      " [   1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    2    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    3    1    3    1    1    1    1    1    1\n",
      "    6    1    1    1    1    2    1    1    1    2   12    1    1    7\n",
      "    1    1    3    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    5    5    1    1    1    1    1\n",
      "    1    1    1    1    1    2    8    1    1    2    1    1    1    1\n",
      "    1    1    1    1    2    1    1    2    6    1    3    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    4    1    1    1    1\n",
      "    9    1    1    1    1    1    1    1    1    4    1    3    1    1\n",
      "    2    1    1    5    3    2    3    1    1    1    1    1    1   14\n",
      "    2    1    1    2    6    7    1    2    1    1    9   68    7    1\n",
      "    5   13 6292    2    9    6    1    1   24    7    1    1    1    1\n",
      "    1    1    1    2] (200,)\n",
      "primary pattern coverage:  0.9332542272322752\n",
      "(5958, 458)\n",
      "threshold:  29.79 5928.21\n",
      "relu_sum, prediction [  72  103 5157  106  116   22  126   98  127   31]\n",
      "non active neurons:  (array([257, 267, 288, 305, 319, 325, 326, 343, 345, 372, 374, 375, 385,\n",
      "       386, 392, 401, 403, 411, 414, 418, 444, 453], dtype=int64),)\n",
      "active neurons:  (array([ 12,  17,  30,  39,  47,  58,  65,  75,  76,  97,  99, 112, 142,\n",
      "       143, 145, 179, 180, 194, 196, 202, 214, 220, 242, 249, 258, 259,\n",
      "       260, 270, 271, 273, 275, 277, 283, 286, 290, 293, 295, 297, 299,\n",
      "       302, 307, 310, 314, 315, 321, 323, 329, 333, 339, 346, 347, 352,\n",
      "       355, 357, 358, 360, 363, 364, 365, 366, 368, 369, 371, 379, 380,\n",
      "       394, 395, 400, 404, 406, 409, 410, 420, 422, 423, 428, 431, 434,\n",
      "       438, 440, 441], dtype=int64),)\n",
      "WARN: neuro_idx = 450 for label 2 is not stable, let's include it anyway\n",
      "\n",
      "Label is  2\n",
      "Stable ReLUs [12, 17, 30, 39, 47, 58, 65, 75, 76, 97, 99, 112, 142, 143, 145, 179, 180, 194, 196, 202, 214, 220, 242, 249, 257, 258, 259, 260, 267, 270, 271, 273, 275, 277, 283, 286, 288, 290, 293, 295, 297, 299, 302, 305, 307, 310, 314, 315, 319, 321, 323, 325, 326, 329, 333, 339, 343, 345, 346, 347, 352, 355, 357, 358, 360, 363, 364, 365, 366, 368, 369, 371, 372, 374, 375, 379, 380, 385, 386, 392, 394, 395, 400, 401, 403, 404, 406, 409, 410, 411, 414, 418, 420, 422, 423, 428, 431, 434, 438, 440, 441, 444, 450, 453]\n",
      "how many unique paths in the filtered pattern? (195, 104)\n",
      "their freq\n",
      " [   1    1    1    2    1    1    1    1    2    4    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    8    1    5    1    1    1\n",
      "    1   12    1    1    1    1    1    1    1    1    1    1    3    1\n",
      "    1    1    1    1    3    1    1    1    6    1    2    1    2    1\n",
      "    1    1    1    1    1    2    1    1    2    1    1    9    4    1\n",
      "    1    1    1    2    2    7    1    1    1    1    1    2    2    1\n",
      "    1    1    1    1    1    3    1    2    2    2    1    1    1    1\n",
      "    1    4    2    1    2    1    4    7    1    2    5    2    1    4\n",
      "    4    1    1    1    1    1    1    1    1    1    2    1   14    1\n",
      "    4    2    1    1    1    1    3    1    1   16    4    1    1    2\n",
      "    1    6    1    4    2    3    1    3    4    1    2    2    1    2\n",
      "    3    1    1    1    1    1    1    4    3    5    1    2  529   19\n",
      " 5039    1    1    1    5    2    1    1    8    3    1    2    3] (195,)\n",
      "primary pattern coverage:  0.8457536085934877\n",
      "(6131, 458)\n",
      "threshold:  30.655 6100.345\n",
      "relu_sum, prediction [  22   42  156 5277    2  323   25   85  144   55]\n",
      "non active neurons:  (array([257, 267, 279, 288, 305, 319, 325, 338, 343, 345, 372, 374, 375,\n",
      "       385, 392, 401, 403, 411, 414, 444, 448, 452, 454], dtype=int64),)\n",
      "active neurons:  (array([  5,   7,  12,  17,  27,  30,  31,  32,  49,  56,  58,  63,  65,\n",
      "        66,  74,  75,  82,  85,  87,  88,  96,  98, 112, 138, 143, 145,\n",
      "       149, 157, 166, 167, 170, 180, 189, 194, 196, 201, 205, 206, 217,\n",
      "       220, 234, 243, 249, 258, 259, 260, 264, 265, 270, 272, 275, 277,\n",
      "       283, 286, 290, 295, 298, 302, 307, 312, 317, 318, 321, 323, 329,\n",
      "       330, 333, 334, 335, 336, 337, 339, 344, 346, 347, 352, 357, 358,\n",
      "       359, 360, 363, 364, 365, 366, 367, 368, 369, 371, 380, 389, 390,\n",
      "       393, 394, 396, 397, 399, 400, 404, 408, 415, 416, 422, 424, 426,\n",
      "       427, 428, 429, 431, 433, 434, 437, 438, 439, 440, 447], dtype=int64),)\n",
      "WARN: neuro_idx = 451 for label 3 is not stable, let's include it anyway\n",
      "\n",
      "Label is  3\n",
      "Stable ReLUs [5, 7, 12, 17, 27, 30, 31, 32, 49, 56, 58, 63, 65, 66, 74, 75, 82, 85, 87, 88, 96, 98, 112, 138, 143, 145, 149, 157, 166, 167, 170, 180, 189, 194, 196, 201, 205, 206, 217, 220, 234, 243, 249, 257, 258, 259, 260, 264, 265, 267, 270, 272, 275, 277, 279, 283, 286, 288, 290, 295, 298, 302, 305, 307, 312, 317, 318, 319, 321, 323, 325, 329, 330, 333, 334, 335, 336, 337, 338, 339, 343, 344, 345, 346, 347, 352, 357, 358, 359, 360, 363, 364, 365, 366, 367, 368, 369, 371, 372, 374, 375, 380, 385, 389, 390, 392, 393, 394, 396, 397, 399, 400, 401, 403, 404, 408, 411, 414, 415, 416, 422, 424, 426, 427, 428, 429, 431, 433, 434, 437, 438, 439, 440, 444, 447, 448, 451, 452, 454]\n",
      "how many unique paths in the filtered pattern? (269, 139)\n",
      "their freq\n",
      " [   1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    3    1    1    1    1    1    3    3    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    3    1    1    1    2    1    1\n",
      "    2    6    1    1    1    1    1    1    4    2    1    1    1    1\n",
      "    1    5    1    1    1    1    1    1    1    1    1    1    1    2\n",
      "    1    1    2    1    1    2    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    3   10    1    1    1    1\n",
      "    1    2    1    1    2    1    1    1    1    1    1    1    6    5\n",
      "    1    1    1    4    1    1    1    1    1    1    1    1    1    1\n",
      "    1   12    2    1    1    1    1    1    1    2    1    1    1    2\n",
      "    1    1    1    1    1    1    1    1    1    2    8    4    1    1\n",
      "    1    6    1    4    1    1    1    8    3    1    1    1    1    1\n",
      "    2    1    1    1    1    1    1    1    1    1    4    1    2    1\n",
      "    1    2    5    8    1    1    1    1    1    1   15    1    3    3\n",
      "   22    1    2    1    1   14    2    9    1    1    1    2    2    2\n",
      "    1    1    1    1    3    1    1    1    5    1    9    1    3    1\n",
      "    4    3    1    2    1    1    1    6    1    4    3    1    1    4\n",
      "    4    2    4    1    1    1   10  540    7 5078   10    3    4    1\n",
      "    1    1    1] (269,)\n",
      "primary pattern coverage:  0.828249877670853\n",
      "(5842, 458)\n",
      "threshold:  29.21 5812.79\n",
      "relu_sum, prediction [  14   22   33    0 5380   12   86    9   42  244]\n",
      "non active neurons:  (array([257, 267, 288, 319, 325, 326, 338, 343, 345, 372, 374, 375, 386,\n",
      "       392, 401, 403, 411, 414, 418, 444, 448, 449, 451, 453, 455],\n",
      "      dtype=int64),)\n",
      "active neurons:  (array([  8,  12,  13,  32,  51,  54,  55,  58,  65,  66,  70,  75,  80,\n",
      "        84,  88,  89,  95,  98, 107, 110, 112, 114, 115, 120, 125, 129,\n",
      "       138, 143, 145, 155, 173, 179, 191, 196, 197, 198, 200, 203, 207,\n",
      "       219, 220, 223, 224, 228, 229, 238, 248, 256, 258, 259, 261, 271,\n",
      "       273, 275, 276, 277, 282, 283, 285, 286, 287, 290, 295, 296, 298,\n",
      "       299, 302, 306, 307, 308, 310, 312, 314, 315, 316, 320, 321, 323,\n",
      "       329, 333, 334, 336, 339, 340, 341, 346, 347, 349, 351, 353, 355,\n",
      "       356, 357, 358, 360, 361, 364, 365, 368, 369, 371, 377, 378, 379,\n",
      "       382, 394, 395, 397, 398, 399, 400, 402, 404, 405, 407, 409, 410,\n",
      "       417, 419, 420, 421, 422, 423, 425, 426, 430, 431, 434, 436, 439,\n",
      "       441, 442], dtype=int64),)\n",
      "WARN: neuro_idx = 452 for label 4 is not stable, let's include it anyway\n",
      "\n",
      "Label is  4\n",
      "Stable ReLUs [8, 12, 13, 32, 51, 54, 55, 58, 65, 66, 70, 75, 80, 84, 88, 89, 95, 98, 107, 110, 112, 114, 115, 120, 125, 129, 138, 143, 145, 155, 173, 179, 191, 196, 197, 198, 200, 203, 207, 219, 220, 223, 224, 228, 229, 238, 248, 256, 257, 258, 259, 261, 267, 271, 273, 275, 276, 277, 282, 283, 285, 286, 287, 288, 290, 295, 296, 298, 299, 302, 306, 307, 308, 310, 312, 314, 315, 316, 319, 320, 321, 323, 325, 326, 329, 333, 334, 336, 338, 339, 340, 341, 343, 345, 346, 347, 349, 351, 353, 355, 356, 357, 358, 360, 361, 364, 365, 368, 369, 371, 372, 374, 375, 377, 378, 379, 382, 386, 392, 394, 395, 397, 398, 399, 400, 401, 402, 403, 404, 405, 407, 409, 410, 411, 414, 417, 418, 419, 420, 421, 422, 423, 425, 426, 430, 431, 434, 436, 439, 441, 442, 444, 448, 449, 451, 452, 453, 455]\n",
      "how many unique paths in the filtered pattern? (212, 158)\n",
      "their freq\n",
      " [   1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    5    1    1    1    1    1    1    2    1    1    3    9    1    1\n",
      "    1    1    1    1    2    1    1    1    3    8    1    1    1    1\n",
      "    1    1    1    3    1    1    1    1    1    1    6    1    1    1\n",
      "    1    1    1    4    6    1    1    1    1    1    1    1    1    1\n",
      "    9    1    1    1    1    1    1    1    1    1    2    3    2    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    2    1\n",
      "    8    1    1    1    1    1    1    1    1    3   13    1    1    1\n",
      "   21    1    4    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    9    1    1    1    1    3    3    1    4    1    1    1    1\n",
      "    1    8    1    2    1    1    1    1    2    1    1    1    1    2\n",
      "    4    1    2    1    2    1    1    1    6    2    1    7    5    2\n",
      "    8    1    1    3    2    3    2    1    2    3    1    1    1    1\n",
      "    3    2    1  299    1    4 5148    5    8    1    3    1    6    1\n",
      "    2    1] (212,)\n",
      "primary pattern coverage:  0.8812050667579596\n",
      "(5421, 458)\n",
      "threshold:  27.105 5393.8949999999995\n",
      "relu_sum, prediction [  93   59   37  228   96 4560  113   34  128   73]\n",
      "non active neurons:  (array([257, 267, 325, 338, 343, 345, 372, 374, 375, 385, 392, 401, 403,\n",
      "       411, 414, 418, 444], dtype=int64),)\n",
      "active neurons:  (array([ 17,  27,  31,  41,  56,  58,  66,  70,  75,  87,  88,  96,  97,\n",
      "       112, 138, 142, 143, 145, 157, 167, 173, 179, 191, 194, 196, 220,\n",
      "       223, 238, 256, 258, 259, 260, 261, 265, 270, 272, 275, 277, 283,\n",
      "       285, 286, 287, 290, 295, 298, 301, 302, 307, 317, 318, 321, 323,\n",
      "       329, 336, 339, 340, 346, 347, 349, 351, 352, 357, 358, 360, 365,\n",
      "       366, 369, 371, 377, 378, 380, 382, 390, 393, 394, 395, 396, 397,\n",
      "       399, 400, 404, 406, 408, 417, 419, 420, 422, 423, 424, 426, 429,\n",
      "       431, 433, 434], dtype=int64),)\n",
      "WARN: neuro_idx = 453 for label 5 is not stable, let's include it anyway\n",
      "\n",
      "Label is  5\n",
      "Stable ReLUs [17, 27, 31, 41, 56, 58, 66, 70, 75, 87, 88, 96, 97, 112, 138, 142, 143, 145, 157, 167, 173, 179, 191, 194, 196, 220, 223, 238, 256, 257, 258, 259, 260, 261, 265, 267, 270, 272, 275, 277, 283, 285, 286, 287, 290, 295, 298, 301, 302, 307, 317, 318, 321, 323, 325, 329, 336, 338, 339, 340, 343, 345, 346, 347, 349, 351, 352, 357, 358, 360, 365, 366, 369, 371, 372, 374, 375, 377, 378, 380, 382, 385, 390, 392, 393, 394, 395, 396, 397, 399, 400, 401, 403, 404, 406, 408, 411, 414, 417, 418, 419, 420, 422, 423, 424, 426, 429, 431, 433, 434, 444, 453]\n",
      "how many unique paths in the filtered pattern? (190, 112)\n",
      "their freq\n",
      " [   1    1    1    4    1    1    1    1    1    1    1    1    1    1\n",
      "    3    2    1    1    2    1    1    1    1    1    3    5    1    1\n",
      "    1    1    1    1    1    1    9    3    1    1    1    1    1    1\n",
      "    1    2    1    1    8    1    1    1    1    5    1    1    1    1\n",
      "    1    1    1    3    3    1    1    1    1    1    1    3    2    4\n",
      "    1    2    1    1    1    1    1    6    5    2    1    1    1    1\n",
      "    1    1    2    5    2    1    1    1    1    1    1    2    1    1\n",
      "    1    1    1    1    8    1    1    8    1    1    1    1    3    1\n",
      "    1    1    1    1    1    1    2    1    1    1    1    1    1    1\n",
      "    1    1    8    3    1    1    1    4    3    1    1    2    1    2\n",
      "    2    1    1    1    3    1    7    2    1    1    1    4    1    2\n",
      "   19    1    2    3    1    7    1    2    2    2    1    4    1    4\n",
      "    1    3    5   14    2    1  631 4413    1    1    9    2    2    3\n",
      "    3    1    1    1    1    1    5    6] (190,)\n",
      "primary pattern coverage:  0.8140564471499724\n",
      "(5918, 458)\n",
      "threshold:  29.59 5888.41\n",
      "relu_sum, prediction [  57   31   44    1   68   85 5606    1   25    0]\n",
      "non active neurons:  (array([255, 257, 267, 288, 305, 325, 338, 343, 345, 372, 374, 375, 385,\n",
      "       386, 392, 401, 403, 411, 414, 418, 444, 451, 455, 456, 457],\n",
      "      dtype=int64),)\n",
      "active neurons:  (array([ 13,  17,  19,  26,  30,  32,  39,  47,  55,  56,  58,  66,  70,\n",
      "        76,  79,  84,  97,  98, 116, 129, 130, 133, 141, 142, 143, 145,\n",
      "       158, 167, 173, 176, 179, 194, 196, 200, 202, 203, 207, 210, 214,\n",
      "       219, 220, 238, 242, 249, 253, 256, 258, 259, 260, 261, 263, 265,\n",
      "       269, 273, 275, 277, 283, 284, 285, 286, 287, 295, 296, 297, 299,\n",
      "       302, 304, 306, 307, 309, 310, 314, 315, 316, 321, 323, 329, 333,\n",
      "       335, 336, 339, 340, 342, 346, 347, 349, 351, 352, 353, 356, 357,\n",
      "       358, 360, 363, 364, 365, 366, 368, 369, 371, 377, 378, 379, 380,\n",
      "       382, 387, 391, 394, 395, 396, 404, 405, 406, 407, 409, 410, 417,\n",
      "       419, 420, 422, 423, 425, 427, 428, 431, 434, 440, 441], dtype=int64),)\n",
      "WARN: neuro_idx = 454 for label 6 is not stable, let's include it anyway\n",
      "\n",
      "Label is  6\n",
      "Stable ReLUs [13, 17, 19, 26, 30, 32, 39, 47, 55, 56, 58, 66, 70, 76, 79, 84, 97, 98, 116, 129, 130, 133, 141, 142, 143, 145, 158, 167, 173, 176, 179, 194, 196, 200, 202, 203, 207, 210, 214, 219, 220, 238, 242, 249, 253, 255, 256, 257, 258, 259, 260, 261, 263, 265, 267, 269, 273, 275, 277, 283, 284, 285, 286, 287, 288, 295, 296, 297, 299, 302, 304, 305, 306, 307, 309, 310, 314, 315, 316, 321, 323, 325, 329, 333, 335, 336, 338, 339, 340, 342, 343, 345, 346, 347, 349, 351, 352, 353, 356, 357, 358, 360, 363, 364, 365, 366, 368, 369, 371, 372, 374, 375, 377, 378, 379, 380, 382, 385, 386, 387, 391, 392, 394, 395, 396, 401, 403, 404, 405, 406, 407, 409, 410, 411, 414, 417, 418, 419, 420, 422, 423, 425, 427, 428, 431, 434, 440, 441, 444, 451, 454, 455, 456, 457]\n",
      "how many unique paths in the filtered pattern? (197, 154)\n",
      "their freq\n",
      " [   1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    2    1    1    1    2    1    1    1    8    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    2\n",
      "    1    2    1    1    1    1    1    1    1    1    1    1    1    2\n",
      "    1    1    2    3    1    1    1    1    1    1    1    1    2    1\n",
      "    1    2    6    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    4   13\n",
      "    1    1    1    1    1    1    1    1    2   12    1    1    2    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    8    1\n",
      "    1    1    1    1    2    1    1    1    1    2    2    1    1    1\n",
      "    1    1    2   20    2    1    9    1    1    1    1    3    2    3\n",
      "    4    1    2    2    3    1    3    1    4    2    2    1    2    2\n",
      "    3    4    1    1    3    1    1    6    1    1    4    5    7    6\n",
      "    1    1    1  146    8 5417    5    1    1    2    1    1    1    1\n",
      "    9] (197,)\n",
      "primary pattern coverage:  0.9153430212909767\n",
      "(6265, 458)\n",
      "threshold:  31.325 6233.675\n",
      "relu_sum, prediction [  31   47   93   28   83   15    1 5789   20  158]\n",
      "non active neurons:  (array([257, 267, 279, 288, 305, 319, 326, 338, 343, 345, 372, 374, 375,\n",
      "       401, 403, 414, 418, 448, 451, 453, 454, 456], dtype=int64),)\n",
      "active neurons:  (array([  7,   8,  26,  31,  49,  54,  58,  63,  66,  70,  75,  82,  87,\n",
      "        96,  98, 107, 112, 115, 124, 125, 129, 131, 138, 142, 143, 144,\n",
      "       145, 155, 170, 189, 191, 192, 196, 206, 216, 220, 223, 228, 229,\n",
      "       231, 235, 239, 258, 259, 260, 264, 265, 270, 272, 273, 275, 276,\n",
      "       277, 282, 283, 284, 285, 286, 295, 296, 298, 299, 306, 307, 308,\n",
      "       309, 312, 314, 317, 318, 320, 323, 329, 330, 332, 333, 334, 336,\n",
      "       339, 341, 344, 346, 349, 350, 359, 360, 361, 365, 367, 369, 377,\n",
      "       380, 388, 389, 391, 396, 402, 404, 405, 406, 407, 408, 415, 416,\n",
      "       417, 422, 424, 426, 430, 431, 433, 434, 436, 439, 442, 443, 447],\n",
      "      dtype=int64),)\n",
      "WARN: neuro_idx = 455 for label 7 is not stable, let's include it anyway\n",
      "\n",
      "Label is  7\n",
      "Stable ReLUs [7, 8, 26, 31, 49, 54, 58, 63, 66, 70, 75, 82, 87, 96, 98, 107, 112, 115, 124, 125, 129, 131, 138, 142, 143, 144, 145, 155, 170, 189, 191, 192, 196, 206, 216, 220, 223, 228, 229, 231, 235, 239, 257, 258, 259, 260, 264, 265, 267, 270, 272, 273, 275, 276, 277, 279, 282, 283, 284, 285, 286, 288, 295, 296, 298, 299, 305, 306, 307, 308, 309, 312, 314, 317, 318, 319, 320, 323, 326, 329, 330, 332, 333, 334, 336, 338, 339, 341, 343, 344, 345, 346, 349, 350, 359, 360, 361, 365, 367, 369, 372, 374, 375, 377, 380, 388, 389, 391, 396, 401, 402, 403, 404, 405, 406, 407, 408, 414, 415, 416, 417, 418, 422, 424, 426, 430, 431, 433, 434, 436, 439, 442, 443, 447, 448, 451, 453, 454, 455, 456]\n",
      "how many unique paths in the filtered pattern? (254, 140)\n",
      "their freq\n",
      " [   1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1   14    1    1    1    1    1    2    1    1    1    1\n",
      "    1    2    1    2    5    1    1    1    2    1    1    1    1    1\n",
      "    1    1    1    1    1    1    2    1    2    1    1    1    1    3\n",
      "    1    1    1    8    1    2    1    1    1    1    1    1    1    1\n",
      "    1    1    1    3    1    1    1    1    1    1    1    1    1    2\n",
      "    1    7    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    2    1    1    1    1    1    1    1    1    2    1    2    1\n",
      "    1    1    1    1    1    1    2    1    2    1    1    1    1    1\n",
      "    1    1   14    1    1    1    1    1    2    1    3    3    1    1\n",
      "    1    1    1    3    1    1    2    1    1    1   16    1    1    1\n",
      "    1    1    1    2    2    1    1    1    1    1    1    1    2    3\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    2    6    1    1   13    1    4    1    1    1    2    1    1    1\n",
      "    1    3    1    3    3    1    2    1    1    2    5    3    1    2\n",
      "    1    1    1    2    2    3    3    1    2    5    2    1    2  234\n",
      "   10 5579    1   10   14    8    4    5    9    1    1    2    1    2\n",
      "    4    5] (254,)\n",
      "primary pattern coverage:  0.8905027932960894\n",
      "(5851, 458)\n",
      "threshold:  29.255 5821.745\n",
      "relu_sum, prediction [  26  144   81  185   47  206   52   13 4966  131]\n",
      "non active neurons:  (array([257, 267, 279, 288, 305, 325, 326, 338, 343, 345, 354, 372, 374,\n",
      "       375, 386, 392, 401, 403, 411, 414, 418, 444, 448, 455], dtype=int64),)\n",
      "active neurons:  (array([  6,  12,  13,  17,  27,  30,  31,  32,  39,  41,  49,  51,  55,\n",
      "        56,  58,  65,  66,  69,  70,  74,  75,  80,  83,  84,  85,  87,\n",
      "        88,  96,  97,  98, 107, 110, 112, 115, 119, 122, 129, 138, 142,\n",
      "       143, 145, 157, 166, 167, 170, 173, 179, 185, 188, 189, 191, 194,\n",
      "       195, 196, 198, 201, 202, 207, 217, 220, 223, 229, 230, 231, 234,\n",
      "       238, 239, 240, 242, 248, 249, 256, 258, 259, 260, 261, 270, 271,\n",
      "       272, 273, 274, 275, 277, 282, 283, 285, 286, 287, 290, 295, 297,\n",
      "       298, 299, 302, 306, 307, 308, 310, 312, 316, 317, 318, 321, 323,\n",
      "       329, 333, 336, 339, 340, 341, 346, 347, 349, 352, 355, 356, 357,\n",
      "       358, 360, 363, 364, 365, 366, 368, 369, 371, 377, 379, 380, 382,\n",
      "       389, 390, 393, 394, 395, 396, 399, 400, 404, 405, 406, 408, 410,\n",
      "       415, 417, 419, 420, 421, 422, 423, 424, 426, 428, 429, 431, 432,\n",
      "       433, 434, 438, 440, 441], dtype=int64),)\n",
      "WARN: neuro_idx = 456 for label 8 is not stable, let's include it anyway\n",
      "\n",
      "Label is  8\n",
      "Stable ReLUs [6, 12, 13, 17, 27, 30, 31, 32, 39, 41, 49, 51, 55, 56, 58, 65, 66, 69, 70, 74, 75, 80, 83, 84, 85, 87, 88, 96, 97, 98, 107, 110, 112, 115, 119, 122, 129, 138, 142, 143, 145, 157, 166, 167, 170, 173, 179, 185, 188, 189, 191, 194, 195, 196, 198, 201, 202, 207, 217, 220, 223, 229, 230, 231, 234, 238, 239, 240, 242, 248, 249, 256, 257, 258, 259, 260, 261, 267, 270, 271, 272, 273, 274, 275, 277, 279, 282, 283, 285, 286, 287, 288, 290, 295, 297, 298, 299, 302, 305, 306, 307, 308, 310, 312, 316, 317, 318, 321, 323, 325, 326, 329, 333, 336, 338, 339, 340, 341, 343, 345, 346, 347, 349, 352, 354, 355, 356, 357, 358, 360, 363, 364, 365, 366, 368, 369, 371, 372, 374, 375, 377, 379, 380, 382, 386, 389, 390, 392, 393, 394, 395, 396, 399, 400, 401, 403, 404, 405, 406, 408, 410, 411, 414, 415, 417, 418, 419, 420, 421, 422, 423, 424, 426, 428, 429, 431, 432, 433, 434, 438, 440, 441, 444, 448, 455, 456]\n",
      "how many unique paths in the filtered pattern? (300, 186)\n",
      "their freq\n",
      " [   1    1    1    1    1    1    1    1    1    1    1    1    1    2\n",
      "    1    2    8    8    1    1    1    1    1    1    1    1    1    1\n",
      "    1    2    1    1    1    1    1    1    1    1    1    1    1    4\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    7    2    2    1    1    1    2    1    1\n",
      "    3    1    1    1    3    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    4    4    1    1    1    1    1    6    1    1    1    1    1\n",
      "    1    1    1    1    1    1    3    4    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    3\n",
      "    1    1    1    1    1    3    7    1    3    1    2    1    9    6\n",
      "    1    3    2    3    1    1    1    1    1    1    1    1    1    2\n",
      "    8    1    1    1    1    2    1    1    1    1    1    1    1    2\n",
      "    5    1    1    1    2    1    3    1    2    1    1    1    1    1\n",
      "    3    1    1    1    1    3    5    1    1    2    1    1    1   12\n",
      "    1    1    1    2    1    1    1    4    1    1    1    1    1    1\n",
      "    1    3    2    2    2    1    1    1    1    7    3    1    1    1\n",
      "    1    5    1    1    1    1    1    1    1    4    3    1    4    3\n",
      "    1    3    3    1    1    2    3    1    1    1    1    1    1   12\n",
      "    3    2    1    4    6    1    2    4    2    1    1    1    2    1\n",
      "    1    2    1    1    1    1  534 4792    6   14    3   12    1    1\n",
      "    1    1    1    1    7    6] (300,)\n",
      "primary pattern coverage:  0.8190052982396172\n",
      "(5949, 458)\n",
      "threshold:  29.745 5919.255\n",
      "relu_sum, prediction [  43   21   22   76  249   43   10  247   72 5166]\n",
      "non active neurons:  (array([257, 267, 288, 305, 319, 325, 326, 338, 343, 345, 372, 374, 375,\n",
      "       386, 392, 401, 403, 411, 414, 418, 444, 449, 450, 454], dtype=int64),)\n",
      "active neurons:  (array([  8,  12,  17,  26,  30,  49,  51,  54,  55,  58,  65,  66,  70,\n",
      "        75,  76,  80,  84,  87,  89,  96,  98, 107, 112, 115, 119, 125,\n",
      "       129, 138, 143, 144, 145, 155, 170, 179, 189, 191, 196, 201, 218,\n",
      "       220, 223, 228, 229, 231, 234, 238, 239, 248, 258, 259, 264, 272,\n",
      "       273, 275, 277, 282, 283, 285, 286, 295, 296, 298, 299, 302, 306,\n",
      "       307, 308, 310, 312, 314, 317, 318, 320, 321, 323, 329, 330, 332,\n",
      "       333, 334, 336, 339, 340, 341, 344, 346, 347, 349, 350, 351, 353,\n",
      "       357, 358, 359, 360, 361, 363, 364, 365, 366, 367, 368, 369, 371,\n",
      "       377, 379, 380, 389, 391, 394, 395, 398, 402, 404, 405, 407, 415,\n",
      "       417, 421, 422, 423, 426, 430, 431, 432, 434, 436, 438, 439, 442],\n",
      "      dtype=int64),)\n",
      "WARN: neuro_idx = 457 for label 9 is not stable, let's include it anyway\n",
      "\n",
      "Label is  9\n",
      "Stable ReLUs [8, 12, 17, 26, 30, 49, 51, 54, 55, 58, 65, 66, 70, 75, 76, 80, 84, 87, 89, 96, 98, 107, 112, 115, 119, 125, 129, 138, 143, 144, 145, 155, 170, 179, 189, 191, 196, 201, 218, 220, 223, 228, 229, 231, 234, 238, 239, 248, 257, 258, 259, 264, 267, 272, 273, 275, 277, 282, 283, 285, 286, 288, 295, 296, 298, 299, 302, 305, 306, 307, 308, 310, 312, 314, 317, 318, 319, 320, 321, 323, 325, 326, 329, 330, 332, 333, 334, 336, 338, 339, 340, 341, 343, 344, 345, 346, 347, 349, 350, 351, 353, 357, 358, 359, 360, 361, 363, 364, 365, 366, 367, 368, 369, 371, 372, 374, 375, 377, 379, 380, 386, 389, 391, 392, 394, 395, 398, 401, 402, 403, 404, 405, 407, 411, 414, 415, 417, 418, 421, 422, 423, 426, 430, 431, 432, 434, 436, 438, 439, 442, 444, 449, 450, 454, 457]\n",
      "how many unique paths in the filtered pattern? (260, 155)\n",
      "their freq\n",
      " [   1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    2    1    1    1    1    1    2    1\n",
      "    7    3    1    1    1    2    1    1    1    1    1    1    1    1\n",
      "    1    1    2    1    1    1    1    1    8    1    1    1    1    1\n",
      "    1    1    1    1    1    1    2    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    4    1\n",
      "    1    1    1    3    2    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    4    1    1    1    1    1    1    1    5    1\n",
      "    1    1    1    1    1    2    1    1    1    2    9    1    1    1\n",
      "    1    8    1   19    1    1    1    1    1    1    1    1    1    1\n",
      "    8    2    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    2    2    2    1    1    1    1    3    1    3    2\n",
      "    1    2    2    1    1    1    1    1    1    1    1    3    1    1\n",
      "    1    1    3    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    3    5    2    1    2    1    1    1    1    1    2\n",
      "    1    1    1    1    1    1    1    1    3    1    1    1    1    2\n",
      "    1    1    1    1    5    1    1    2    1    1    1    1    1    1\n",
      "    5    4    2  486 5053    3   11    1    8    1    2    1    2    5\n",
      "    1    1    5    1    1    3    3    5] (260,)\n",
      "primary pattern coverage:  0.8493864515044546\n",
      "(5923, 458)\n",
      "threshold:  59.230000000000004 5863.7699999999995\n",
      "relu_sum, prediction [5685    0   29   15   11   77   48   11   43    4]\n",
      "non active neurons:  (array([225, 257, 267, 279, 288, 305, 325, 326, 338, 343, 345, 370, 372,\n",
      "       373, 374, 375, 376, 381, 385, 386, 392, 401, 403, 411, 414, 418,\n",
      "       444, 449, 450, 451, 452, 454, 455, 456, 457], dtype=int64),)\n",
      "active neurons:  (array([ 18,  19,  26,  27,  30,  31,  45,  46,  55,  56,  63,  70,  72,\n",
      "        74,  75,  82,  83,  85,  86,  88,  97, 100, 103, 112, 115, 116,\n",
      "       127, 136, 138, 140, 141, 142, 143, 144, 145, 147, 148, 159, 165,\n",
      "       170, 171, 172, 173, 179, 185, 192, 193, 194, 196, 198, 205, 209,\n",
      "       210, 213, 217, 222, 234, 235, 238, 241, 243, 247, 258, 259, 260,\n",
      "       264, 265, 269, 271, 272, 274, 275, 276, 277, 283, 284, 285, 287,\n",
      "       289, 290, 293, 295, 297, 298, 301, 302, 303, 306, 307, 309, 314,\n",
      "       316, 318, 321, 323, 329, 339, 340, 342, 344, 346, 347, 348, 349,\n",
      "       351, 352, 357, 358, 360, 362, 365, 366, 367, 369, 371, 380, 382,\n",
      "       388, 390, 391, 393, 394, 395, 396, 397, 398, 399, 404, 405, 406,\n",
      "       408, 409, 410, 415, 417, 419, 420, 422, 423, 424, 426, 427, 429,\n",
      "       434, 437, 445, 447], dtype=int64),)\n",
      "WARN: neuro_idx = 448 for label 0 is not stable, let's include it anyway\n",
      "\n",
      "Label is  0\n",
      "Stable ReLUs [18, 19, 26, 27, 30, 31, 45, 46, 55, 56, 63, 70, 72, 74, 75, 82, 83, 85, 86, 88, 97, 100, 103, 112, 115, 116, 127, 136, 138, 140, 141, 142, 143, 144, 145, 147, 148, 159, 165, 170, 171, 172, 173, 179, 185, 192, 193, 194, 196, 198, 205, 209, 210, 213, 217, 222, 225, 234, 235, 238, 241, 243, 247, 257, 258, 259, 260, 264, 265, 267, 269, 271, 272, 274, 275, 276, 277, 279, 283, 284, 285, 287, 288, 289, 290, 293, 295, 297, 298, 301, 302, 303, 305, 306, 307, 309, 314, 316, 318, 321, 323, 325, 326, 329, 338, 339, 340, 342, 343, 344, 345, 346, 347, 348, 349, 351, 352, 357, 358, 360, 362, 365, 366, 367, 369, 370, 371, 372, 373, 374, 375, 376, 380, 381, 382, 385, 386, 388, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 401, 403, 404, 405, 406, 408, 409, 410, 411, 414, 415, 417, 418, 419, 420, 422, 423, 424, 426, 427, 429, 434, 437, 444, 445, 447, 448, 449, 450, 451, 452, 454, 455, 456, 457]\n",
      "how many unique paths in the filtered pattern? (432, 183)\n",
      "their freq\n",
      " [   1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    4\n",
      "    1    4    1    1    1    1    1    1    1    4    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    5    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    2    1    1    6    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    2    1    2\n",
      "    1    1    1    1    1    2    1    1    1    1    2    1    1   13\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    2    1    4    1    1    1    1    1    1    1\n",
      "    2    1    1    2    2    2   12    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    2    1   23    2    1    1    1\n",
      "    1    1    1    1    1    1    1    1    2    2    1    1    1    1\n",
      "    1    1    2    1    1    1    1    1    1   20    1    1    1    1\n",
      "    1    1    1    1    2    1    2    1    1    1    8    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    2    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    2    1    1    1    1    1    2    1    1    2\n",
      "    1    1   33    1    1    1    1    1    1    1    1    1    1    2\n",
      "    1    2    1    3    1    1    1    1    2    1    1    1    2    1\n",
      "    1    2   12    1    3   18    1    1    2    1    2    1    1    1\n",
      "   10    1    1    1    1    1    1    1    1    1    4    1    1    1\n",
      "    1    1    5    1    1    2    1    1    2   10    1    1    1    8\n",
      "    1    1    1    2    1    7    1    1    1    1    3    1    7    1\n",
      "    1    1    1    8    1    1    1    1    6    1    1    1    1    1\n",
      "    1    1    1    3    1    1    1   42    1    4    1    2    3    1\n",
      "    1    2    9    3   10    4    3    1    7    2   11    3    3    1\n",
      "    2   43    1   24    8    7    8 5010    2    1    3    1    1    1\n",
      "    1    1   10    1    1    3    1    1    1    1    1   43] (432,)\n",
      "primary pattern coverage:  0.8458551409758568\n",
      "(6742, 458)\n",
      "threshold:  67.42 6674.58\n",
      "relu_sum, prediction [   1 6519   35   27   10   28    8   22   88    4]\n",
      "non active neurons:  (array([ 28,  68, 126, 161, 244, 257, 266, 267, 279, 288, 292, 319, 325,\n",
      "       326, 338, 343, 345, 374, 375, 385, 386, 392, 401, 403, 411, 414,\n",
      "       418, 444, 448, 450, 451, 452, 453, 454, 455, 457], dtype=int64),)\n",
      "active neurons:  (array([  1,   5,   6,  12,  13,  14,  17,  24,  26,  31,  33,  38,  39,\n",
      "        49,  51,  52,  57,  58,  61,  63,  64,  65,  66,  67,  74,  75,\n",
      "        76,  79,  80,  81,  84,  87,  91,  96,  97,  98,  99, 103, 105,\n",
      "       112, 113, 119, 124, 138, 143, 145, 151, 153, 157, 158, 160, 162,\n",
      "       166, 167, 169, 170, 176, 180, 185, 188, 189, 191, 194, 196, 201,\n",
      "       202, 207, 212, 217, 220, 229, 230, 233, 237, 239, 240, 249, 250,\n",
      "       256, 258, 259, 260, 261, 265, 268, 270, 271, 272, 273, 275, 277,\n",
      "       282, 283, 284, 286, 290, 295, 297, 298, 301, 304, 308, 310, 312,\n",
      "       314, 315, 316, 317, 318, 320, 321, 323, 324, 328, 329, 331, 333,\n",
      "       334, 336, 337, 339, 341, 346, 355, 356, 357, 358, 359, 363, 364,\n",
      "       366, 368, 369, 371, 373, 377, 378, 379, 380, 382, 384, 387, 389,\n",
      "       390, 394, 395, 396, 399, 400, 404, 408, 409, 410, 412, 413, 415,\n",
      "       416, 419, 420, 424, 427, 428, 431, 432, 433, 435, 436, 438, 439,\n",
      "       440, 441, 442, 443], dtype=int64),)\n",
      "WARN: neuro_idx = 449 for label 1 is not stable, let's include it anyway\n",
      "\n",
      "Label is  1\n",
      "Stable ReLUs [1, 5, 6, 12, 13, 14, 17, 24, 26, 28, 31, 33, 38, 39, 49, 51, 52, 57, 58, 61, 63, 64, 65, 66, 67, 68, 74, 75, 76, 79, 80, 81, 84, 87, 91, 96, 97, 98, 99, 103, 105, 112, 113, 119, 124, 126, 138, 143, 145, 151, 153, 157, 158, 160, 161, 162, 166, 167, 169, 170, 176, 180, 185, 188, 189, 191, 194, 196, 201, 202, 207, 212, 217, 220, 229, 230, 233, 237, 239, 240, 244, 249, 250, 256, 257, 258, 259, 260, 261, 265, 266, 267, 268, 270, 271, 272, 273, 275, 277, 279, 282, 283, 284, 286, 288, 290, 292, 295, 297, 298, 301, 304, 308, 310, 312, 314, 315, 316, 317, 318, 319, 320, 321, 323, 324, 325, 326, 328, 329, 331, 333, 334, 336, 337, 338, 339, 341, 343, 345, 346, 355, 356, 357, 358, 359, 363, 364, 366, 368, 369, 371, 373, 374, 375, 377, 378, 379, 380, 382, 384, 385, 386, 387, 389, 390, 392, 394, 395, 396, 399, 400, 401, 403, 404, 408, 409, 410, 411, 412, 413, 414, 415, 416, 418, 419, 420, 424, 427, 428, 431, 432, 433, 435, 436, 438, 439, 440, 441, 442, 443, 444, 448, 449, 450, 451, 452, 453, 454, 455, 457]\n",
      "how many unique paths in the filtered pattern? (351, 210)\n",
      "their freq\n",
      " [   1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    8    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    2    1    1    1    1    1    2    1    1   36    5    6    7\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    2    1\n",
      "    1    2    9    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    2    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    2    1    1    1    1    1    1\n",
      "    1    1    4    1    1    1    2    1    1    1    1    1    1    1\n",
      "    1    1    1    1   12    1    2    1    1    1    1    2    7    1\n",
      "    1    2    4    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1   13    1    1    1    1    1    1\n",
      "    1    1    1    1    3    1    1    1    1    1    1    1    1    1\n",
      "    1    1   19    1    1    2    1    1    1    1    1    1    1    2\n",
      "    1    1    5    1    1    1    1    2    1   24    1    4    1    1\n",
      "    1    1    2   23    1    1    1    3    1    1    3    1    4    1\n",
      "    1    1    1    1    1    2    2    1   13    1    1    2    1    5\n",
      "    1    1    1    1    2    1    1    2   29    1    3    1   31    1\n",
      "    1    1    9    1    1    4    1   27    1    1   14    1    1    5\n",
      "    1    1    4    2    5    1    1   18    1    6    1   36    4    3\n",
      "    6    3 5913    1    1   23    7    1    1    1    1    1    1    1\n",
      "   14    1    1    1    1   17    2    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    7\n",
      "   11] (351,)\n",
      "primary pattern coverage:  0.8770394541679027\n",
      "(5958, 458)\n",
      "threshold:  59.58 5898.42\n",
      "relu_sum, prediction [  72  103 5157  106  116   22  126   98  127   31]\n",
      "non active neurons:  (array([257, 267, 288, 305, 319, 325, 326, 338, 343, 345, 354, 372, 374,\n",
      "       375, 385, 386, 392, 401, 403, 411, 414, 418, 444, 453, 457],\n",
      "      dtype=int64),)\n",
      "active neurons:  (array([ 12,  13,  17,  26,  30,  32,  39,  47,  52,  55,  58,  63,  65,\n",
      "        72,  75,  76,  97,  98,  99, 112, 130, 132, 141, 142, 143, 145,\n",
      "       170, 179, 180, 194, 196, 202, 205, 207, 214, 220, 238, 242, 249,\n",
      "       258, 259, 260, 269, 270, 271, 273, 275, 277, 283, 286, 290, 293,\n",
      "       295, 297, 299, 302, 307, 310, 314, 315, 318, 321, 323, 329, 333,\n",
      "       335, 339, 346, 347, 352, 355, 357, 358, 360, 363, 364, 365, 366,\n",
      "       368, 369, 371, 379, 380, 387, 390, 394, 395, 396, 400, 404, 406,\n",
      "       408, 409, 410, 416, 420, 422, 423, 427, 428, 431, 432, 434, 438,\n",
      "       440, 441], dtype=int64),)\n",
      "WARN: neuro_idx = 450 for label 2 is not stable, let's include it anyway\n",
      "\n",
      "Label is  2\n",
      "Stable ReLUs [12, 13, 17, 26, 30, 32, 39, 47, 52, 55, 58, 63, 65, 72, 75, 76, 97, 98, 99, 112, 130, 132, 141, 142, 143, 145, 170, 179, 180, 194, 196, 202, 205, 207, 214, 220, 238, 242, 249, 257, 258, 259, 260, 267, 269, 270, 271, 273, 275, 277, 283, 286, 288, 290, 293, 295, 297, 299, 302, 305, 307, 310, 314, 315, 318, 319, 321, 323, 325, 326, 329, 333, 335, 338, 339, 343, 345, 346, 347, 352, 354, 355, 357, 358, 360, 363, 364, 365, 366, 368, 369, 371, 372, 374, 375, 379, 380, 385, 386, 387, 390, 392, 394, 395, 396, 400, 401, 403, 404, 406, 408, 409, 410, 411, 414, 416, 418, 420, 422, 423, 427, 428, 431, 432, 434, 438, 440, 441, 444, 450, 453, 457]\n",
      "how many unique paths in the filtered pattern? (384, 132)\n",
      "their freq\n",
      " [   1    1    1    1    1    1    2    1    1    1    1    3    1    1\n",
      "    1    1    1    2    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    2    4    1    1    1    1\n",
      "    1    4   10    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1   20    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    3\n",
      "    1   10    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    6    1    5    1    1    1    1    1    2    1    1    2    1    1\n",
      "    1    9    2   16    1    1    1    1    1    1    1    1    1    1\n",
      "    1    2    2    1    1    1    1    3    3    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1   14    1    6    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1   12    1    1\n",
      "    1    1    6   13    1    1    1    1    1    1    1    1    1    1\n",
      "    4    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    5    1    2    1    1    1    3    1    1    4    1    5    1    1\n",
      "    1    1    1    1    1    1    3    2    1    1    1    1    1    1\n",
      "    1    1    1    1    1    2    1    1    1    7    1    3    1    1\n",
      "    1    1    5    3    1    1    2    4    1    1    1    1    1    1\n",
      "    1    1    1    6    1    1    1    1    1    1    1    1    1    4\n",
      "    2    1    1    1    1    1    1    1    1    3    2    1    1    1\n",
      "    1    1    1    1    1    7    1    1    1    1    2    7    1    2\n",
      "    2    3    1   12    4    2    3    1    2    8    4    1    4    1\n",
      "    1    1    2    2    2    2   10    2    1    1    1    2    1    3\n",
      "    2    6    1    1    1    1    4    1    5    1   15    1    4    2\n",
      "    4    1  364   18   13 4842    1    5    1    1    4    7    1   34\n",
      "    2    1    5    2    1    3] (384,)\n",
      "primary pattern coverage:  0.8126888217522659\n",
      "(6131, 458)\n",
      "threshold:  61.31 6069.69\n",
      "relu_sum, prediction [  22   42  156 5277    2  323   25   85  144   55]\n",
      "non active neurons:  (array([ 68, 126, 225, 257, 267, 279, 288, 305, 319, 325, 326, 338, 343,\n",
      "       345, 370, 372, 374, 375, 385, 386, 392, 401, 403, 411, 414, 418,\n",
      "       444, 448, 449, 452, 454, 457], dtype=int64),)\n",
      "active neurons:  (array([  1,   5,   6,   7,  12,  17,  27,  30,  31,  32,  41,  49,  56,\n",
      "        58,  63,  65,  66,  69,  74,  75,  82,  83,  85,  87,  88,  96,\n",
      "        97,  98, 112, 132, 138, 140, 143, 145, 149, 157, 166, 167, 170,\n",
      "       174, 180, 185, 189, 194, 196, 201, 202, 205, 206, 217, 220, 229,\n",
      "       234, 243, 249, 256, 258, 259, 260, 261, 264, 265, 270, 272, 274,\n",
      "       275, 277, 280, 283, 285, 286, 290, 295, 298, 302, 307, 308, 312,\n",
      "       317, 318, 321, 322, 323, 324, 329, 330, 331, 333, 334, 335, 336,\n",
      "       337, 339, 340, 344, 346, 347, 352, 357, 358, 359, 360, 363, 364,\n",
      "       365, 366, 367, 368, 369, 371, 380, 383, 389, 390, 393, 394, 396,\n",
      "       397, 399, 400, 404, 406, 408, 415, 416, 419, 420, 422, 423, 424,\n",
      "       426, 427, 428, 429, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
      "       440, 447], dtype=int64),)\n",
      "WARN: neuro_idx = 451 for label 3 is not stable, let's include it anyway\n",
      "\n",
      "Label is  3\n",
      "Stable ReLUs [1, 5, 6, 7, 12, 17, 27, 30, 31, 32, 41, 49, 56, 58, 63, 65, 66, 68, 69, 74, 75, 82, 83, 85, 87, 88, 96, 97, 98, 112, 126, 132, 138, 140, 143, 145, 149, 157, 166, 167, 170, 174, 180, 185, 189, 194, 196, 201, 202, 205, 206, 217, 220, 225, 229, 234, 243, 249, 256, 257, 258, 259, 260, 261, 264, 265, 267, 270, 272, 274, 275, 277, 279, 280, 283, 285, 286, 288, 290, 295, 298, 302, 305, 307, 308, 312, 317, 318, 319, 321, 322, 323, 324, 325, 326, 329, 330, 331, 333, 334, 335, 336, 337, 338, 339, 340, 343, 344, 345, 346, 347, 352, 357, 358, 359, 360, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 374, 375, 380, 383, 385, 386, 389, 390, 392, 393, 394, 396, 397, 399, 400, 401, 403, 404, 406, 408, 411, 414, 415, 416, 418, 419, 420, 422, 423, 424, 426, 427, 428, 429, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 444, 447, 448, 449, 451, 452, 454, 457]\n",
      "how many unique paths in the filtered pattern? (585, 178)\n",
      "their freq\n",
      " [   1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    8    7    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    2    1    1    1    1    1    1    1    2    1    1    1\n",
      "    1    3    1    1    1    1    1    1    2    1    1    1    1    1\n",
      "    1    1    1   10    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    2    2    1    1    1    1    1    1    1    2\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    5\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    2   10\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    7    1\n",
      "    1    1    1    1    1    1    1    1    1    2    1    1    2    2\n",
      "    2    1    1    1    1    1    1    1    1    4    2    2    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    3    1    1    9    1    1    1    1    1    1\n",
      "   12    1    1    1    1    1    1    1    1    1    2    1    1    1\n",
      "   15    1    1    1    2    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    5    1    2    1    2    1    1    1    1    1\n",
      "    1    1    1    1    1    1    8    1    2    1    1    1    1    1\n",
      "    1    2    2    1    1    1    1    1    1    1    1    1    2    2\n",
      "    1    1    1    3    1    1    1    1   13    1    1    3    4    1\n",
      "    1    1    1    1    2    2    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    2    2    1    1    2\n",
      "   15    1    1    1    1    1    1    1    1    1    2    1    1    2\n",
      "    1    1    1    2   12    1    1    1    4    1    1    1    1   13\n",
      "    1    1    1    1    1    1    1    4    1    1    6    1    1    1\n",
      "   23    2    1    2    2    1   10    1    1    1    1    1   10    1\n",
      "    1    4    1    1    1    1    1    1    1    1    5    1    1    1\n",
      "    1    1    1    1    2    1    6    1    1    1    1    2    1    1\n",
      "    1    1    1    1    5    1    2    1    2    1    2    3    2    1\n",
      "    2    1    3    2    1    1    1    1    1    3    6    1    2    9\n",
      "    1    1    1    4    1    1    7    2    3    1    1    1    6    2\n",
      "    3    1    1    2    1    8    7  339   18    2 4753   11    5   26\n",
      "    3    4   17    2    1    4    3    2    2    1    4   10    2    1\n",
      "    1    1    1    1    1    1    1    1    1    4    1   24    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    5    2\n",
      "    7    1    1    1    1    1    1    1    2    1    1    1    1    1\n",
      "    1    1    1    1    2    9    1    1    1    1    1] (585,)\n",
      "primary pattern coverage:  0.7752405806556842\n",
      "(5842, 458)\n",
      "threshold:  58.42 5783.58\n",
      "relu_sum, prediction [  14   22   33    0 5380   12   86    9   42  244]\n",
      "non active neurons:  (array([257, 267, 288, 319, 325, 326, 338, 343, 345, 372, 374, 375, 386,\n",
      "       392, 401, 403, 411, 414, 418, 444, 445, 448, 449, 450, 451, 453,\n",
      "       455, 456], dtype=int64),)\n",
      "active neurons:  (array([  8,  12,  13,  17,  32,  51,  54,  55,  58,  65,  66,  70,  75,\n",
      "        76,  80,  84,  88,  89,  95,  98, 107, 110, 112, 114, 115, 120,\n",
      "       122, 125, 129, 138, 143, 145, 155, 173, 179, 188, 191, 196, 197,\n",
      "       198, 199, 200, 203, 207, 208, 219, 220, 223, 224, 228, 229, 238,\n",
      "       248, 252, 256, 258, 259, 260, 261, 263, 271, 273, 275, 276, 277,\n",
      "       282, 283, 284, 285, 286, 287, 290, 295, 296, 298, 299, 302, 306,\n",
      "       307, 308, 310, 312, 314, 315, 316, 317, 320, 321, 323, 329, 332,\n",
      "       333, 334, 336, 339, 340, 341, 346, 347, 349, 350, 351, 353, 355,\n",
      "       356, 357, 358, 360, 361, 364, 365, 366, 368, 369, 371, 377, 378,\n",
      "       379, 382, 387, 389, 391, 394, 395, 397, 398, 399, 400, 402, 404,\n",
      "       405, 406, 407, 409, 410, 417, 419, 420, 421, 422, 423, 425, 426,\n",
      "       430, 431, 434, 436, 439, 441, 442], dtype=int64),)\n",
      "WARN: neuro_idx = 452 for label 4 is not stable, let's include it anyway\n",
      "\n",
      "Label is  4\n",
      "Stable ReLUs [8, 12, 13, 17, 32, 51, 54, 55, 58, 65, 66, 70, 75, 76, 80, 84, 88, 89, 95, 98, 107, 110, 112, 114, 115, 120, 122, 125, 129, 138, 143, 145, 155, 173, 179, 188, 191, 196, 197, 198, 199, 200, 203, 207, 208, 219, 220, 223, 224, 228, 229, 238, 248, 252, 256, 257, 258, 259, 260, 261, 263, 267, 271, 273, 275, 276, 277, 282, 283, 284, 285, 286, 287, 288, 290, 295, 296, 298, 299, 302, 306, 307, 308, 310, 312, 314, 315, 316, 317, 319, 320, 321, 323, 325, 326, 329, 332, 333, 334, 336, 338, 339, 340, 341, 343, 345, 346, 347, 349, 350, 351, 353, 355, 356, 357, 358, 360, 361, 364, 365, 366, 368, 369, 371, 372, 374, 375, 377, 378, 379, 382, 386, 387, 389, 391, 392, 394, 395, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 409, 410, 411, 414, 417, 418, 419, 420, 421, 422, 423, 425, 426, 430, 431, 434, 436, 439, 441, 442, 444, 445, 448, 449, 450, 451, 452, 453, 455, 456]\n",
      "how many unique paths in the filtered pattern? (357, 179)\n",
      "their freq\n",
      " [   1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    2    1   11    1    1    1    1\n",
      "    1    1    1    1    1    4    1    1    1    1    1    1    2    1\n",
      "    1    1    1    1    1    1    1    1    5    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    2    1    2    3    1\n",
      "    1    1    1    1    1    1    1    7    1    1    1    1    1    1\n",
      "    1    2    1    1    1    1    1    6    1    1    1    1    1    1\n",
      "    1    5    1    1    1    1    1    1    1    1    8    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1   11    1    1    1    1    1    1    1    1    1    2    1\n",
      "    1    1    1    1    1    1    1    1    1    1    2    5    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    2    2    1    1\n",
      "    1    1    1    1    1    1    2    1   11    1    1    1    1    1\n",
      "    1    1    1    1    1    2    1    1    2    1   12    1    1    1\n",
      "    1    1    1    1    1   16    3    1    2    1    2    1    3    1\n",
      "    1    1    1    1    1    1    4    1    1    1    1    1    3    1\n",
      "    1    1    1    1    1    2    3    1   14    2    1    1    1    1\n",
      "    6    1    1    1    2    1    2    3    1    1    3    1    4    1\n",
      "    2   21    1    1    3    2    1    1    1    1    1    1    1    3\n",
      "    1    1    1    1   19    2    1    1    1    2    1    1    1    2\n",
      "    2    1    1    1   19    1    5    2    1    4    4   27    1    3\n",
      "   15   34    1    1    3    2    1    1    1    1    1    1    6    1\n",
      "    1    1    1    2  229   25    1 4896   15    3    2    3    1    8\n",
      "    4    1    1    4    1    1    1] (357,)\n",
      "primary pattern coverage:  0.8380691543991784\n",
      "(5421, 458)\n",
      "threshold:  54.21 5366.79\n",
      "relu_sum, prediction [  93   59   37  228   96 4560  113   34  128   73]\n",
      "non active neurons:  (array([225, 257, 267, 279, 288, 325, 338, 343, 345, 372, 374, 375, 385,\n",
      "       392, 401, 403, 411, 414, 418, 444, 450, 455], dtype=int64),)\n",
      "active neurons:  (array([  9,  12,  17,  27,  31,  41,  56,  58,  63,  66,  70,  74,  75,\n",
      "        83,  85,  87,  88,  96,  97, 100, 110, 112, 127, 138, 142, 143,\n",
      "       145, 157, 167, 170, 172, 173, 179, 189, 191, 194, 196, 217, 220,\n",
      "       223, 234, 238, 239, 240, 249, 256, 258, 259, 260, 261, 265, 270,\n",
      "       272, 274, 275, 277, 283, 285, 286, 287, 290, 295, 298, 301, 302,\n",
      "       306, 307, 317, 318, 321, 323, 329, 334, 336, 339, 340, 344, 346,\n",
      "       347, 349, 351, 352, 357, 358, 360, 365, 366, 369, 371, 377, 378,\n",
      "       380, 382, 390, 393, 394, 395, 396, 397, 399, 400, 404, 405, 406,\n",
      "       408, 409, 417, 419, 420, 422, 423, 424, 426, 429, 431, 433, 434,\n",
      "       439], dtype=int64),)\n",
      "WARN: neuro_idx = 453 for label 5 is not stable, let's include it anyway\n",
      "\n",
      "Label is  5\n",
      "Stable ReLUs [9, 12, 17, 27, 31, 41, 56, 58, 63, 66, 70, 74, 75, 83, 85, 87, 88, 96, 97, 100, 110, 112, 127, 138, 142, 143, 145, 157, 167, 170, 172, 173, 179, 189, 191, 194, 196, 217, 220, 223, 225, 234, 238, 239, 240, 249, 256, 257, 258, 259, 260, 261, 265, 267, 270, 272, 274, 275, 277, 279, 283, 285, 286, 287, 288, 290, 295, 298, 301, 302, 306, 307, 317, 318, 321, 323, 325, 329, 334, 336, 338, 339, 340, 343, 344, 345, 346, 347, 349, 351, 352, 357, 358, 360, 365, 366, 369, 371, 372, 374, 375, 377, 378, 380, 382, 385, 390, 392, 393, 394, 395, 396, 397, 399, 400, 401, 403, 404, 405, 406, 408, 409, 411, 414, 417, 418, 419, 420, 422, 423, 424, 426, 429, 431, 433, 434, 439, 444, 450, 453, 455]\n",
      "how many unique paths in the filtered pattern? (433, 141)\n",
      "their freq\n",
      " [   1    1    1    1    1    1    1    1    1    2    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    2   17    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    2    1    1    2    6   13    1    1    1    1    1    2\n",
      "    1    1    1    1    1    1    1    1    1    1    2    2    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    2    1\n",
      "    1    1    1    1    1    2    1    1    1    1    2    3    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    2    1    1    1    1    1    1    1    2    5    2    1    1\n",
      "    1    1    1    1    6    1    1    1    1    1    1    1    1    1\n",
      "    3    1    1    1    1    2   27    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    2    4    1\n",
      "    5    3    1    1    1    1    1    1    1    3    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    2    2    1\n",
      "    1    1    1    1    1    1    2    1    1    1    1    1    1    2\n",
      "    1    1    1    6    4    7    1    2    1    1    1    1    1    1\n",
      "    1    1    2    1    1    1    1    1    9    4    1    2    1    1\n",
      "    1    1    1    1    1    2    9    1    1    1    1    1    1    2\n",
      "    4    2    1    1    1    1    1    1    1    2    1    2    1    1\n",
      "    4    7    1    1    1    1    1    2    1    1    1    1   12    1\n",
      "    1    2    1    1    2    2    1    6    9    1    1    1    1    1\n",
      "    2    1    1    1    1    1    2   14    1    1    1    1    1    1\n",
      "    1    4    1    4    1    1    1    6    3    1    1    1    2    1\n",
      "    1    3    2    1    1    1    1    1    1    4    1    1    1    2\n",
      "    1    2    1    1    1    1    1    2    6    7    3    1    2    1\n",
      "    4    1    5    1    1    2    1    1    1    1    3    1    1    1\n",
      "    1    1    1    1    5    1    9    1    1    2    6    9    3    1\n",
      "    1   11    1    2    2    1    1    1    1    2    1    1    1    2\n",
      "   19    3    6    1   20    1   14    1   10    7  416    7 4141   15\n",
      "    1    1    1    3    1    1    1    1    1    2    5    1    1    1\n",
      "    2    1    2    1    2   11    1    3   13    6   16    1    1] (433,)\n",
      "primary pattern coverage:  0.7638812027301236\n",
      "(5918, 458)\n",
      "threshold:  59.18 5858.82\n",
      "relu_sum, prediction [  57   31   44    1   68   85 5606    1   25    0]\n",
      "non active neurons:  (array([161, 255, 257, 267, 288, 305, 325, 326, 338, 343, 345, 372, 374,\n",
      "       375, 385, 386, 392, 401, 403, 411, 414, 418, 444, 448, 449, 450,\n",
      "       451, 455, 456, 457], dtype=int64),)\n",
      "active neurons:  (array([ 13,  17,  19,  26,  30,  32,  39,  45,  47,  51,  55,  56,  58,\n",
      "        66,  70,  76,  78,  79,  81,  83,  84,  97,  98,  99, 113, 116,\n",
      "       128, 129, 130, 133, 139, 141, 142, 143, 145, 158, 167, 170, 172,\n",
      "       173, 176, 177, 179, 194, 195, 196, 197, 200, 202, 203, 207, 209,\n",
      "       210, 214, 219, 220, 223, 235, 238, 242, 248, 249, 251, 253, 256,\n",
      "       258, 259, 260, 261, 263, 265, 269, 271, 273, 275, 277, 283, 284,\n",
      "       285, 286, 287, 295, 296, 297, 298, 299, 302, 304, 306, 307, 309,\n",
      "       310, 314, 315, 316, 321, 323, 329, 333, 335, 336, 339, 340, 341,\n",
      "       342, 346, 347, 349, 351, 352, 353, 356, 357, 358, 360, 363, 364,\n",
      "       365, 366, 368, 369, 371, 377, 378, 379, 380, 382, 387, 391, 394,\n",
      "       395, 396, 404, 405, 406, 407, 409, 410, 417, 419, 420, 422, 423,\n",
      "       424, 425, 427, 428, 431, 434, 440, 441], dtype=int64),)\n",
      "WARN: neuro_idx = 454 for label 6 is not stable, let's include it anyway\n",
      "\n",
      "Label is  6\n",
      "Stable ReLUs [13, 17, 19, 26, 30, 32, 39, 45, 47, 51, 55, 56, 58, 66, 70, 76, 78, 79, 81, 83, 84, 97, 98, 99, 113, 116, 128, 129, 130, 133, 139, 141, 142, 143, 145, 158, 161, 167, 170, 172, 173, 176, 177, 179, 194, 195, 196, 197, 200, 202, 203, 207, 209, 210, 214, 219, 220, 223, 235, 238, 242, 248, 249, 251, 253, 255, 256, 257, 258, 259, 260, 261, 263, 265, 267, 269, 271, 273, 275, 277, 283, 284, 285, 286, 287, 288, 295, 296, 297, 298, 299, 302, 304, 305, 306, 307, 309, 310, 314, 315, 316, 321, 323, 325, 326, 329, 333, 335, 336, 338, 339, 340, 341, 342, 343, 345, 346, 347, 349, 351, 352, 353, 356, 357, 358, 360, 363, 364, 365, 366, 368, 369, 371, 372, 374, 375, 377, 378, 379, 380, 382, 385, 386, 387, 391, 392, 394, 395, 396, 401, 403, 404, 405, 406, 407, 409, 410, 411, 414, 417, 418, 419, 420, 422, 423, 424, 425, 427, 428, 431, 434, 440, 441, 444, 448, 449, 450, 451, 454, 455, 456, 457]\n",
      "how many unique paths in the filtered pattern? (396, 182)\n",
      "their freq\n",
      " [   1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    7    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    3    6    1    1    1    1    2    1    1    1    1    1    1\n",
      "    1    1    1    2    1    2    1    1    1    1    1    1    1    1\n",
      "    1    3    1    3    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    2    2    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1   11    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    2\n",
      "   14    2    3    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    2    1    1    1    1    2    1    1    1    1    1\n",
      "    1    1    1    1    1    2    2   30    1    1    1    1    1    1\n",
      "    1    1   16    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    2    1   11    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1   26    3    1    1\n",
      "    1    3    1    1    1    8    1    1    1    4    1    1   19    1\n",
      "    1    1    1    1    1    4    1   14    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    2    1    7    2    1\n",
      "    1    1    1    1    7    1    2    2    9    4    1    1    6    1\n",
      "    1    1    2    2    1    1    4   12    1    1    1    1    3    1\n",
      "    1    1    1   29    1    1    1    1   19    1    1    1    3    1\n",
      "    1    1    1    1    1    2   17    1    9    1    1   22    4    2\n",
      "    1   12    1    5    1    1    1    2    1    1    1    1    1   20\n",
      "    1    3    1    2    1    4   12    3    1    3    2    1    1    4\n",
      "    1   28    4    2    3    4    1    1   56    7 4926    9    8   18\n",
      "    1    1   39    2    1    1    1    7    1    2    1    2    1   33\n",
      "    1    1    1    1] (396,)\n",
      "primary pattern coverage:  0.8323758026360257\n",
      "(6265, 458)\n",
      "threshold:  62.65 6202.35\n",
      "relu_sum, prediction [  31   47   93   28   83   15    1 5789   20  158]\n",
      "non active neurons:  (array([257, 267, 279, 288, 305, 319, 326, 338, 343, 345, 372, 374, 375,\n",
      "       386, 401, 403, 411, 414, 418, 444, 448, 449, 451, 453, 454, 456],\n",
      "      dtype=int64),)\n",
      "active neurons:  (array([  7,   8,  12,  17,  26,  31,  49,  54,  58,  59,  60,  63,  65,\n",
      "        66,  70,  74,  75,  82,  86,  87,  96,  98, 107, 112, 115, 124,\n",
      "       125, 129, 131, 138, 142, 143, 144, 145, 155, 160, 170, 189, 191,\n",
      "       192, 194, 196, 201, 206, 216, 220, 223, 228, 229, 231, 235, 239,\n",
      "       248, 258, 259, 260, 264, 265, 270, 272, 273, 275, 276, 277, 282,\n",
      "       283, 284, 285, 286, 290, 295, 296, 298, 299, 306, 307, 308, 309,\n",
      "       312, 314, 317, 318, 320, 321, 323, 329, 330, 332, 333, 334, 336,\n",
      "       339, 341, 344, 346, 349, 350, 359, 360, 361, 365, 367, 369, 377,\n",
      "       380, 383, 388, 389, 391, 396, 402, 404, 405, 406, 407, 408, 415,\n",
      "       416, 417, 422, 424, 426, 430, 431, 432, 433, 434, 436, 439, 442,\n",
      "       443, 447], dtype=int64),)\n",
      "WARN: neuro_idx = 455 for label 7 is not stable, let's include it anyway\n",
      "\n",
      "Label is  7\n",
      "Stable ReLUs [7, 8, 12, 17, 26, 31, 49, 54, 58, 59, 60, 63, 65, 66, 70, 74, 75, 82, 86, 87, 96, 98, 107, 112, 115, 124, 125, 129, 131, 138, 142, 143, 144, 145, 155, 160, 170, 189, 191, 192, 194, 196, 201, 206, 216, 220, 223, 228, 229, 231, 235, 239, 248, 257, 258, 259, 260, 264, 265, 267, 270, 272, 273, 275, 276, 277, 279, 282, 283, 284, 285, 286, 288, 290, 295, 296, 298, 299, 305, 306, 307, 308, 309, 312, 314, 317, 318, 319, 320, 321, 323, 326, 329, 330, 332, 333, 334, 336, 338, 339, 341, 343, 344, 345, 346, 349, 350, 359, 360, 361, 365, 367, 369, 372, 374, 375, 377, 380, 383, 386, 388, 389, 391, 396, 401, 402, 403, 404, 405, 406, 407, 408, 411, 414, 415, 416, 417, 418, 422, 424, 426, 430, 431, 432, 433, 434, 436, 439, 442, 443, 444, 447, 448, 449, 451, 453, 454, 455, 456]\n",
      "how many unique paths in the filtered pattern? (383, 159)\n",
      "their freq\n",
      " [   1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    3    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    3    1    1    7    1    1    1    1    1    2    1    1\n",
      "    1    1    1    1    1    1    1    8    1    1    1    1    1    1\n",
      "    1    6    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    2    4    1    1    2    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    2    1    1    2    1    1    1   29    3    1\n",
      "    1    1    1    1    1    1    1    2    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    2    1    2    1\n",
      "    1    2    1    1    1   11    1    1    1    1    2    1    4    1\n",
      "    2    1    1    1    1    1    1    3    1    1    1    1    1    1\n",
      "    1    1    1    1    7    2    3    1    4    1    2    2    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    2    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1   12    1\n",
      "    1    1    1    1    1    1    1    1    1    3    1    1    1    1\n",
      "    1    1    1    1    1    2    4    1    2    1    1    1    1    1\n",
      "    1    2    1    1   16    1    1    1    1    1    1    1    1    1\n",
      "    1    1    2    1    1    1    1   20    2    1    1    1    1    1\n",
      "    1    1    1    1    1    2    1    1    1    1    1    1   19    1\n",
      "    1    1    1    5    1    1    9    1    1    2   15    1    1    4\n",
      "    1    1    1    1    1    1   25    1    1    2    1    1    2    1\n",
      "    1    5   12    1    1    1    2    4    3    1    1    1    1    2\n",
      "    3    3    1    1    3    2    2  187    8 5339    4   13   15    2\n",
      "   30    1    5    1    1    1    1   19    3    1    7    1    1    1\n",
      "    1    1    4    1    4] (383,)\n",
      "primary pattern coverage:  0.85219473264166\n",
      "(5851, 458)\n",
      "threshold:  58.51 5792.49\n",
      "relu_sum, prediction [  26  144   81  185   47  206   52   13 4966  131]\n",
      "non active neurons:  (array([ 68, 257, 267, 279, 288, 305, 325, 326, 338, 343, 345, 354, 372,\n",
      "       374, 375, 386, 392, 401, 403, 411, 414, 418, 444, 448, 452, 454,\n",
      "       455], dtype=int64),)\n",
      "active neurons:  (array([  6,   9,  11,  12,  13,  17,  19,  27,  30,  31,  32,  39,  41,\n",
      "        49,  51,  55,  56,  58,  63,  65,  66,  67,  69,  70,  72,  74,\n",
      "        75,  76,  80,  82,  83,  84,  85,  87,  88,  96,  97,  98, 107,\n",
      "       110, 112, 115, 119, 122, 129, 138, 142, 143, 145, 157, 166, 167,\n",
      "       170, 173, 179, 180, 185, 188, 189, 191, 194, 195, 196, 198, 201,\n",
      "       202, 207, 217, 220, 223, 224, 229, 230, 231, 234, 235, 238, 239,\n",
      "       240, 242, 243, 248, 249, 256, 258, 259, 260, 261, 270, 271, 272,\n",
      "       273, 274, 275, 277, 282, 283, 284, 285, 286, 287, 290, 293, 295,\n",
      "       297, 298, 299, 302, 306, 307, 308, 310, 312, 315, 316, 317, 318,\n",
      "       321, 323, 329, 333, 336, 339, 340, 341, 346, 347, 349, 351, 352,\n",
      "       355, 356, 357, 358, 359, 360, 363, 364, 365, 366, 368, 369, 371,\n",
      "       377, 378, 379, 380, 382, 389, 390, 393, 394, 395, 396, 399, 400,\n",
      "       404, 405, 406, 408, 409, 410, 415, 416, 417, 419, 420, 421, 422,\n",
      "       423, 424, 426, 427, 428, 429, 431, 432, 433, 434, 435, 436, 438,\n",
      "       440, 441, 442], dtype=int64),)\n",
      "WARN: neuro_idx = 456 for label 8 is not stable, let's include it anyway\n",
      "\n",
      "Label is  8\n",
      "Stable ReLUs [6, 9, 11, 12, 13, 17, 19, 27, 30, 31, 32, 39, 41, 49, 51, 55, 56, 58, 63, 65, 66, 67, 68, 69, 70, 72, 74, 75, 76, 80, 82, 83, 84, 85, 87, 88, 96, 97, 98, 107, 110, 112, 115, 119, 122, 129, 138, 142, 143, 145, 157, 166, 167, 170, 173, 179, 180, 185, 188, 189, 191, 194, 195, 196, 198, 201, 202, 207, 217, 220, 223, 224, 229, 230, 231, 234, 235, 238, 239, 240, 242, 243, 248, 249, 256, 257, 258, 259, 260, 261, 267, 270, 271, 272, 273, 274, 275, 277, 279, 282, 283, 284, 285, 286, 287, 288, 290, 293, 295, 297, 298, 299, 302, 305, 306, 307, 308, 310, 312, 315, 316, 317, 318, 321, 323, 325, 326, 329, 333, 336, 338, 339, 340, 341, 343, 345, 346, 347, 349, 351, 352, 354, 355, 356, 357, 358, 359, 360, 363, 364, 365, 366, 368, 369, 371, 372, 374, 375, 377, 378, 379, 380, 382, 386, 389, 390, 392, 393, 394, 395, 396, 399, 400, 401, 403, 404, 405, 406, 408, 409, 410, 411, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 426, 427, 428, 429, 431, 432, 433, 434, 435, 436, 438, 440, 441, 442, 444, 448, 452, 454, 455, 456]\n",
      "how many unique paths in the filtered pattern? (521, 213)\n",
      "their freq\n",
      " [   1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    2    1    1    1    1    1    1    1    1    1    1   13\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    9    2\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    5    4    1    1    1    1    1\n",
      "    1    1    1    1    1    2    1    1    4   32    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    3    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    2    1    2    2    2    1\n",
      "    1    1    1    1    1    1    1    2    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    8    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    2    3    2    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    2    1    1    1    2    1\n",
      "    1    1    1    1    1    7    7    1    1    6    1    1    1    1\n",
      "    1    1    1    1    1    1   18    1    1    1    1    1    1    1\n",
      "    1    1    5    7    1    1    1    1    1    1    4    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    5    1    1    1    1    1\n",
      "    1    6    5    1    1    1    1    2    1    1    1    1    1    1\n",
      "    1    1    3    1    1    2    1    1    1    1    1    1    1    4\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    5    1\n",
      "    1    2    1    1    2    1    1    1    1    1    1    1    1    1\n",
      "    1    1    4    1    1    1    1    1    1    1    1    1    3   14\n",
      "    1    1    1    1    1    6    2    1    1    1    1    1    2    4\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    4    2    1    1    1    1    1    4   19    1    1    3    1\n",
      "    1    1    2    1   12    1    1    1    2    2    2    1    1    9\n",
      "    2    1    1    1    2    1    3    3    1    1    1    1    1    2\n",
      "    1    1    1    1    1    1    1    1   12    6    1    1    1    1\n",
      "    2   18    9    7    2    1    2    1    3    2    1    1    1    1\n",
      "    8    3    1    1    1    3   12    1    1    1    1    2    5   15\n",
      "    3    1    5    1    1    2    2    1    1    6    6    4    1    4\n",
      "    7    2    7  383 4530    5   12    7    7    3   10    1    1    1\n",
      "    1    3    5    1    1    1    1    1    1    1    1    1    2    1\n",
      "    1    2    1] (521,)\n",
      "primary pattern coverage:  0.7742266279268502\n",
      "(5949, 458)\n",
      "threshold:  59.49 5889.51\n",
      "relu_sum, prediction [  43   21   22   76  249   43   10  247   72 5166]\n",
      "non active neurons:  (array([257, 267, 288, 305, 319, 325, 326, 338, 343, 345, 372, 374, 375,\n",
      "       385, 386, 392, 401, 403, 411, 414, 418, 444, 448, 449, 450, 453,\n",
      "       454], dtype=int64),)\n",
      "active neurons:  (array([  8,  12,  17,  26,  27,  30,  32,  49,  51,  54,  55,  58,  59,\n",
      "        60,  63,  65,  66,  70,  74,  75,  76,  80,  84,  87,  89,  96,\n",
      "        98, 107, 110, 112, 115, 119, 122, 124, 125, 128, 129, 137, 138,\n",
      "       143, 144, 145, 155, 170, 179, 189, 191, 196, 198, 201, 208, 218,\n",
      "       219, 220, 223, 224, 228, 229, 231, 234, 238, 239, 247, 248, 258,\n",
      "       259, 261, 264, 265, 270, 272, 273, 275, 276, 277, 282, 283, 284,\n",
      "       285, 286, 290, 294, 295, 296, 298, 299, 302, 306, 307, 308, 310,\n",
      "       312, 314, 317, 318, 320, 321, 323, 329, 330, 332, 333, 334, 336,\n",
      "       339, 340, 341, 344, 346, 347, 349, 350, 351, 353, 357, 358, 359,\n",
      "       360, 361, 363, 364, 365, 366, 367, 368, 369, 371, 377, 379, 380,\n",
      "       383, 389, 391, 394, 395, 397, 398, 400, 402, 404, 405, 407, 415,\n",
      "       417, 421, 422, 423, 425, 426, 427, 430, 431, 432, 434, 436, 438,\n",
      "       439, 441, 442, 447], dtype=int64),)\n",
      "WARN: neuro_idx = 457 for label 9 is not stable, let's include it anyway\n",
      "\n",
      "Label is  9\n",
      "Stable ReLUs [8, 12, 17, 26, 27, 30, 32, 49, 51, 54, 55, 58, 59, 60, 63, 65, 66, 70, 74, 75, 76, 80, 84, 87, 89, 96, 98, 107, 110, 112, 115, 119, 122, 124, 125, 128, 129, 137, 138, 143, 144, 145, 155, 170, 179, 189, 191, 196, 198, 201, 208, 218, 219, 220, 223, 224, 228, 229, 231, 234, 238, 239, 247, 248, 257, 258, 259, 261, 264, 265, 267, 270, 272, 273, 275, 276, 277, 282, 283, 284, 285, 286, 288, 290, 294, 295, 296, 298, 299, 302, 305, 306, 307, 308, 310, 312, 314, 317, 318, 319, 320, 321, 323, 325, 326, 329, 330, 332, 333, 334, 336, 338, 339, 340, 341, 343, 344, 345, 346, 347, 349, 350, 351, 353, 357, 358, 359, 360, 361, 363, 364, 365, 366, 367, 368, 369, 371, 372, 374, 375, 377, 379, 380, 383, 385, 386, 389, 391, 392, 394, 395, 397, 398, 400, 401, 402, 403, 404, 405, 407, 411, 414, 415, 417, 418, 421, 422, 423, 425, 426, 427, 430, 431, 432, 434, 436, 438, 439, 441, 442, 444, 447, 448, 449, 450, 453, 454, 457]\n",
      "how many unique paths in the filtered pattern? (493, 188)\n",
      "their freq\n",
      " [   1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    2    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    2    4\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    5\n",
      "    2    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    3    5    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    3    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    5    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    2    4    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    5    1    2   11    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    2    1    1    2   10\n",
      "    1    1    1    1    1    1    1    1    1    1    3    1    1    1\n",
      "    2    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    2    1    1    1    1    2    1    1    1\n",
      "    1    1    1    4    1    1    2    1    1    1    1    1    1    1\n",
      "    1    1    3   13    1    1    1    1    1    1    1    1    1    2\n",
      "    1    1    1    1    1    1    1    6    1    2    3    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    6    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1   15    1\n",
      "    1    1    1    2    1    1    7    8    1    1    1    1    1    1\n",
      "    1    1    1    1    1   11    1    1    1    1    1    1    1    1\n",
      "    1    1    1    2    2    1    1    1    1    1    1    1    1    2\n",
      "    1    1    2    2    1    2    1    1    1    1    1    1    1    5\n",
      "    1    1    1    1    1    1    1    1    1    2    1    1    1    1\n",
      "    1    3    1    1    1    2    1    1    1    2    7    1    1    1\n",
      "    1    1    1    2    2    1    3    8    9    2    1    1   15    1\n",
      "    1    1    1    4    1    1   18    2   29    1    1    2    1    1\n",
      "    2    1    1    1    1    1    1    1    1    1    1    1    1    3\n",
      "    1    1    1    1    2    1    1    1    2    1    1    1    2   14\n",
      "   17    1    2    1   15    1    1    1    1    1    1    7    1    2\n",
      "    1    1    1    4    3    2    2    2   12    2    5    3  295 4788\n",
      "    1   24    3    3    7    1    2    5   15    1    1    4    2    1\n",
      "    1    1    5] (493,)\n",
      "primary pattern coverage:  0.8048411497730711\n",
      "(5923, 458)\n",
      "threshold:  296.15000000000003 5626.849999999999\n",
      "relu_sum, prediction [5685    0   29   15   11   77   48   11   43    4]\n",
      "non active neurons:  (array([ 10,  48, 225, 227, 257, 267, 278, 279, 288, 292, 300, 305, 325,\n",
      "       326, 327, 338, 343, 345, 354, 370, 372, 373, 374, 375, 376, 381,\n",
      "       384, 385, 386, 392, 401, 403, 411, 412, 413, 414, 418, 444, 449,\n",
      "       450, 451, 452, 453, 454, 455, 456, 457], dtype=int64),)\n",
      "active neurons:  (array([  8,   9,  17,  18,  19,  21,  26,  27,  30,  31,  32,  39,  41,\n",
      "        45,  46,  47,  49,  54,  55,  56,  58,  59,  63,  69,  70,  72,\n",
      "        74,  75,  80,  82,  83,  85,  86,  87,  88,  96,  97, 100, 103,\n",
      "       112, 115, 116, 127, 136, 138, 139, 140, 141, 142, 143, 144, 145,\n",
      "       147, 148, 157, 159, 163, 165, 167, 170, 171, 172, 173, 177, 179,\n",
      "       185, 189, 191, 192, 193, 194, 196, 198, 201, 202, 205, 206, 209,\n",
      "       210, 213, 214, 215, 217, 220, 222, 223, 234, 235, 238, 239, 241,\n",
      "       242, 243, 247, 248, 249, 258, 259, 260, 261, 264, 265, 269, 271,\n",
      "       272, 273, 274, 275, 276, 277, 283, 284, 285, 286, 287, 289, 290,\n",
      "       293, 295, 297, 298, 299, 301, 302, 303, 306, 307, 309, 314, 316,\n",
      "       317, 318, 320, 321, 322, 323, 329, 330, 334, 335, 339, 340, 342,\n",
      "       344, 346, 347, 348, 349, 351, 352, 357, 358, 359, 360, 362, 363,\n",
      "       365, 366, 367, 369, 371, 380, 382, 388, 390, 391, 393, 394, 395,\n",
      "       396, 397, 398, 399, 400, 404, 405, 406, 407, 408, 409, 410, 415,\n",
      "       417, 419, 420, 422, 423, 424, 426, 427, 428, 429, 432, 433, 434,\n",
      "       437, 438, 440, 445, 446, 447, 448], dtype=int64),)\n",
      "\n",
      "Label is  0\n",
      "Stable ReLUs [8, 9, 10, 17, 18, 19, 21, 26, 27, 30, 31, 32, 39, 41, 45, 46, 47, 48, 49, 54, 55, 56, 58, 59, 63, 69, 70, 72, 74, 75, 80, 82, 83, 85, 86, 87, 88, 96, 97, 100, 103, 112, 115, 116, 127, 136, 138, 139, 140, 141, 142, 143, 144, 145, 147, 148, 157, 159, 163, 165, 167, 170, 171, 172, 173, 177, 179, 185, 189, 191, 192, 193, 194, 196, 198, 201, 202, 205, 206, 209, 210, 213, 214, 215, 217, 220, 222, 223, 225, 227, 234, 235, 238, 239, 241, 242, 243, 247, 248, 249, 257, 258, 259, 260, 261, 264, 265, 267, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 283, 284, 285, 286, 287, 288, 289, 290, 292, 293, 295, 297, 298, 299, 300, 301, 302, 303, 305, 306, 307, 309, 314, 316, 317, 318, 320, 321, 322, 323, 325, 326, 327, 329, 330, 334, 335, 338, 339, 340, 342, 343, 344, 345, 346, 347, 348, 349, 351, 352, 354, 357, 358, 359, 360, 362, 363, 365, 366, 367, 369, 370, 371, 372, 373, 374, 375, 376, 380, 381, 382, 384, 385, 386, 388, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 417, 418, 419, 420, 422, 423, 424, 426, 427, 428, 429, 432, 433, 434, 437, 438, 440, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457]\n",
      "how many unique paths in the filtered pattern? (1511, 249)\n",
      "their freq\n",
      " [1 1 1 ... 1 1 1] (1511,)\n",
      "primary pattern coverage:  0.5225392537565423\n",
      "(6742, 458)\n",
      "threshold:  337.1 6404.9\n",
      "relu_sum, prediction [   1 6519   35   27   10   28    8   22   88    4]\n",
      "non active neurons:  (array([  0,  28,  34,  35,  36,  48,  68, 126, 161, 225, 226, 244, 257,\n",
      "       262, 266, 267, 279, 288, 291, 292, 319, 325, 326, 338, 343, 345,\n",
      "       348, 354, 374, 375, 385, 386, 392, 398, 401, 403, 411, 414, 418,\n",
      "       444, 448, 450, 451, 452, 453, 454, 455, 456, 457], dtype=int64),)\n",
      "active neurons:  (array([  1,   5,   6,   7,   9,  12,  13,  14,  16,  17,  22,  24,  25,\n",
      "        26,  30,  31,  33,  38,  39,  49,  51,  52,  57,  58,  59,  60,\n",
      "        61,  63,  64,  65,  66,  67,  69,  74,  75,  76,  79,  80,  81,\n",
      "        83,  84,  87,  91,  94,  96,  97,  98,  99, 103, 105, 106, 107,\n",
      "       110, 112, 113, 119, 123, 124, 137, 138, 143, 145, 150, 151, 153,\n",
      "       156, 157, 158, 160, 162, 166, 167, 169, 170, 176, 180, 185, 188,\n",
      "       189, 191, 192, 194, 196, 201, 202, 207, 212, 217, 220, 223, 224,\n",
      "       229, 230, 231, 233, 234, 237, 239, 240, 249, 250, 251, 256, 258,\n",
      "       259, 260, 261, 265, 268, 270, 271, 272, 273, 275, 277, 282, 283,\n",
      "       284, 286, 289, 290, 295, 297, 298, 299, 301, 304, 306, 307, 308,\n",
      "       309, 310, 312, 313, 314, 315, 316, 317, 318, 320, 321, 322, 323,\n",
      "       324, 328, 329, 330, 331, 333, 334, 336, 337, 339, 341, 346, 347,\n",
      "       355, 356, 357, 358, 359, 360, 363, 364, 365, 366, 368, 369, 371,\n",
      "       373, 377, 378, 379, 380, 382, 384, 387, 388, 389, 390, 394, 395,\n",
      "       396, 397, 399, 400, 402, 404, 407, 408, 409, 410, 412, 413, 415,\n",
      "       416, 419, 420, 422, 423, 424, 426, 427, 428, 431, 432, 433, 434,\n",
      "       435, 436, 438, 439, 440, 441, 442, 443, 446, 449], dtype=int64),)\n",
      "\n",
      "Label is  1\n",
      "Stable ReLUs [0, 1, 5, 6, 7, 9, 12, 13, 14, 16, 17, 22, 24, 25, 26, 28, 30, 31, 33, 34, 35, 36, 38, 39, 48, 49, 51, 52, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 74, 75, 76, 79, 80, 81, 83, 84, 87, 91, 94, 96, 97, 98, 99, 103, 105, 106, 107, 110, 112, 113, 119, 123, 124, 126, 137, 138, 143, 145, 150, 151, 153, 156, 157, 158, 160, 161, 162, 166, 167, 169, 170, 176, 180, 185, 188, 189, 191, 192, 194, 196, 201, 202, 207, 212, 217, 220, 223, 224, 225, 226, 229, 230, 231, 233, 234, 237, 239, 240, 244, 249, 250, 251, 256, 257, 258, 259, 260, 261, 262, 265, 266, 267, 268, 270, 271, 272, 273, 275, 277, 279, 282, 283, 284, 286, 288, 289, 290, 291, 292, 295, 297, 298, 299, 301, 304, 306, 307, 308, 309, 310, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 330, 331, 333, 334, 336, 337, 338, 339, 341, 343, 345, 346, 347, 348, 354, 355, 356, 357, 358, 359, 360, 363, 364, 365, 366, 368, 369, 371, 373, 374, 375, 377, 378, 379, 380, 382, 384, 385, 386, 387, 388, 389, 390, 392, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 418, 419, 420, 422, 423, 424, 426, 427, 428, 431, 432, 433, 434, 435, 436, 438, 439, 440, 441, 442, 443, 444, 446, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457]\n",
      "how many unique paths in the filtered pattern? (1574, 267)\n",
      "their freq\n",
      " [1 1 1 ... 1 1 1] (1574,)\n",
      "primary pattern coverage:  0.535449421536636\n",
      "(5958, 458)\n",
      "threshold:  297.90000000000003 5660.099999999999\n",
      "relu_sum, prediction [  72  103 5157  106  116   22  126   98  127   31]\n",
      "non active neurons:  (array([ 68, 225, 236, 257, 266, 267, 288, 305, 319, 325, 326, 338, 343,\n",
      "       345, 354, 372, 374, 375, 385, 386, 392, 401, 403, 411, 414, 418,\n",
      "       444, 448, 449, 451, 452, 453, 454, 455, 456, 457], dtype=int64),)\n",
      "active neurons:  (array([  1,  12,  13,  17,  18,  19,  24,  26,  27,  30,  31,  32,  33,\n",
      "        39,  40,  41,  46,  47,  51,  52,  55,  56,  58,  63,  65,  66,\n",
      "        67,  72,  74,  75,  76,  79,  83,  84,  85,  96,  97,  98,  99,\n",
      "       100, 112, 116, 123, 128, 129, 130, 132, 133, 139, 141, 142, 143,\n",
      "       145, 150, 151, 153, 157, 159, 165, 166, 167, 170, 172, 173, 176,\n",
      "       177, 179, 180, 185, 194, 195, 196, 198, 201, 202, 205, 207, 210,\n",
      "       214, 215, 217, 220, 223, 230, 232, 234, 235, 237, 238, 242, 243,\n",
      "       245, 249, 251, 253, 256, 258, 259, 260, 261, 265, 268, 269, 270,\n",
      "       271, 272, 273, 275, 277, 283, 285, 286, 287, 289, 290, 293, 295,\n",
      "       297, 299, 302, 307, 308, 310, 314, 315, 316, 318, 321, 323, 329,\n",
      "       330, 331, 333, 335, 337, 339, 340, 346, 347, 349, 352, 355, 356,\n",
      "       357, 358, 359, 360, 361, 363, 364, 365, 366, 368, 369, 371, 379,\n",
      "       380, 387, 389, 390, 393, 394, 395, 396, 400, 404, 406, 407, 408,\n",
      "       409, 410, 416, 419, 420, 422, 423, 427, 428, 431, 432, 434, 436,\n",
      "       437, 438, 440, 441, 446, 447], dtype=int64),)\n",
      "WARN: neuro_idx = 450 for label 2 is not stable, let's include it anyway\n",
      "\n",
      "Label is  2\n",
      "Stable ReLUs [1, 12, 13, 17, 18, 19, 24, 26, 27, 30, 31, 32, 33, 39, 40, 41, 46, 47, 51, 52, 55, 56, 58, 63, 65, 66, 67, 68, 72, 74, 75, 76, 79, 83, 84, 85, 96, 97, 98, 99, 100, 112, 116, 123, 128, 129, 130, 132, 133, 139, 141, 142, 143, 145, 150, 151, 153, 157, 159, 165, 166, 167, 170, 172, 173, 176, 177, 179, 180, 185, 194, 195, 196, 198, 201, 202, 205, 207, 210, 214, 215, 217, 220, 223, 225, 230, 232, 234, 235, 236, 237, 238, 242, 243, 245, 249, 251, 253, 256, 257, 258, 259, 260, 261, 265, 266, 267, 268, 269, 270, 271, 272, 273, 275, 277, 283, 285, 286, 287, 288, 289, 290, 293, 295, 297, 299, 302, 305, 307, 308, 310, 314, 315, 316, 318, 319, 321, 323, 325, 326, 329, 330, 331, 333, 335, 337, 338, 339, 340, 343, 345, 346, 347, 349, 352, 354, 355, 356, 357, 358, 359, 360, 361, 363, 364, 365, 366, 368, 369, 371, 372, 374, 375, 379, 380, 385, 386, 387, 389, 390, 392, 393, 394, 395, 396, 400, 401, 403, 404, 406, 407, 408, 409, 410, 411, 414, 416, 418, 419, 420, 422, 423, 427, 428, 431, 432, 434, 436, 437, 438, 440, 441, 444, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457]\n",
      "how many unique paths in the filtered pattern? (2104, 225)\n",
      "their freq\n",
      " [1 1 1 ... 1 1 1] (2104,)\n",
      "primary pattern coverage:  0.4033232628398791\n",
      "(6131, 458)\n",
      "threshold:  306.55 5824.45\n",
      "relu_sum, prediction [  22   42  156 5277    2  323   25   85  144   55]\n",
      "non active neurons:  (array([  3,  34,  68, 126, 161, 225, 257, 267, 279, 288, 305, 319, 325,\n",
      "       326, 338, 343, 345, 370, 372, 374, 375, 376, 385, 386, 392, 401,\n",
      "       403, 411, 414, 418, 444, 448, 449, 450, 452, 454, 455, 456, 457],\n",
      "      dtype=int64),)\n",
      "active neurons:  (array([  1,   5,   6,   7,   9,  12,  17,  18,  26,  27,  30,  31,  32,\n",
      "        33,  41,  45,  46,  49,  51,  56,  58,  59,  63,  65,  66,  67,\n",
      "        69,  70,  72,  74,  75,  82,  83,  85,  87,  88,  96,  97,  98,\n",
      "       100, 103, 107, 110, 112, 116, 119, 128, 132, 136, 138, 140, 141,\n",
      "       142, 143, 144, 145, 149, 150, 153, 157, 166, 167, 168, 170, 172,\n",
      "       174, 176, 179, 180, 185, 186, 189, 190, 191, 194, 196, 198, 201,\n",
      "       202, 205, 206, 207, 213, 217, 218, 220, 229, 230, 231, 234, 239,\n",
      "       243, 245, 248, 249, 251, 256, 258, 259, 260, 261, 264, 265, 270,\n",
      "       271, 272, 274, 275, 277, 280, 282, 283, 284, 285, 286, 287, 289,\n",
      "       290, 293, 295, 298, 301, 302, 303, 306, 307, 308, 310, 312, 313,\n",
      "       314, 317, 318, 321, 322, 323, 324, 328, 329, 330, 331, 332, 333,\n",
      "       334, 335, 336, 337, 339, 340, 341, 344, 346, 347, 352, 357, 358,\n",
      "       359, 360, 363, 364, 365, 366, 367, 368, 369, 371, 377, 378, 380,\n",
      "       383, 388, 389, 390, 393, 394, 395, 396, 397, 399, 400, 404, 406,\n",
      "       408, 410, 415, 416, 419, 420, 421, 422, 423, 424, 426, 427, 428,\n",
      "       429, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 445, 447],\n",
      "      dtype=int64),)\n",
      "WARN: neuro_idx = 451 for label 3 is not stable, let's include it anyway\n",
      "\n",
      "Label is  3\n",
      "Stable ReLUs [1, 3, 5, 6, 7, 9, 12, 17, 18, 26, 27, 30, 31, 32, 33, 34, 41, 45, 46, 49, 51, 56, 58, 59, 63, 65, 66, 67, 68, 69, 70, 72, 74, 75, 82, 83, 85, 87, 88, 96, 97, 98, 100, 103, 107, 110, 112, 116, 119, 126, 128, 132, 136, 138, 140, 141, 142, 143, 144, 145, 149, 150, 153, 157, 161, 166, 167, 168, 170, 172, 174, 176, 179, 180, 185, 186, 189, 190, 191, 194, 196, 198, 201, 202, 205, 206, 207, 213, 217, 218, 220, 225, 229, 230, 231, 234, 239, 243, 245, 248, 249, 251, 256, 257, 258, 259, 260, 261, 264, 265, 267, 270, 271, 272, 274, 275, 277, 279, 280, 282, 283, 284, 285, 286, 287, 288, 289, 290, 293, 295, 298, 301, 302, 303, 305, 306, 307, 308, 310, 312, 313, 314, 317, 318, 319, 321, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 343, 344, 345, 346, 347, 352, 357, 358, 359, 360, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 374, 375, 376, 377, 378, 380, 383, 385, 386, 388, 389, 390, 392, 393, 394, 395, 396, 397, 399, 400, 401, 403, 404, 406, 408, 410, 411, 414, 415, 416, 418, 419, 420, 421, 422, 423, 424, 426, 427, 428, 429, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 444, 445, 447, 448, 449, 450, 451, 452, 454, 455, 456, 457]\n",
      "how many unique paths in the filtered pattern? (2202, 248)\n",
      "their freq\n",
      " [1 1 1 ... 1 1 1] (2202,)\n",
      "primary pattern coverage:  0.41885499918447233\n",
      "(5842, 458)\n",
      "threshold:  292.1 5549.9\n",
      "relu_sum, prediction [  14   22   33    0 5380   12   86    9   42  244]\n",
      "non active neurons:  (array([ 48, 108, 161, 255, 257, 262, 267, 288, 305, 311, 319, 325, 326,\n",
      "       338, 343, 345, 372, 374, 375, 386, 392, 401, 403, 411, 414, 418,\n",
      "       444, 445, 448, 449, 450, 451, 453, 454, 455, 456, 457], dtype=int64),)\n",
      "active neurons:  (array([  8,  12,  13,  17,  26,  27,  30,  32,  39,  41,  46,  47,  49,\n",
      "        51,  54,  55,  56,  58,  60,  65,  66,  70,  74,  75,  76,  77,\n",
      "        80,  81,  84,  86,  87,  88,  89,  93,  95,  96,  97,  98, 104,\n",
      "       107, 110, 112, 113, 114, 115, 117, 118, 119, 120, 122, 125, 128,\n",
      "       129, 137, 138, 143, 145, 147, 155, 167, 173, 179, 180, 188, 190,\n",
      "       191, 192, 195, 196, 197, 198, 199, 200, 201, 203, 207, 208, 210,\n",
      "       216, 218, 219, 220, 223, 224, 228, 229, 231, 234, 235, 238, 239,\n",
      "       240, 242, 247, 248, 249, 252, 253, 256, 258, 259, 260, 261, 263,\n",
      "       270, 271, 273, 275, 276, 277, 282, 283, 284, 285, 286, 287, 290,\n",
      "       291, 293, 295, 296, 297, 298, 299, 300, 302, 306, 307, 308, 310,\n",
      "       312, 313, 314, 315, 316, 317, 320, 321, 323, 329, 330, 332, 333,\n",
      "       334, 336, 339, 340, 341, 344, 346, 347, 349, 350, 351, 353, 355,\n",
      "       356, 357, 358, 360, 361, 364, 365, 366, 367, 368, 369, 371, 377,\n",
      "       378, 379, 380, 382, 387, 389, 391, 394, 395, 397, 398, 399, 400,\n",
      "       402, 404, 405, 406, 407, 409, 410, 412, 413, 417, 419, 420, 421,\n",
      "       422, 423, 424, 425, 426, 430, 431, 434, 436, 438, 439, 441, 442],\n",
      "      dtype=int64),)\n",
      "WARN: neuro_idx = 452 for label 4 is not stable, let's include it anyway\n",
      "\n",
      "Label is  4\n",
      "Stable ReLUs [8, 12, 13, 17, 26, 27, 30, 32, 39, 41, 46, 47, 48, 49, 51, 54, 55, 56, 58, 60, 65, 66, 70, 74, 75, 76, 77, 80, 81, 84, 86, 87, 88, 89, 93, 95, 96, 97, 98, 104, 107, 108, 110, 112, 113, 114, 115, 117, 118, 119, 120, 122, 125, 128, 129, 137, 138, 143, 145, 147, 155, 161, 167, 173, 179, 180, 188, 190, 191, 192, 195, 196, 197, 198, 199, 200, 201, 203, 207, 208, 210, 216, 218, 219, 220, 223, 224, 228, 229, 231, 234, 235, 238, 239, 240, 242, 247, 248, 249, 252, 253, 255, 256, 257, 258, 259, 260, 261, 262, 263, 267, 270, 271, 273, 275, 276, 277, 282, 283, 284, 285, 286, 287, 288, 290, 291, 293, 295, 296, 297, 298, 299, 300, 302, 305, 306, 307, 308, 310, 311, 312, 313, 314, 315, 316, 317, 319, 320, 321, 323, 325, 326, 329, 330, 332, 333, 334, 336, 338, 339, 340, 341, 343, 344, 345, 346, 347, 349, 350, 351, 353, 355, 356, 357, 358, 360, 361, 364, 365, 366, 367, 368, 369, 371, 372, 374, 375, 377, 378, 379, 380, 382, 386, 387, 389, 391, 392, 394, 395, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 409, 410, 411, 412, 413, 414, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 430, 431, 434, 436, 438, 439, 441, 442, 444, 445, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457]\n",
      "how many unique paths in the filtered pattern? (1880, 246)\n",
      "their freq\n",
      " [1 1 1 ... 1 1 1] (1880,)\n",
      "primary pattern coverage:  0.43135912358781237\n",
      "(5421, 458)\n",
      "threshold:  271.05 5149.95\n",
      "relu_sum, prediction [  93   59   37  228   96 4560  113   34  128   73]\n",
      "non active neurons:  (array([ 68, 225, 257, 267, 279, 288, 305, 319, 325, 326, 338, 343, 345,\n",
      "       372, 374, 375, 385, 386, 392, 401, 403, 411, 414, 418, 444, 448,\n",
      "       449, 450, 451, 452, 454, 455, 456, 457], dtype=int64),)\n",
      "active neurons:  (array([  6,   7,   8,   9,  12,  17,  19,  27,  30,  31,  32,  39,  41,\n",
      "        45,  46,  47,  49,  51,  54,  55,  56,  58,  61,  63,  65,  66,\n",
      "        69,  70,  74,  75,  78,  82,  83,  84,  85,  87,  88,  96,  97,\n",
      "        98, 100, 103, 107, 110, 112, 113, 115, 122, 127, 138, 142, 143,\n",
      "       145, 147, 149, 157, 158, 159, 167, 170, 171, 172, 173, 179, 180,\n",
      "       185, 186, 189, 190, 191, 192, 194, 195, 196, 198, 200, 201, 206,\n",
      "       207, 208, 209, 210, 213, 217, 219, 220, 222, 223, 229, 234, 238,\n",
      "       239, 240, 243, 248, 249, 252, 256, 258, 259, 260, 261, 263, 264,\n",
      "       265, 270, 271, 272, 273, 274, 275, 277, 280, 282, 283, 284, 285,\n",
      "       286, 287, 290, 295, 298, 299, 301, 302, 303, 306, 307, 310, 312,\n",
      "       313, 314, 316, 317, 318, 321, 323, 329, 333, 334, 336, 339, 340,\n",
      "       341, 342, 344, 346, 347, 349, 351, 352, 356, 357, 358, 360, 362,\n",
      "       363, 364, 365, 366, 369, 371, 377, 378, 379, 380, 382, 388, 389,\n",
      "       390, 393, 394, 395, 396, 397, 398, 399, 400, 404, 405, 406, 408,\n",
      "       409, 410, 415, 416, 417, 419, 420, 421, 422, 423, 424, 426, 427,\n",
      "       428, 429, 431, 433, 434, 437, 438, 439, 440, 447], dtype=int64),)\n",
      "WARN: neuro_idx = 453 for label 5 is not stable, let's include it anyway\n",
      "\n",
      "Label is  5\n",
      "Stable ReLUs [6, 7, 8, 9, 12, 17, 19, 27, 30, 31, 32, 39, 41, 45, 46, 47, 49, 51, 54, 55, 56, 58, 61, 63, 65, 66, 68, 69, 70, 74, 75, 78, 82, 83, 84, 85, 87, 88, 96, 97, 98, 100, 103, 107, 110, 112, 113, 115, 122, 127, 138, 142, 143, 145, 147, 149, 157, 158, 159, 167, 170, 171, 172, 173, 179, 180, 185, 186, 189, 190, 191, 192, 194, 195, 196, 198, 200, 201, 206, 207, 208, 209, 210, 213, 217, 219, 220, 222, 223, 225, 229, 234, 238, 239, 240, 243, 248, 249, 252, 256, 257, 258, 259, 260, 261, 263, 264, 265, 267, 270, 271, 272, 273, 274, 275, 277, 279, 280, 282, 283, 284, 285, 286, 287, 288, 290, 295, 298, 299, 301, 302, 303, 305, 306, 307, 310, 312, 313, 314, 316, 317, 318, 319, 321, 323, 325, 326, 329, 333, 334, 336, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 349, 351, 352, 356, 357, 358, 360, 362, 363, 364, 365, 366, 369, 371, 372, 374, 375, 377, 378, 379, 380, 382, 385, 386, 388, 389, 390, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 403, 404, 405, 406, 408, 409, 410, 411, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 426, 427, 428, 429, 431, 433, 434, 437, 438, 439, 440, 444, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457]\n",
      "how many unique paths in the filtered pattern? (2282, 240)\n",
      "their freq\n",
      " [ 1  1  1 ... 24  1  1] (2282,)\n",
      "primary pattern coverage:  0.36174137612986534\n",
      "(5918, 458)\n",
      "threshold:  295.90000000000003 5622.099999999999\n",
      "relu_sum, prediction [  57   31   44    1   68   85 5606    1   25    0]\n",
      "non active neurons:  (array([ 10,  37,  48,  68, 161, 225, 255, 257, 267, 288, 305, 319, 325,\n",
      "       326, 338, 343, 345, 372, 374, 375, 385, 386, 392, 401, 403, 411,\n",
      "       414, 418, 444, 448, 449, 450, 451, 452, 453, 455, 456, 457],\n",
      "      dtype=int64),)\n",
      "active neurons:  (array([  1,  12,  13,  17,  18,  19,  26,  30,  31,  32,  33,  36,  39,\n",
      "        45,  47,  49,  51,  52,  54,  55,  56,  58,  63,  65,  66,  70,\n",
      "        72,  74,  75,  76,  78,  79,  81,  83,  84,  87,  88,  91,  95,\n",
      "        97,  98,  99, 107, 110, 112, 113, 116, 120, 122, 123, 125, 127,\n",
      "       128, 129, 130, 132, 133, 139, 141, 142, 143, 145, 147, 149, 153,\n",
      "       157, 158, 159, 167, 170, 172, 173, 175, 176, 177, 179, 190, 191,\n",
      "       194, 195, 196, 197, 198, 200, 202, 203, 207, 209, 210, 214, 215,\n",
      "       218, 219, 220, 223, 228, 235, 238, 239, 241, 242, 246, 248, 249,\n",
      "       250, 251, 252, 253, 256, 258, 259, 260, 261, 263, 265, 268, 269,\n",
      "       271, 272, 273, 275, 277, 283, 284, 285, 286, 287, 290, 293, 295,\n",
      "       296, 297, 298, 299, 302, 304, 306, 307, 309, 310, 314, 315, 316,\n",
      "       318, 321, 323, 328, 329, 333, 335, 336, 339, 340, 341, 342, 346,\n",
      "       347, 349, 351, 352, 353, 356, 357, 358, 360, 363, 364, 365, 366,\n",
      "       368, 369, 371, 377, 378, 379, 380, 382, 387, 391, 393, 394, 395,\n",
      "       396, 399, 404, 405, 406, 407, 408, 409, 410, 416, 417, 419, 420,\n",
      "       421, 422, 423, 424, 425, 426, 427, 428, 431, 434, 438, 440, 441],\n",
      "      dtype=int64),)\n",
      "WARN: neuro_idx = 454 for label 6 is not stable, let's include it anyway\n",
      "\n",
      "Label is  6\n",
      "Stable ReLUs [1, 10, 12, 13, 17, 18, 19, 26, 30, 31, 32, 33, 36, 37, 39, 45, 47, 48, 49, 51, 52, 54, 55, 56, 58, 63, 65, 66, 68, 70, 72, 74, 75, 76, 78, 79, 81, 83, 84, 87, 88, 91, 95, 97, 98, 99, 107, 110, 112, 113, 116, 120, 122, 123, 125, 127, 128, 129, 130, 132, 133, 139, 141, 142, 143, 145, 147, 149, 153, 157, 158, 159, 161, 167, 170, 172, 173, 175, 176, 177, 179, 190, 191, 194, 195, 196, 197, 198, 200, 202, 203, 207, 209, 210, 214, 215, 218, 219, 220, 223, 225, 228, 235, 238, 239, 241, 242, 246, 248, 249, 250, 251, 252, 253, 255, 256, 257, 258, 259, 260, 261, 263, 265, 267, 268, 269, 271, 272, 273, 275, 277, 283, 284, 285, 286, 287, 288, 290, 293, 295, 296, 297, 298, 299, 302, 304, 305, 306, 307, 309, 310, 314, 315, 316, 318, 319, 321, 323, 325, 326, 328, 329, 333, 335, 336, 338, 339, 340, 341, 342, 343, 345, 346, 347, 349, 351, 352, 353, 356, 357, 358, 360, 363, 364, 365, 366, 368, 369, 371, 372, 374, 375, 377, 378, 379, 380, 382, 385, 386, 387, 391, 392, 393, 394, 395, 396, 399, 401, 403, 404, 405, 406, 407, 408, 409, 410, 411, 414, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 431, 434, 438, 440, 441, 444, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457]\n",
      "how many unique paths in the filtered pattern? (1809, 247)\n",
      "their freq\n",
      " [1 1 1 ... 1 1 1] (1809,)\n",
      "primary pattern coverage:  0.46873943899966203\n",
      "(6265, 458)\n",
      "threshold:  313.25 5951.75\n",
      "relu_sum, prediction [  31   47   93   28   83   15    1 5789   20  158]\n",
      "non active neurons:  (array([108, 221, 225, 257, 262, 267, 279, 288, 305, 319, 325, 326, 338,\n",
      "       343, 345, 370, 372, 374, 375, 385, 386, 392, 401, 403, 411, 414,\n",
      "       418, 444, 448, 449, 450, 451, 452, 453, 454, 456, 457], dtype=int64),)\n",
      "active neurons:  (array([  7,   8,   9,  12,  17,  19,  26,  31,  33,  46,  49,  54,  55,\n",
      "        58,  59,  60,  63,  65,  66,  70,  74,  75,  76,  77,  82,  86,\n",
      "        87,  88,  89,  96,  98, 102, 106, 107, 112, 115, 118, 124, 125,\n",
      "       127, 128, 129, 131, 137, 138, 142, 143, 144, 145, 155, 159, 160,\n",
      "       167, 170, 177, 186, 187, 189, 191, 192, 194, 196, 199, 201, 203,\n",
      "       206, 208, 212, 213, 216, 218, 220, 223, 224, 228, 229, 231, 234,\n",
      "       235, 238, 239, 240, 245, 248, 252, 258, 259, 260, 264, 265, 270,\n",
      "       272, 273, 275, 276, 277, 282, 283, 284, 285, 286, 289, 290, 293,\n",
      "       294, 295, 296, 298, 299, 306, 307, 308, 309, 310, 312, 314, 317,\n",
      "       318, 320, 321, 322, 323, 329, 330, 331, 332, 333, 334, 335, 336,\n",
      "       339, 341, 344, 346, 347, 349, 350, 351, 358, 359, 360, 361, 362,\n",
      "       365, 367, 368, 369, 377, 380, 383, 388, 389, 390, 391, 393, 396,\n",
      "       397, 398, 399, 400, 402, 404, 405, 406, 407, 408, 415, 416, 417,\n",
      "       421, 422, 424, 425, 426, 427, 429, 430, 431, 432, 433, 434, 435,\n",
      "       436, 437, 439, 442, 443, 447], dtype=int64),)\n",
      "WARN: neuro_idx = 455 for label 7 is not stable, let's include it anyway\n",
      "\n",
      "Label is  7\n",
      "Stable ReLUs [7, 8, 9, 12, 17, 19, 26, 31, 33, 46, 49, 54, 55, 58, 59, 60, 63, 65, 66, 70, 74, 75, 76, 77, 82, 86, 87, 88, 89, 96, 98, 102, 106, 107, 108, 112, 115, 118, 124, 125, 127, 128, 129, 131, 137, 138, 142, 143, 144, 145, 155, 159, 160, 167, 170, 177, 186, 187, 189, 191, 192, 194, 196, 199, 201, 203, 206, 208, 212, 213, 216, 218, 220, 221, 223, 224, 225, 228, 229, 231, 234, 235, 238, 239, 240, 245, 248, 252, 257, 258, 259, 260, 262, 264, 265, 267, 270, 272, 273, 275, 276, 277, 279, 282, 283, 284, 285, 286, 288, 289, 290, 293, 294, 295, 296, 298, 299, 305, 306, 307, 308, 309, 310, 312, 314, 317, 318, 319, 320, 321, 322, 323, 325, 326, 329, 330, 331, 332, 333, 334, 335, 336, 338, 339, 341, 343, 344, 345, 346, 347, 349, 350, 351, 358, 359, 360, 361, 362, 365, 367, 368, 369, 370, 372, 374, 375, 377, 380, 383, 385, 386, 388, 389, 390, 391, 392, 393, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 411, 414, 415, 416, 417, 418, 421, 422, 424, 425, 426, 427, 429, 430, 431, 432, 433, 434, 435, 436, 437, 439, 442, 443, 444, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457]\n",
      "how many unique paths in the filtered pattern? (1805, 226)\n",
      "their freq\n",
      " [ 1  1  1 ... 19  2  1] (1805,)\n",
      "primary pattern coverage:  0.4684756584197925\n",
      "(5851, 458)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.bool_):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NpEncoder, self).default(obj)\n",
    "    \n",
    "\n",
    "\n",
    "all_stable_relus = []\n",
    "\n",
    "all_alpha_patterns = {\"model\": LOADPATH}\n",
    "\n",
    "write_log = True\n",
    "if write_log:\n",
    "    ReLU_exp_log = open(\"relu_exp_log{}.csv\".format(datetime.now().strftime(\"%H-%M-%S\")), \"w\")\n",
    "    ReLU_exp_json = open(\"relu_exp_data{}.json\".format(datetime.now().strftime(\"%H-%M-%S\")), \"w\")\n",
    "    ReLU_exp_log.write(\"Epsilon,Label,NumStableReLU,NumUniqueAP,Alpha Pattern Cover\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# for epsilon in [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05]:\n",
    "epsilon_to_patterns = dict()\n",
    "for epsilon in [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05]:\n",
    "    alpha_patterns = {}\n",
    "    label_to_most_common_pattern = dict()\n",
    "    for label in all_patterns.label2patterns:\n",
    "#     for label in [0,2,8]:\n",
    "        patterns = all_patterns.label2patterns[label]\n",
    "        print(patterns.shape)\n",
    "\n",
    "        occuring_patterns = patterns.tolist() #make patterns into list of lists first dim is each example, second dim is the pattern\n",
    "        most_common_pattern = max(occuring_patterns, key =  lambda x :occuring_patterns.count(x)) #argmax the count of each pattern\n",
    "\n",
    "        #print(\"most common pattern: {}\".format(most_common_pattern) )\n",
    "        \n",
    "        pattern_indices = list(filter( lambda x : most_common_pattern[x] , range(len(most_common_pattern))   ))#get true indices     \n",
    "        #print(\"pattern_indices: {}\".format(pattern_indices))\n",
    "        label_to_most_common_pattern[label] = (pattern_indices,most_common_pattern)\n",
    "        relu_sum = np.sum(patterns, axis = 0).squeeze()\n",
    "        \n",
    "        print(\"threshold: \", epsilon*patterns.shape[0], (1-epsilon)*patterns.shape[0])\n",
    "        \n",
    "#         print(\"relu_sum, layer-1 \", relu_sum[:256])\n",
    "#         print(\"relu_sum, layer-2 \", relu_sum[256:384])\n",
    "#         print(\"relu_sum, layer-3 \", relu_sum[384:448])\n",
    "        print(\"relu_sum, prediction\", relu_sum[448:458])\n",
    "#         print(\"relu_sum\", relu_sum[-10:])\n",
    "        \n",
    "        non_active_neurons = np.where(relu_sum<=epsilon*patterns.shape[0])\n",
    "        active_neurons = np.where(relu_sum>=(1-epsilon)*patterns.shape[0])\n",
    "        print(\"non active neurons: \", non_active_neurons)\n",
    "        print(\"active neurons: \", active_neurons)\n",
    "\n",
    "        stable_idx = np.concatenate([np.where(relu_sum<=epsilon*patterns.shape[0]), \n",
    "                                     np.where(relu_sum>=(1-epsilon)*patterns.shape[0])],\n",
    "                                    axis = 1\n",
    "                                    ).squeeze()\n",
    "        neuro_idx = patterns.shape[1] - 10 + label\n",
    "        if neuro_idx not in stable_idx:\n",
    "            print(f\"WARN: neuro_idx = {neuro_idx} for label {label} is not stable, let's include it anyway\")\n",
    "            stable_idx = np.append(stable_idx, neuro_idx)\n",
    "        stable_idx = sorted(stable_idx) #sort the indices of the stable ReLUs. \n",
    "        unique_patterns, freq = np.unique(patterns[:, stable_idx ], axis = 0, return_counts=True)\n",
    "        alpha_p = unique_patterns[np.argmax(freq)]\n",
    "        print()\n",
    "        print(\"Label is \", label)\n",
    "        print(\"Stable ReLUs\", stable_idx)\n",
    "        print(\"how many unique paths in the filtered pattern?\", unique_patterns.shape)\n",
    "        print(\"their freq\\n\", freq, freq.shape)\n",
    "#         print(\"most prominent pattern\", np.argmax(freq), alpha_p)\n",
    "#         print(\"alpha_p is \", alpha_p)\n",
    "\n",
    "\n",
    "        assert(len(stable_idx) == alpha_p.shape[-1])\n",
    "        assert(freq.shape[0]==unique_patterns.shape[0])\n",
    "#         alpha_patterns[label] = (stable_idx, tuple(alpha_p))\n",
    "        alpha_patterns[label] = {\"stable_idx\": stable_idx,\n",
    "                                \"alpha_pattern\": alpha_p,\n",
    "                                \"alpha_pattern_coverage\": freq.max()/freq.sum(),\n",
    "                                \"pattern_frequency\": freq}\n",
    "    \n",
    "#         print(\"pattern frequency:\", freq)\n",
    "        print(\"primary pattern coverage: \", freq.max()/freq.sum(),)\n",
    "\n",
    "        if write_log:\n",
    "            ReLU_exp_log.write(\"{},{},{},{},{}\\n\".format(epsilon, label, len(stable_idx), unique_patterns.shape[0], freq.max()/freq.sum()))\n",
    "    all_alpha_patterns[epsilon] = alpha_patterns\n",
    "    epsilon_to_patterns[epsilon] = label_to_most_common_pattern\n",
    "json.dump(epsilon_to_patterns, open(\"most_common_patterns{}.json\".format(datetime.now().strftime(\"%H-%M-%S\")), \"w\")) \n",
    "    \n",
    "if write_log:\n",
    "    ReLU_exp_log.close()\n",
    "    json.dump(all_alpha_patterns, fp = ReLU_exp_json, indent=2, cls=NpEncoder)\n",
    "    ReLU_exp_json.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label 0 contains 49 neurons and has the following overlaps with others:\n",
      "[49, 21, 18, 22, 22, 24, 36, 21, 29, 22]\n",
      "label 1 contains 79 neurons and has the following overlaps with others:\n",
      "[21, 79, 28, 35, 28, 24, 41, 26, 41, 24]\n",
      "label 2 contains 34 neurons and has the following overlaps with others:\n",
      "[18, 28, 34, 24, 25, 18, 32, 17, 28, 21]\n",
      "label 3 contains 41 neurons and has the following overlaps with others:\n",
      "[22, 35, 24, 41, 24, 22, 33, 24, 35, 25]\n",
      "label 4 contains 53 neurons and has the following overlaps with others:\n",
      "[22, 28, 25, 24, 53, 20, 42, 22, 32, 29]\n",
      "label 5 contains 32 neurons and has the following overlaps with others:\n",
      "[24, 24, 18, 22, 20, 32, 27, 20, 25, 22]\n",
      "label 6 contains 76 neurons and has the following overlaps with others:\n",
      "[36, 41, 32, 33, 42, 27, 76, 26, 42, 32]\n",
      "label 7 contains 44 neurons and has the following overlaps with others:\n",
      "[21, 26, 17, 24, 22, 20, 26, 44, 26, 25]\n",
      "label 8 contains 64 neurons and has the following overlaps with others:\n",
      "[29, 41, 28, 35, 32, 25, 42, 26, 64, 31]\n",
      "label 9 contains 43 neurons and has the following overlaps with others:\n",
      "[22, 24, 21, 25, 29, 22, 32, 25, 31, 43]\n"
     ]
    }
   ],
   "source": [
    "debug = True\n",
    "if debug:\n",
    "    alpha_patterns = all_alpha_patterns[0.0001]\n",
    "    for l1 in range(0,10):\n",
    "        p1 = set(alpha_patterns[l1][\"stable_idx\"])\n",
    "        print(f\"label {l1} contains {len(p1)} neurons and has the following overlaps with others:\" )\n",
    "        row = []\n",
    "        for l2 in range(0,10):\n",
    "            p2 = set(alpha_patterns[l2][\"stable_idx\"])\n",
    "            row.append( len( p1 & p2 ) )\n",
    "        print(row)            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19, 70, 142, 238, 257, 258, 259, 260, 265, 267, 275, 285, 287, 288, 295, 302, 307, 323, 329, 338, 339, 340, 343, 346, 347, 349, 352, 360, 365, 369, 374, 375, 380, 392, 396, 401, 403, 406, 414, 417, 418, 420, 423, 424, 426, 429, 434, 448, 449]\n",
      "(True, True, True, True, False, True, True, True, True, False, True, True, True, False, True, True, True, True, True, False, True, True, False, True, True, True, True, True, True, True, False, False, True, False, True, False, False, True, False, True, False, True, True, True, True, True, True, True, False)\n",
      "dict_values([238])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check\n",
    "CHECK_WEIRD_IMAGE = True\n",
    "image_samples = 10\n",
    "\n",
    "if CHECK_WEIRD_IMAGE:\n",
    "    label = 0\n",
    "#     stable_idx, alpha_p = alpha_patterns[label]\n",
    "    stable_idx = alpha_patterns[label][\"stable_idx\"]\n",
    "    alpha_p = alpha_patterns[label][\"alpha_pattern\"]\n",
    "    alpha_p = tuple(alpha_p)\n",
    "    print(stable_idx)\n",
    "    print(alpha_p)\n",
    "    counters = defaultdict(int)\n",
    "    for data, target in stable_loader:\n",
    "\n",
    "        filter_ids = target == label\n",
    "\n",
    "        data = data[filter_ids]\n",
    "        pattern = model.get_pattern(data, layers, device)\n",
    "        for idx, p in enumerate(pattern):\n",
    "            filtered = tuple(p[stable_idx])\n",
    "            if filtered != alpha_p:\n",
    "                counters[filtered]+=1\n",
    "                if image_samples > 0:\n",
    "                    image_samples -= 1\n",
    "                    fig = plt.figure()\n",
    "                    plt.imshow(data[idx].reshape(28,28))\n",
    "                    plt.title(f\"{image_samples}-th sample\")\n",
    "\n",
    "\n",
    "\n",
    "    print(counters.values())\n",
    "\n",
    "debug = False \n",
    "if debug: \n",
    "    label = 0\n",
    "    stable_idx = alpha_patterns[label][\"stable_idx\"]\n",
    "    alpha_p = alpha_patterns[label][\"alpha_pattern\"]\n",
    "    alpha_p = tuple(alpha_p)\n",
    "    print(\"stable_idx\", stable_idx)\n",
    "    print(\"alpha_p\", alpha_p)\n",
    "    counters = defaultdict(int)\n",
    "    for data, target in test_loader:\n",
    "\n",
    "        filter_ids = target == label\n",
    "\n",
    "        data = data[filter_ids]\n",
    "        pattern = model.get_pattern(data, layers, device)\n",
    "        for idx, p in enumerate(pattern):\n",
    "            filtered = tuple(p[stable_idx])\n",
    "#             if filtered in intersection:\n",
    "            if filtered != alpha_p:\n",
    "                counters[filtered]+=1\n",
    "    print(sum(counters.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'some_input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4396/2386266478.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;31m#compute the patterns that are both in train and test set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mstable_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha_patterns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"stable_idx\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#for a label what are the stable relu, 1d array [10,20,50] are stable RELU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_pattern\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msome_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstable_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#only look at stable values, eacch is 0 or 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m#confirm no overlap in stable region\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'some_input' is not defined"
     ]
    }
   ],
   "source": [
    "all_heatmaps = {}\n",
    "# for epsilon in [0.01, 0.05]:\n",
    "num_patterns = 1 #-1 for all\n",
    "modification_string += \" - num_patterns {} - \".format(num_patterns)\n",
    "for epsilon in [0.0001]:    \n",
    "    alpha_patterns = all_alpha_patterns[epsilon]\n",
    "    heatmap = []\n",
    "    for label in labels:\n",
    "        row = []\n",
    "\n",
    "        #compute the patterns that are both in train and test set\n",
    "        stable_idx = np.array(alpha_patterns[label][\"stable_idx\"]) #for a label what are the stable relu, 1d array [10,20,50] are stable RELU\n",
    "        p = model.get_pattern(some_input,layers, )\n",
    "        print(p[stable_idx]) #only look at stable values, eacch is 0 or 1\n",
    "        #confirm no overlap in stable region\n",
    "        alpha_p = alpha_patterns[label][\"alpha_pattern\"]\n",
    "        alpha_p = tuple(alpha_p)\n",
    "        test_patterns = all_test_patterns.label2patterns[label]\n",
    "\n",
    "        print(\"LABEL:\", label)\n",
    "        print(\"how many unique paths in the full pattern?\", np.unique(test_patterns, axis = 0).shape)\n",
    "        print(\"how many unique paths in the filtered pattern?\", np.unique(test_patterns[:, stable_idx ], axis = 0).shape)\n",
    "        print(\"how many unique paths in the randomly filtered pattern?\", \n",
    "              np.unique(test_patterns[:, \n",
    "                                 np.random.choice(458, len(stable_idx), replace = False) ], axis = 0).shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        train_patterns = all_patterns.label2patterns[label]\n",
    "        raw_train_patterns = np.unique(train_patterns[:, stable_idx], axis = 0)\n",
    "        print(raw_train_patterns.shape)\n",
    "\n",
    "        raw_test_patterns = np.unique(test_patterns[:, stable_idx], axis = 0)\n",
    "        print(raw_test_patterns.shape)\n",
    "\n",
    "        set_train_patterns = set([tuple(p) for p in raw_train_patterns])\n",
    "        set_test_patterns = set([tuple(p) for p in raw_test_patterns])\n",
    "\n",
    "        intersection = set_train_patterns.intersection(set_test_patterns)\n",
    "\n",
    "        print(len(set_train_patterns), len(set_test_patterns))\n",
    "        print(len(intersection))\n",
    "\n",
    "        for label2 in labels:\n",
    "            print(f\"examining images with groundtruth label = {label2}\")\n",
    "            counters = defaultdict(int)\n",
    "            img_ct = 0\n",
    "            img_same_pattern = 0 \n",
    "            for data, target in test_loader:\n",
    "\n",
    "                filter_ids = target == label2\n",
    "\n",
    "                data = data[filter_ids]\n",
    "                pattern = model.get_pattern(data, layers, device)\n",
    "                print(type(pattern))\n",
    "                print(pattern)\n",
    "                image_samples = 5\n",
    "                for idx, p in enumerate(pattern):\n",
    "                    print(\"p is {}\".format(p))\n",
    "                    img_ct += 1\n",
    "                    filtered = tuple(p[stable_idx])\n",
    "#                     if filtered in intersection:\n",
    "#                         counters[filtered]+=1\n",
    "                    if filtered == alpha_p:\n",
    "                        img_same_pattern += 1\n",
    "                        if image_samples > 0:\n",
    "                            image_samples -= 1\n",
    "                            fig = plt.figure()\n",
    "                            plt.imshow(data[idx].reshape(28,28))\n",
    "                            plt.title(f\"gt-{label2}-s{image_samples} vs wrong:{label}\")\n",
    "\n",
    "#             row.append(sum(counters.values()))\n",
    "            row.append(img_same_pattern)\n",
    "            print(f\"label2 = {label2} has {img_ct} images, out of which {img_same_pattern} share the same pattern as label={label}\")\n",
    "            \n",
    "        heatmap.append(row)\n",
    "    all_heatmaps[epsilon] = heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 1]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x2880 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test patterns\n",
    "root - INFO - (980, 458)\n",
    "root - INFO - (1135, 458)\n",
    "root - INFO - (1032, 458)\n",
    "root - INFO - (1010, 458)\n",
    "root - INFO - (982, 458)\n",
    "root - INFO - (892, 458)\n",
    "root - INFO - (958, 458)\n",
    "root - INFO - (1028, 458)\n",
    "root - INFO - (974, 458)\n",
    "root - INFO - (1009, 458)\n",
    "\"\"\"\n",
    "fig, axs = plt.subplots(nrows=2, figsize = (20, 40))\n",
    "counter = 0\n",
    "for epsilon in all_heatmaps:\n",
    "    heatmap = all_heatmaps[epsilon]\n",
    "    print(heatmap)\n",
    "    df_cm = pd.DataFrame(heatmap, labels, labels)\n",
    "    \n",
    "    axs[counter].set_title(\"Epsilon:{}\".format(epsilon))\n",
    "\n",
    "    sn.heatmap( df_cm,ax = axs[counter], annot=True, cmap='Blues', fmt='g', annot_kws={\"fontsize\":30})\n",
    "    counter+=1\n",
    "fig.savefig(modification_string+'confusion_matrix{}.pdf'.format(datetime.now().strftime(\"%m-%d-%Y-%H-%M-%S\")))\n",
    "# print(intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ6:study the hot ReLU and the gradient\n",
    "Do at least the following statistics on the activation patterns.\n",
    "- What are the top k RELU with the highest gradient value (indicating that they are highly influential ReLU). If we only look at those ReLU, how many activation patterns do we have? This exp should be parametrized by k\n",
    "- For activation patterns from images from the same label (e.g 7), what ReLU are stable, and what not? To check for stable, we set a threshold T%. If the value of the ith ReLU is the same for at least T% of the time, we say that ith ReLU is stable.\n",
    "- Given that ith ReLU is stable for the label 7, is it also stable for a different label (e.g 9)? Note that for label 7, it may stable and always be 1, but for label 9, it may also be stable but with value 0.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Checking ReLUs with highest gradient\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
